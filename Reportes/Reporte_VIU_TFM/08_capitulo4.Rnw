\chapter{Resultados}\label{cap:resul}

\section{Contexto y problema planteado}

Conforme a lo expuesto en el capítulo introductorio y en consonancia con los objetivos planteados, el propósito de este trabajo de fin de máster es que, mediante las aportaciones que los pensionistas realizaron durante su vida laboral, detectar mediante técnicas de aprendizaje no supervizado aquellas que son fraudentan y luego generar un modelo de aprendizaje supervizado que me permita discrimnar los perfiles de los potenciales afiliados que podrían realizar un tipo de fraude en función del comportamiento de su materia gravada\footnote{Es todo ingreso susceptible de apreciación pecuniaria, percibido por la persona afiliada, o en caso del trabajo no remunerado del hogar, por su unidad económica familiar.} para la generación de sus aportaciones.\\

En primer paso es la generación de una adecuado proceso KKD (en función de lo descrito en la seccón xxxxx), para que a partir de los datos primarios que dispone el IESS, generar el conocimiento adecuado que permita dar solución al problema planteado. En las siguientes secciones de muestra cada una de las fases del proceso KKD.

Un aspecto importante a considerar es que la información inicial (se llamára \textit{data\_afi}) con la cual se generó la primera parte del proceso KDD es resultado de un preprocesamiento a las bases transaccionales del IESS, por lo que, su manipulación fue realizada mediante lenguaje \textit{pl/SQL} en la base de datos \textit{oracle}. El esquema de las tablas transacionales y el código utilizado para la generación de la información inicial se detallan en el anexo \ref{cap:anexo1}. La fecha de extracción de la información fue a mayo 2024 y el análisis se centra con fecha de corte al 31 de diciembre de 2023. Esta fecha indica que se analizarán todos los registros anteriores a la misma.

Adicionalmente, es preciso indicar que todo el proceso de limpieza, preprocesamiento y transformación de datos se lo realizó usando el lenguaje de programación \textit{Python} mediante versionamiento a través de la herramienta \textit{git}, creando un repositorio en Github. El nombre de este repositorio es \textit{VIU\_TFM} (Véase \legalcite{CristianVIUTFM}) y en el mismo se encuentran script de python que fueron utilizados para alcanzar el objetivo planteado y script de R utilizados en la edición del presente proyecto en formato \texttt{\LaTeX}.


\section{Fuente de datos}

Dentro de todas las fuentes de información que dispone el Instituto Ecuatoriano de Seguridad Social, se consideran las bases de datos transaccionales que guardan la información de Historia Laboral\footnote{El componente de Historia Laboral (HL) contiene la información de la vida laboral del afiliado, que incluye características como su información personal, empresa donde trabaja o trabajó, su fecha de primera aportación, las salidas del sistema, reingresos, aportes,
sueldos, transiciones entre seguros, etc. La HL se encuentra cargada dentro del esquema
iess\_owner} y Prestacional\footnote{El componente Prestacional contiene de manera general la información del pensionista del IESS, incluyendo campos como su información personal, monto de su pensión,
incrementos o mejoras en la pensión, tipo del seguro en que solicitó la pensión, etc. Este
componente se encuentra cargado dentro del esquema pensiones\_owner}. Adicionalmente, la información se complementa con los datos proporcionados por Registro Civil (entidad pública que guarda los datos personales de la población ecuatoriana)

\section{Selección de datos}

Para tener información consolidada se debía de hacer joins entre las tablas de la sección \ref{sec:fuentes_datos} de la parte de anexos, lo cual implicaba tener en la tabla final un sinnúmero de variables que no estaban relacionadas directamente con el problema a abordar. De esta manera, de todo el conjunto de atributos iniciales se seleccionaron aquellos que permitirán describir el comportamiento del actual afiliado y abordar el objetivo planteado  dentro de nuestro proceso KDD.

Los atributos seleccionados dentro del dataset \textit{data\_afi} son los siguientes:

\begin{multicols}{2}  
    \begin{itemize}
        \item CEDULA\_COD: Secuencial que indentifica al afiliado,\\[-0.75cm]
        \item ANIO: Corresponde al año del pago de la planilla del afiliado,\\[-0.75cm]
        \item MES: Corresponde al mes del pago de la planilla del afilaido,
    \end{itemize}
    \begin{itemize}  
        \item CODSEC: Corresponde a la abreviación del sector en el cual trabajó el afiliado,\\[-0.75cm]
        \item SECTOR: Corresponde al sector en el cual trabajó el afiliado,\\[-0.75cm]
        \item SALARIO: Corresponde al salario sobre el cual aporte el afiliado,
    \end{itemize}
\end{multicols}

Para los pensionistas tenemos un mismo esquema de información, mismo que se describe a continuación:

\begin{multicols}{2}  
    \begin{itemize}
        \item CEDULA\_COD: Secuencial que indentifica al pensionista,\\[-0.75cm]
        \item SEXO: Corresponde al sexo del pensionista,\\[-0.75cm]
        \item FECHA\_NACIMIENTO: Corresponde a la fecha de nacimiento del pensionista,\\[-0.75cm]
        \item FECHA\_MUERTE: Corresponde a la fecha de muerte del pensionista,\\[-0.75cm]
        \item FECHA\_DERECHO: Corresponde a la fecha de derecho\footnote{Es la fecha en la cual una persona tiene derecho a solicitar su jubilación} del pensionista,\\[-0.75cm]
    \end{itemize}
    \begin{itemize}  
        \item NUMERO\_IMPOSICIONES: Corresponde al número de imposiciones\footnote{Una imposición correspnde a treinta (30) días laborados} al momento de la jubilación,\\[-0.75cm]
        \item COEFICIENTE\_REAL: Corresponde al valor del coeficiente\footnote{Es el valor del coeficiente anual de años cumplidos de imposiciones acorde a la \legalcite{ResIESS_CD100}} dentro del sistema Prestacional,\\[-0.75cm]
        \item COEFICIENTE\_CALCULADO: Corresponde al valor del coeficiente calculado en base a la historia laboral,\\[-0.75cm]
        \item PROMEDIO\_SUELDO\_REAL: Corresponde a la base de calculo\footnote{Para el cómputo de la base de cálculo de la pensión, se procederá a la suma de doce (12) meses de imposiciones consecutivas y ese resultado se dividirá para doce (12). Obtenido así el promedio mensual de los sueldos o salarios de cada año de imposiciones del afiliado, se seleccionarán los cinco (5) promedio mensuales de mayor cuantía y el resultado de la suma se dividirá para cinco (5)} del promedio de los años de mejores sueldos o salarios sobre los cuales se aportó dentro del sistema Prestacional,\\[-0.75cm]
        \item PROMEDIO\_CAL: Corresponde al la base de cálculo estimada en función de los cinco (5) mejroes años de sueldo sobre los cuales aportó,\\[-0.75cm]
        \item VALOR\_PENSION: Corresponde a la pensión calculada en el sistema Prestacional,\\[-0.75cm]
        \item PENSION\_CAL: Corresponde a la pensión calculada en función del artículo 13\footnote{La pensión mensual por invalidez o vejez y el subsidio transitorio por incapacidad será igual al resultado de la multiplicación de la Base de Cálculo de la \legalcite{ResIESS_CD100}, por el coeficiente anual de años cumplidos de imposiciones. De los 40 años en adelante se incrementará el 0,0125 por cada año de imposiciones adicionales.} de la \legalcite{ResIESS_CD100},\\[-0.75cm]
        \item ID\_PRESTACION: Corresponde al identificador único de la prestación,\\[-0.75cm]
        \item RANGO\_INI\_5MEJ: Corresponde a la fecha máxima de los cinco (5) mejores años de sueldo,\\[-0.75cm]
        \item RANGO\_FIN\_5MEJ: Corresponde a la fecha mínima de los cinco (5) mejores años de sueldo,\\[-0.75cm]
        \item N\_MESES: Corresponde al número de meses trabajados

    \end{itemize}
\end{multicols}

Los atributo descritos anteriormente serán dividos en tres grupos, para las jubilaciones de vejez, invalidez y discapacidad. El nombre de estos conjuntos de datos serán \textit{data\_vej}, \textit{data\_inv} y \textit{data\_dis} para hacer referencia a la información de las jubilaciones de vejez, invalidez y discapacidad respectivamente.

\section{Limpieza de datos}\label{cha_resul:limpieza}

Para alcanzar el objetivo planteado, la limpieza de datos del presente proyecto se divide en dos partes. La primera parte se centra en el proceso de minería de datos para los datos utilizados antes de la ejecución de algoritmos de aprendizaje no supervizado para etiquetar los salarios y a las personas que generarón alguna aportación fraudelenta en función del comportamiento histórtico de los salarios a lo largo de su vida laboral. La seguna parte corresponde al preprocesamiento de la información resultante de los algoritmos no supervizados para su posterior implementación en los métodos supervizados.

\subsection{Datos previos a la aplicación de aprendizaje no supervizado}

Además de considerar las explicaciones dadas en el penúltimo párrafo de la sección \ref{sec:fuentes_datos} de la parte de anexos, es importante mencionar que el conjunto de datos \textit{data\_afi} no va a presentar problemas con missing values ni datos inconsistentes en ningún atributo, debido a que estas novedades ya se resolvieron con anterioridad (desde el comienzo de construcción del dataset original). Por otro parte, las bases de datos de los pensionistas en ciertos atributos si van a presentar problemas con datos perdidos, como por ejemplo la \textit{FECHA\_MUERTE}\footnote{Debido a que a la fecha de corte no todos los pensionistas estpan muertos}, \textit{NUMERO\_IMPOSICIONES}\footnote{Debido a que como el sistema del IESS tiene dos fuentes de información (HL Y HOST) algunos regustros no están correctamente migrados}, etc.

El dataset de los afiliados contiene 68.062.270 filas y 12 columnas, el conjunto de datos de los pensionistas de vejez tiene 681.799 filas con 17 columnas, el de invalidez tiene 48.146 filas y 17 columnas  y los datos de discapacidad tiene 14.662 filas y 17 columnas.

\subsection{Datos previos a la aplicación de aprendizaje supervizado}

\section{Transformación de datos}

\subsection{Datos previos a la aplicación de aprendizaje no supervizado}

Con la finalidad de aliviar el costo computacional, se transforman variables en atributos más sencillos y se crean variables que permitirán alcanzar el objetivo planteado. A manera general, todo el proceso de transformación de datos se describe en la sección \ref{sec:limpieza_datos} de la parte de anexos. Si el lector desea tener una experiencia más didáctica con todo el proceso, puede hacerlo visualizando el archivo  \textit{VIU\_clean\_data.ipynb} de \legalcite{CristianVIUTFM}.

A manera general, en lo que sigue se describen las variables que fueron creadas (para mayor detalle véase sección \ref{sec:limpieza_datos} de la parte de anexos.):

\begin{itemize}
\item SUELDO: Corresponde a la suma de la materia gravada histórica del afiliado hasta el momento de su jubilación, \\[-0.75cm]
\item APORTE: Corresponde a la suma del aporte\footnote{Es la multiplicación entre la materia gravada del afiliado, mes a mes, con el valor de la tasa de aportación. Estos valores se presentan en la tabla \ref{tab:info_tasa_aport_actuarial} de la sección \ref{sec:limpieza_datos} de la parte de anexo.} del afiliado hasta el momento de su jubilación,\\[-0.75cm]
\item INTERES\_APORTE: Corresponde a la suma por concepto del interés\footnote{Corresponde a la multiplicación entre la variable APORTE, mes a mes, con la tasa de interés actuarial. Estos valores se presentan en la tabla \ref{tab:info_tasa_aport_actuarial} de la sección \ref{sec:limpieza_datos} de la parte de anexo.} que genero el aporte del afiliado durante su vida laboral.\\[-0.75cm]
\item FIN\_HL: Corresponde a la fecha de la última planilla genera por concepto de aportes durante a vida laboral del afiliado\\[-0.75cm]
\item INI\_HL: Corresponde a la fecha de la primera planilla genera por concepto de aportes durante a vida laboral del afiliado\\[-0.75cm]
\item MES\_AS: Corresponde al número de meses aportados\footnote{Es el conteo del número de veces no únicos, es decir, si una persona aporte dos o más veces en el mismo mes, se le cuenta dos o más veces} durante la vida laboral del afiliado\\[-0.75cm]
\item MES\_TU: Corresponde al número de meses distintos\footnote{Es el conteo del núemro de meses únicos, es decir, si una persona aportó dos o más veces en el mismo mes, solo se le contabiliza como una vez} aportados durante la vida laboral del afiliado,\\[-0.75cm]
\item  N\_PRI, N\_PUB, N\_IND, N\_VOL\_EX y N\_VOL\_EC: Guardan la información sobre las veces que el afiliado aporte en los sectores Privado, Público, Independiente, Voluntario del Exterior y Voluntario residente del Ecuador respectivamente.

\end{itemize}

En base a los artículo 2 y 13 de la \legalcite{ ResIESS_CD100}, se procede a calcular la base de calculo. Para esto se crean las variables GRUPO\_SEL\footnote{Es una variable indicatriz, que toma los valores de 1, si para un mes x del año Y, el registro se cuenta para la base de cálculo; 0 caso contrario}, BASE\_CAL\footnote{Es el valor de la Base de Cálculo en concordancia con el artículo 2 de la \legalcite{ResIESS_CD100}}. Adicionalmente, se crean las variables SBU\footnote{Contiene la información del Salario Básico Unificado para los trabajadores del Ecuador}, cuyos valores son los presentes en \cite{bce_salarios}, INI\_CAL y FIN\_CAL que corresponde a las fechas máxima y mínima de la base de calculo respectivamente, y, M\_PRI, M\_PUB, M\_IND, M\_VOL\_EX y M\_VOL\_EC que guardarán la información sobre las veces que el afiliado aporte dentro de sus mejores años de aporte en los sectores Privado, Público, Independiente, Voluntario del Exterior y Voluntario residente del Ecuador respectivamente.

El dataset resultante de este proceso se datos se llamará \textit{data\_l}, mismo que será utilizado para la discrimnación de la etiqueta de fraude o no fraude en las aportaciones. Este tabulado contendrá 62.130.167 registros y 16 atributos, que corresponde a  442.570 personas. Adicionalmente se crean las variables \textit{LS1}, \textit{SAL\_PROM1}, \textit{LS2} y \textit{SAL\_PROM2}, que corresponden al límite superior\footnote{Se define como la suma entre el tercer cuartil + 1,5 veces el rango inter cuartilico } del bigote del diagrama de caja y sueldo promedio para los salarios históricos y a partir del año 2000\footnote{Debido a la crisis ecónomica por la cual atravezaba el Ecuador, a partir del año 2000 el país cambia los Sucres (como moneda nacional)  a dólares estadounidenses como moneda oficial \cite{Ecua_sucre_dolar}} en adelante, respectivamemte. Esta consideración se la realiza debido a que el país cambió su moneda, por lo que, las contribuciones realizadas en sucres y posteriormente transformación a dólares con la tasa de cambios a esa fecha eran significativamente menores al SBU del año 2000 y así en adelante. En este sentido, se considerarán los valores de las variables \textit{LS2} y \textit{SAL\_PROM2}.



\subsection{Datos previos a la aplicación de aprendizaje supervizado}

Una vez que finalizado el 

\subsection{Tratamiento de valores perdidos}

Como ya se expuso anteriormente, \textit{data\_afi} no contiene valores perdidos. Pero por el contrario \textit{data\_vej}, \textit{data\_inv} y \textit{data\_dis} si va a tener variables con valores perdidos, principalmente en las variables \textit{FECHA\_MUERTE}, \textit{NUMERO\_IMPOSICIONES} pero estos valores son corregios con los valores del dataset previo a la aplicación de aprendizaje supervizado.

\subsection{Tratamiento de outlier}

La principal variable de interés en \textit{data\_afi} es el \textit{SALARIO}, misma permitirá discriminar si la persona realizaron lagún tipo de fraude para obtener un mejor beneficio pensional a largo plazo. En este sentido, no se realiza ninguna corrección de sus valores pues es justamente lo que queremos detectar con los algoritmos de aprendizaje no supervizados.

\section{Aprendizaje no supervizado}

Para la ejecución de los algoritmos de aprendizaje no supervizado se utiliza la base de datos \textit{data\_l}. Los algoritmos utilizados son cluster jerarquico\footnote{Se utiliza la métrica single pues es la que ayuda a detectar outlier \cite{Hogde2004}}, k-mean y dbscan, puesto que los mismoS me permiten realizar la busqueda de los salarios que son atipicos dentro del comportamiento salarial del afiliado.

\subsection{Cluster jerárquico}

Para este análisis, solo se considerarán los valores  igual a uno (1) de la variable \textit{GRUPO\_SEL}, puesto que, estos registros son los meses y años de los cinco (5) mejores años de sueldo. 


Como el algoritmo de cluster jerarquico requiere de gran capacidad computacional, se procedió a dividir el dataset \textit{data\_l} en dos grupos. El primer grupo (de nombre \textit{ul}) solo considerará a las personas que durante toda su vida laboral y en un mismo mes aportarón solo una vez en ese mes. El número de personas que tienen esta condición es 373.069. El segundo grupo será el complemento del primero (se llamará \textit{ml}) y contiene información de 69.501 personas

Tanto para \textit{ul} como \textit{ml} se calculo el bigote superior de los sueldos  para cada persona(esta variable se llamara \textit{LS\_MS}, que corresponde al bigote superior de los mejores cinco mejores años de sueldo).

En referencia a la literatura, al utilizar la métrica de single en el algoritmo de cluster jerárquico, se puede detectar registros atípicos, por lo cual, está métrica será la que se va a utilizar en nuestro análisis. El código utilizado es la función \textit{cluster\_jerarquico} del código de la sección \ref{sec:alg_clus_jear} de anexos. La idea general del código es considerar como máximo dos cluster y dentro de cada uno de ellos realizar el siguiente análisis:

\begin{itemize}
\item Si el número de cluster que se forman es mayor a 1, se calcula el centroide de cada cluster y si este valor es mayor a \textit{LS\_MS}, entonces todas las observaciones del cluster serán atipicas. La etiqueta de ese sueldo será 1.
\item Si el  número de cluster formados es igual a 1, entonces la etiqueta será -1, valor que se corregíra despúes.
\end{itemize}

Los resultados de la aplicación de función \textit{cluster\_jerarquico}, muestran que hay 123.850 personas con al menos un sueldo atípico y 52.121 personas cuyos sueldos formaron un solo cluster.  A manera de ejemplo, se presetan los siguientes casos.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{graficos/algoritmo_cj_271_1.png}
\caption{\headlinecolor{\underline{Cluster jerárquico: Caso 1}}}
\label{fig:algoritmo_cj_271_1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{graficos/algoritmo_cj_20889867_1.png}
\caption{\headlinecolor{\underline{Cluster jerárquico: Caso -1}}}
\label{fig:algoritmo_cj_271_1}
\end{figure}

La clasificación anterior debe ser corregida debido a que hay sueldos que, el algortimo los clasifica como atípicos, pero por la naturaleza de su valor no lo deberían serlo. Estos valores recaen sobre los sueldos que son igual al SBU.

Por otro lado, una segunda correción se realiza a los sueldos que formaron un solo cluster, pues el algoritmo no me determinó si en efecto eran o no valores atípicos, por lo que, si un sueldo fue clasificado como -1 y su valor es mayor al mínimo entre \textit{LS2} y \textit{LS\_MS} entonces el valor es atípico. 

Una tercera corrección se hace para los sueldos de la data \textit{ml}, pues aquí la variable sueldo para un mes es la suma de todas las aportaciones que realizó en ese mes, por lo tanto, si una de las partes que componen la suma es mayor  al mínimo entre \textit{LS2} y \textit{LS\_MS}, entonces es sueldo si es atipico.

En este sentido, en la primera fila de la figura \ref{fig:algoritmo_cj_depu} se muestra la clasificación del algoritmos, y en la segunda, las correccones realizadas en base a lo expuesto con anterioridad. 

En la figura \ref{fig:algoritmo_cj_depu_anex} de la parte de anexos se muestran otros ejemplos.


\begin{landscape}
\begin{figure}[H]  
    \centering
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_8804_2.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_3071_2.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_20857054_2.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_10133_2.png} 
    \end{minipage}
   
   \vfill 
  \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_8804_3.png} 
    \end{minipage}
     \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_3071_3.png}  
        
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_20857054_3.png}  
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_10133_3.png}  
    \end{minipage}

\caption{\headlinecolor{\underline{Resultados de la aplicaicón del cluster jerárquico para los casos 1 y -1 }}}
\label{fig:algoritmo_cj_depu}  
    
\end{figure}

Como se observa de la gráfica anterior, la corrección es adecuado puesto que, se estarían clasificando como atípicos valores que no lo son.

Para que el lector pueda tener una visión más detalla del proceso, puede revisar el script \textit{VIU\_cluster\_jerarquico.ipynb} de \legalcite{CristianVIUTFM}.

\end{landscape}

\section{K-Means}

Otro algoritmo que tiene gran potencial para estimar valores atípicos es el k-means. En este sentido, se sigue un proceso similar al expuesto en cluster jerarquico con respecto a las consideraciones para \textit{GRUPO\_SEL}, \textit{data\_l}, \textit{ul}, \textit{ml} y \textit{LS\_MS}. La ejecución de este algoritmo requiere de un tiempo muy extenso de procesamiento  (24 horas en promedio). Por otro parte, siguiendo lo expresado en la literatura, este algoritmo se divide en dos casos, uno con los datos sin normalizar y el otro con los datos normalizados. Con la finalidad de realizar un ejercicio didácico para estimar el número de cluster que agruparán los salaiors de cada persona, se hace una estimación (Véase el código de la sección \ref{})













