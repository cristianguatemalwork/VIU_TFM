\chapter{Resultados}\label{cap:resul}

\section{Contexto y problema planteado}

Conforme a lo expuesto en el capítulo introductorio y en consonancia con los objetivos planteados, el propósito de este trabajo de fin de máster es que, mediante las aportaciones que los pensionistas realizaron durante su vida laboral, detectar mediante técnicas de aprendizaje no supervizado aquellas que son fraudulentas y luego generar un modelo de aprendizaje supervizado que permita discriminar los perfiles de los potenciales afiliados que podrían realizar un tipo de fraude en función del comportamiento de su materia gravada\footnote{Es todo ingreso susceptible de apreciación pecuniaria, percibido por la persona afiliada, o en caso del trabajo no remunerado del hogar, por su unidad económica familiar.} para la generación de sus aportaciones.\\

En primer paso es la generación de una adecuado proceso KKD (en función de lo descrito en la seccón xxxxx), para que a partir de los datos primarios que dispone el IESS, generar el conocimiento adecuado que permita dar solución al problema planteado. En las siguientes secciones de muestra cada una de las fases del proceso KKD.

Un aspecto importante a considerar es que la información inicial (se llamará \textit{data\_afi}) con la cual se generó la primera parte del proceso KDD es resultado de un preprocesamiento a las bases transaccionales del IESS, por lo que, su manipulación fue realizada mediante lenguaje \textit{pl/SQL} en la base de datos \textit{oracle}. El esquema de las tablas transaccionales y el código utilizado para la generación de la información inicial se detallan en el anexo \ref{cap:anexo1}. La fecha de extracción de la información fue a mayo 2024 y el análisis se centra con fecha de corte al 31 de diciembre de 2023. Esta fecha indica que se analizarán todos los registros anteriores a la misma.

Adicionalmente, es preciso indicar que todo el proceso de limpieza, preprocesamiento y transformación de datos se lo realizó usando el lenguaje de programación \textit{Python} mediante versionamiento a través de la herramienta \textit{git}, creando un repositorio en Github. El nombre de este repositorio es \textit{VIU\_TFM} (Véase \legalcite{CristianVIUTFM}) y en el mismo se encuentran script de python que fueron utilizados para alcanzar el objetivo planteado y script de R utilizados en la edición del presente proyecto en formato \texttt{\LaTeX}.


\section{Fuente de datos}

Dentro de todas las fuentes de información que dispone el Instituto Ecuatoriano de Seguridad Social, se consideran las bases de datos transaccionales que guardan la información de Historia Laboral\footnote{El componente de Historia Laboral (HL) contiene la información de la vida laboral del afiliado, que incluye características como su información personal, empresa donde trabaja o trabajó, su fecha de primera aportación, las salidas del sistema, reingresos, aportes,
sueldos, transiciones entre seguros, etc. La HL se encuentra cargada dentro del esquema
iess\_owner} y Prestacional\footnote{El componente Prestacional contiene de manera general la información del pensionista del IESS, incluyendo campos como su información personal, monto de su pensión,
incrementos o mejoras en la pensión, tipo del seguro en que solicitó la pensión, etc. Este
componente se encuentra cargado dentro del esquema pensiones\_owner}. Adicionalmente, la información se complementa con los datos proporcionados por Registro Civil (entidad pública que guarda los datos personales de la población ecuatoriana)

\section{Selección de datos}

Para tener información consolidada se debía de hacer joins entre las tablas de la sección \ref{sec:fuentes_datos} de la parte de anexos, lo cual implicaba tener en la tabla final un sinnúmero de variables que no estaban relacionadas directamente con el problema a abordar. De esta manera, de todo el conjunto de atributos iniciales se seleccionaron aquellos que permitirán describir el comportamiento del actual afiliado y abordar el objetivo planteado  dentro de nuestro proceso KDD.

Los atributos seleccionados dentro del dataset \textit{data\_afi} son los siguientes:

\begin{multicols}{2}  
    \begin{itemize}
        \item CEDULA\_COD: Secuencial que indentifica al afiliado,\\[-0.75cm]
        \item ANIO: Corresponde al año del pago de la planilla del afiliado,\\[-0.75cm]
        \item MES: Corresponde al mes del pago de la planilla del afilaido,
    \end{itemize}
    \begin{itemize}  
        \item CODSEC: Corresponde a la abreviación del sector en el cual trabajó el afiliado,\\[-0.75cm]
        \item SECTOR: Corresponde al sector en el cual trabajó el afiliado,\\[-0.75cm]
        \item SALARIO: Corresponde al salario sobre el cual aporte el afiliado,
    \end{itemize}
\end{multicols}

Para los pensionistas tenemos un mismo esquema de información, mismo que se describe a continuación:

\begin{multicols}{2}  
    \begin{itemize}
        \item CEDULA\_COD: Secuencial que indentifica al pensionista,\\[-0.75cm]
        \item SEXO: Corresponde al sexo del pensionista,\\[-0.75cm]
        \item FECHA\_NACIMIENTO: Corresponde a la fecha de nacimiento del pensionista,\\[-0.75cm]
        \item FECHA\_MUERTE: Corresponde a la fecha de muerte del pensionista,\\[-0.75cm]
        \item FECHA\_DERECHO: Corresponde a la fecha de derecho\footnote{Es la fecha en la cual una persona tiene derecho a solicitar su jubilación} del pensionista,\\[-0.75cm]
    \end{itemize}
    \begin{itemize}  
        \item NUMERO\_IMPOSICIONES: Corresponde al número de imposiciones\footnote{Una imposición correspnde a treinta (30) días laborados} al momento de la jubilación,\\[-0.75cm]
        \item COEFICIENTE\_REAL: Corresponde al valor del coeficiente\footnote{Es el valor del coeficiente anual de años cumplidos de imposiciones acorde a la \legalcite{ResIESS_CD100}} dentro del sistema Prestacional,\\[-0.75cm]
        \item COEFICIENTE\_CALCULADO: Corresponde al valor del coeficiente calculado en base a la historia laboral,\\[-0.75cm]
        \item PROMEDIO\_SUELDO\_REAL: Corresponde a la base de cálculo\footnote{Para el cómputo de la base de cálculo de la pensión, se procederá a la suma de doce (12) meses de imposiciones consecutivas y ese resultado se dividirá para doce (12). Obtenido así el promedio mensual de los sueldos o salarios de cada año de imposiciones del afiliado, se seleccionarán los cinco (5) promedio mensuales de mayor cuantía y el resultado de la suma se dividirá para cinco (5)} del promedio de los años de mejores sueldos o salarios sobre los cuales se aportó dentro del sistema Prestacional,\\[-0.75cm]
        \item PROMEDIO\_CAL: Corresponde al la base de cálculo estimada en función de los cinco (5) mejroes años de sueldo sobre los cuales aportó,\\[-0.75cm]
        \item VALOR\_PENSION: Corresponde a la pensión calculada en el sistema Prestacional,\\[-0.75cm]
        \item PENSION\_CAL: Corresponde a la pensión calculada en función del artículo 13\footnote{La pensión mensual por invalidez o vejez y el subsidio transitorio por incapacidad será igual al resultado de la multiplicación de la Base de Cálculo de la \legalcite{ResIESS_CD100}, por el coeficiente anual de años cumplidos de imposiciones. De los 40 años en adelante se incrementará el 0,0125 por cada año de imposiciones adicionales.} de la \legalcite{ResIESS_CD100},\\[-0.75cm]
        \item ID\_PRESTACION: Corresponde al identificador único de la prestación,\\[-0.75cm]
        \item RANGO\_INI\_5MEJ: Corresponde a la fecha máxima de los cinco (5) mejores años de sueldo,\\[-0.75cm]
        \item RANGO\_FIN\_5MEJ: Corresponde a la fecha mínima de los cinco (5) mejores años de sueldo,\\[-0.75cm]
        \item N\_MESES: Corresponde al número de meses trabajados

    \end{itemize}
\end{multicols}

Los atributos descritos anteriormente serán dividos en tres grupos, para las jubilaciones de vejez, invalidez y discapacidad. El nombre de estos conjuntos de datos serán \textit{data\_vej}, \textit{data\_inv} y \textit{data\_dis} para hacer referencia a la información de las jubilaciones de vejez, invalidez y discapacidad respectivamente.

\section{Limpieza de datos}\label{cha_resul:limpieza}

Para alcanzar el objetivo planteado, la limpieza de datos del presente proyecto se divide en dos partes. La primera parte se centra en el proceso de minería de datos para los datos utilizados antes de la ejecución de algoritmos de aprendizaje no supervizado para etiquetar los salarios y a las personas que generarón alguna aportación fraudelenta en función del comportamiento histórtico de los salarios a lo largo de su vida laboral. La seguna parte corresponde al preprocesamiento de la información resultante de los algoritmos no supervizados para su posterior implementación en los métodos supervizados.

\subsection{Datos previos a la aplicación de aprendizaje no supervizado}

Además de considerar las explicaciones dadas en el penúltimo párrafo de la sección \ref{sec:fuentes_datos} de la parte de anexos, es importante mencionar que el conjunto de datos \textit{data\_afi} no va a presentar problemas con missing values ni datos inconsistentes en ningún atributo, debido a que estas novedades ya se resolvieron con anterioridad (desde el comienzo de construcción del dataset original). Por otro parte, las bases de datos de los pensionistas en ciertos atributos sí van a presentar problemas con datos perdidos, como por ejemplo la \textit{FECHA\_MUERTE}\footnote{Debido a que a la fecha de corte no todos los pensionistas están muertos}, \textit{NUMERO\_IMPOSICIONES}\footnote{Debido a que como el sistema del IESS tiene dos fuentes de información (HL Y HOST) algunos regustros no están correctamente migrados}, etc.

El dataset de los afiliados contiene 68.062.270 filas y 12 columnas, el conjunto de datos de los pensionistas de vejez tiene 681.799 filas con 17 columnas, el de invalidez tiene 48.146 filas y 17 columnas  y los datos de discapacidad tiene 14.662 filas y 17 columnas.

\subsection{Datos previos a la aplicación de aprendizaje supervizado}

Una vez obtenida la etiqueta de atipico (valor 1) o no atipico (valor de 0) para los sueldos dentro de los cinco mejores años de los afiliados al IESS tras la implementación de los algoritmos de las secciones \ref{sec:apr_no_sup_cj}, \ref{sec:apr_no_sup_km} y \ref{sec:apr_no_sup_db} se procede a a unir en un único conjunto de datos las variables que serán consideradas en el aprendizaje supervizado. Los atributos son básicamente los mimso que \texit{data_l}, pero se incluyen las variables \textit{ATI\_CJ}\footnote{Para los resultados de cluster jerárquico}, \textit{ATI\_KM}\footnote{Para los resultados de k-means} y \textit{ATI\_DB}\footnote{Para los resultados de dbscan}, cuyos valores son 0 o 1 para identificar si los sueldos son atipicos o no respectivamente. 


\section{Transformación de datos}

\subsection{Datos previos a la aplicación de aprendizaje no supervizado}

Con la finalidad de aliviar el costo computacional, se transforman variables en atributos más sencillos y se crean variables que permitirán alcanzar el objetivo planteado. A manera general, todo el proceso de transformación de datos se describe en la sección \ref{sec:limpieza_datos} de la parte de anexos. Si el lector desea tener una experiencia más didáctica con todo el proceso, puede hacerlo visualizando el archivo  \textit{VIU\_clean\_data.ipynb} de \legalcite{CristianVIUTFM}.

A manera general, en lo que sigue se describen las variables que fueron creadas (para mayor detalle véase sección \ref{sec:limpieza_datos} de la parte de anexos.):

\begin{itemize}
\item SUELDO: Corresponde a la suma de la materia gravada histórica del afiliado hasta el momento de su jubilación, \\[-0.75cm]
\item APORTE: Corresponde a la suma del aporte\footnote{Es la multiplicación entre la materia gravada del afiliado, mes a mes, con el valor de la tasa de aportación. Estos valores se presentan en la tabla \ref{tab:info_tasa_aport_actuarial} de la sección \ref{sec:limpieza_datos} de la parte de anexo.} del afiliado hasta el momento de su jubilación,\\[-0.75cm]
\item INTERES\_APORTE: Corresponde a la suma por concepto del interés\footnote{Corresponde a la multiplicación entre la variable APORTE, mes a mes, con la tasa de interés actuarial. Estos valores se presentan en la tabla \ref{tab:info_tasa_aport_actuarial} de la sección \ref{sec:limpieza_datos} de la parte de anexo.} que genero el aporte del afiliado durante su vida laboral.\\[-0.75cm]
\item FIN\_HL: Corresponde a la fecha de la última planilla genera por concepto de aportes durante a vida laboral del afiliado\\[-0.75cm]
\item INI\_HL: Corresponde a la fecha de la primera planilla genera por concepto de aportes durante a vida laboral del afiliado\\[-0.75cm]
\item MES\_AS: Corresponde al número de meses aportados\footnote{Es el conteo del número de veces no únicos, es decir, si una persona aporte dos o más veces en el mismo mes, se le cuenta dos o más veces} durante la vida laboral del afiliado\\[-0.75cm]
\item MES\_TU: Corresponde al número de meses distintos\footnote{Es el conteo del núemro de meses únicos, es decir, si una persona aportó dos o más veces en el mismo mes, solo se le contabiliza como una vez} aportados durante la vida laboral del afiliado,\\[-0.75cm]
\item  N\_PRI, N\_PUB, N\_IND, N\_VOL\_EX y N\_VOL\_EC: Guardan la información sobre las veces que el afiliado aporte en los sectores Privado, Público, Independiente, Voluntario del Exterior y Voluntario residente del Ecuador respectivamente.

\end{itemize}

En base a los artículos 2 y 13 de la \legalcite{ ResIESS_CD100}, se procede a calcular la base de cálculo. Para esto se crean las variables GRUPO\_SEL\footnote{Es una variable indicatriz, que toma los valores de 1, si para un mes x del año Y, el registro se cuenta para la base de cálculo; 0 caso contrario}, BASE\_CAL\footnote{Es el valor de la Base de Cálculo en concordancia con el artículo 2 de la \legalcite{ResIESS_CD100}}. Adicionalmente, se crean las variables SBU\footnote{Contiene la información del Salario Básico Unificado para los trabajadores del Ecuador}, cuyos valores son los presentes en \cite{bce_salarios}, INI\_CAL y FIN\_CAL que corresponde a las fechas máxima y mínima de la base de calculo respectivamente, y, M\_PRI, M\_PUB, M\_IND, M\_VOL\_EX y M\_VOL\_EC que guardarán la información sobre las veces que el afiliado aporte dentro de sus mejores años de aporte en los sectores Privado, Público, Independiente, Voluntario del Exterior y Voluntario residente del Ecuador respectivamente.

El dataset resultante de este proceso se datos se llamará \textit{data\_l}, mismo que será utilizado para la discriminación de la etiqueta de fraude o no fraude en las aportaciones. Este tabulado contendrá 62.130.167 registros y 16 atributos, que corresponde a  442.570 personas. Adicionalmente, se crean las variables \textit{LS1}, \textit{SAL\_PROM1}, \textit{LS2} y \textit{SAL\_PROM2}, que corresponden al límite superior\footnote{Se define como la suma entre el tercer cuartil + 1,5 veces el rango inter cuartilico } del bigote del diagrama de caja y sueldo promedio para los salarios históricos y a partir del año 2000\footnote{Debido a la crisis ecónomica por la cual atravesaba el Ecuador, a partir del año 2000 el país cambia los Sucres (como moneda nacional)  a dólares estadounidenses como moneda oficial \cite{Ecua_sucre_dolar}} en adelante, respectivamemte. Esta consideración se la realiza debido a que el país cambió su moneda, por lo que, las contribuciones realizadas en sucres y posterior transformación a dólares con la tasa de cambios a esa fecha eran significativamente menores al SBU del año 2000 y así en adelante. En este sentido, se considerarán los valores de las variables \textit{LS2} y \textit{SAL\_PROM2}.



\subsection{Datos previos a la aplicación de aprendizaje supervizado}

Una vez que finalizado el 

\subsection{Tratamiento de valores perdidos}

Como ya se expuso anteriormente, \textit{data\_afi} no contiene valores perdidos. Pero por el contrario \textit{data\_vej}, \textit{data\_inv} y \textit{data\_dis} si va a tener variables con valores perdidos, principalmente en las variables \textit{FECHA\_MUERTE}, \textit{NUMERO\_IMPOSICIONES} pero estos valores son corregidos con los valores del dataset previo a la aplicación de aprendizaje supervizado.

\subsection{Tratamiento de outliers}

La principal variable de interés en \textit{data\_afi} es el \textit{SALARIO},la misma permitirá discriminar si las personas realizaron algún tipo de fraude para obtener un mejor beneficio pensional a largo plazo. En este sentido, no se realiza ninguna corrección de sus valores pues es justamente lo que queremos detectar con los algoritmos de aprendizaje no supervizado.

\section{Aprendizaje no supervizado}

Para la ejecución de los algoritmos de aprendizaje no supervizado se utiliza la base de datos \textit{data\_l}. Los algoritmos utilizados son Clúster Jerárquico\footnote{Se utiliza la métrica single pues es la que ayuda a detectar outlier \cite{Hogde2004}}, K-mean y DBscan, puesto que los mismos permiten realizar la búsqueda de los salarios que son atípicos dentro del comportamiento salarial del afiliado.

\subsection{Clúster jerárquico} \label{sec:apr_no_sup_cj}

La selección de este algoritmo para la detección de atípicos se basa en sus ventajas para identificar la estructura inherente de los datos, lo que permite detectar aquellos que no pertenecen a ningún clúster. Además, proporciona una visión clara de la relación entre los datos atípicos y el resto de los datos mediante el uso de dendrogramas, lo que facilita visualizar las diferencias y relaciones entre ellos, enfocando el análisis hacia la dirección adecuada en este proceso \citep{Hodge2004} .

Para este análisis, solo se considerarán los valores  iguales a uno (1) de la variable \textit{GRUPO\_SEL}, puesto que, estos registros son los meses y años de los cinco (5) mejores años de sueldo. 

Como el algoritmo de Clúster Jerárquico requiere de gran capacidad computacional, se procedió a dividir el dataset \textit{data\_l} en dos grupos. El primer grupo (de nombre \textit{ul}) solo considerará a las personas que durante toda su vida laboral y en un mismo mes realizaron solo una aportación. El número de personas que tienen esta condición es 373.069. El segundo grupo será el complemento del primero (se llamará \textit{ml}) y contiene información de 69.501 personas

Tanto para \textit{ul} como \textit{ml}, se calculó el bigote superior de los sueldos de los cinco mejores años de cada persona, esta variable se llamará \textit{LS\_MS}.

En referencia a la literatura, al utilizar la métrica single en el algoritmo de clúster jerárquico, se pueden detectar registros atípicos, por lo cual, está métrica será la que se va a utilizar en nuestro análisis. El código utilizado es la función \textit{cluster\_jerarquico} del código de la sección \ref{sec:alg_clus_jear} de anexos. La idea general del código es considerar como máximo dos clústeres y dentro de cada uno de ellos realizar el siguiente análisis:

\begin{itemize}
\item Si el número de clústeres que se forman es mayor a 1, se calcula el centroide de cada clúster. Si este valor es mayor a \textit{LS\_MS}, entonces todas las observaciones del clúster serán atípicas y se etiquetarán con el valor de 1. Caso contrario, su etiqueta será 0.
\item Si el  número de clústeres formados es igual a 1, entonces la etiqueta de todos los sueldos será -1, valor que se corregirá después.
\end{itemize}

Los resultados de la aplicación de la función \textit{cluster\_jerarquico}, muestran que hay 123.850 personas con al menos un sueldo atípico y 52.121 personas cuyos sueldos formaron un solo clúster.  A manera de ejemplo, se presentan los siguientes casos.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{graficos/algoritmo_cj_271_1.png}
\caption{\headlinecolor{\underline{Cluster jerárquico: Caso 1}}}
\label{fig:algoritmo_cj_271_1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{graficos/algoritmo_cj_20889867_1.png}
\caption{\headlinecolor{\underline{Cluster jerárquico: Caso -1}}}
\label{fig:algoritmo_cj_271_1}
\end{figure}

La clasificación anterior debe ser corregida debido a que hay sueldos que, el algortimo los clasifica como atípicos, pero por la naturaleza de su valor no deberían serlo. Estos valores recaen sobre los sueldos que son iguales al SBU.

Por otro lado, una segunda correción se realiza a los sueldos que formaron un solo clúster, pues el algoritmo no determinó si en efecto eran o no valores atípicos, por lo que, si un sueldo fue clasificado como -1 y su valor es mayor al mínimo entre \textit{LS2} y \textit{LS\_MS} entonces el valor es atípico. 

Una tercera corrección se hace para los sueldos de la data \textit{ml}, pues aquí la variable sueldo para un mes es la suma de todas las aportaciones que se realizaron en ese mes, por lo tanto, si una de las partes que componen la suma es mayor  al mínimo entre \textit{LS2} y \textit{LS\_MS}, entonces ese sueldo sí es atípico.

En este sentido, en la primera fila de la figura \ref{fig:algoritmo_cj_depu} se muestra la clasificación del algoritmos, y en la segunda, las correccones realizadas en base a lo expuesto con anterioridad. 

En la figura \ref{fig:algoritmo_cj_depu_anex} de la parte de anexos se muestran otros ejemplos.


\begin{landscape}
\begin{figure}[H]  
    \centering
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_8804_2.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_3071_2.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_20857054_2.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_10133_2.png} 
    \end{minipage}
   
   \vfill 
  \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_8804_3.png} 
    \end{minipage}
     \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_3071_3.png}  
        
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_20857054_3.png}  
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_cj_10133_3.png}  
    \end{minipage}

\caption{\headlinecolor{\underline{Resultados de la aplicación del clúster jerárquico para los casos 1 y -1 }}}
\label{fig:algoritmo_cj_depu}  
    
\end{figure}

Como se observa en la gráfica anterior, la corrección es adecuada puesto que, se estarían clasificando como atípicos valores que no lo son.

Para que el lector pueda tener una visión más detallada del proceso, puede revisar el script \textit{VIU\_cluster\_jerarquico.ipynb} de \legalcite{CristianVIUTFM}.

\end{landscape}

\section{K-Means} \label{sec:apr_no_sup_km}

Otro algoritmo que tiene gran potencial para la estimación de valores atípicos es  K-means, destacando por su facilidad de implementación y forma de operar. Este método permite identificar observaciones atípicas de forma más óptima al detectar aquellos puntos que se desvían significativamente de los centroides de los clústeres que se han formado. Así, se localizan las anomalías que se alejan de los patrones de los distintos grupos, siendo una herramienta bastante útil para la detección de outliers \citep{wei2019msd}. 

En este sentido, se sigue un proceso similar a lo expuesto en clúster jerárquico con respecto a las consideraciones para \textit{GRUPO\_SEL}, \textit{data\_l}, \textit{ul}, \textit{ml} y \textit{LS\_MS}. La ejecución de este algoritmo requiere de un tiempo muy extenso de procesamiento, debido a la gran cantidad de datos.

Por otra parte, siguiendo lo expresado en la literatura, este algoritmo se divide en cuatro casos, dos casos para los datos sin y con normalización y otros dos casos para los datos con y sin datos duplicados, esto tiene la finalidad de mejorar la velocidad del procesamiento del algoritmo de K-means conforme lo exponen \cite{K-Means Clustering in Python: Efficiency of Preprocessing} y \cite{AdventuresinMachineLearning}. Con la finalidad de realizar un ejercicio didácico para estimar el número de clústeres que agruparán los salarios de cada persona, se hace una estimación (Véase la función \textit{num\_cluster} del código de la sección \ref{sec:alg_kmean}). Los casos serán abreviados por \textit{ATI\_KM\_M1} para datos con duplicados y sin normalización,  \textit{ATI\_KM\_M2}  para datos sin duplicados y sin normalización,  \textit{ATI\_KM\_M3} para datos con duplicados y  con normalizados; y, \textit{ATI\_KM\_43} para datos sin duplicados y con normalizados

Los métodos que nos servirán para estimar el número de cluster, para los datos de \textit{ul} y \textit{ml}, son por el método del codo y por el método de la silueta.

Para \textit{ul}
\begin{itemize}
\item Caso \textit{ATI\_KM\_M1}.- Método del codo es 2.053 y la silueta de 3.665,
\item Caso \textit{ATI\_KM\_M2}.- Método del codo es 1.677 y la silueta de 2.066,
\item Caso \textit{ATI\_KM\_M3}.- Método del codo es 2.134 y la silueta de 3.558,
\item Caso \textit{ATI\_KM\_M4}.- Método del codo es 1.677 y la silueta de 2.065,
\end{itemize}

Para \textit{ml}
\begin{itemize}
\item Caso \textit{ATI\_KM\_M1}.- Método del codo es 2.223 y la silueta de 3.626,
\item Caso \textit{ATI\_KM\_M2}.- Método del codo es 2.067 y la silueta de 2.532,
\item Caso \textit{ATI\_KM\_M3}.- Método del codo es 2.233 y la silueta de 3.622,
\item Caso \textit{ATI\_KM\_M4}.- Método del codo es 2.066 y la silueta de 2.529,
\end{itemize}

Como se puede apreciar, el número de clústeres toma valores entre 2 y 3 aproximadamente, lo cual va acorde a considerar  que nuestra clasificación  solo  considerará dos (2) clústeres, puesto que, se hace el supuesto que los salarios se agruparán en los clústeres de sin y con atípicos, respectivamente. La función que se utilizará es \textit{clasificacion\_kmean} del código de la sección \ref{sec:alg_kmean}. Es importante notar que, con la finalidad de mejorar la elección inicial de los centroides, se considera el método \textit{k-means++}.

Tras aplicar \textit{clasificacion\_kmean}, tenemos que si el número de clústeres\footnote{Independientemente de considerar que se formen dos clústeres, el algoritmo generaba uno o dos clúster, lo cual dependía del comportamiento de los datos} generados es mayor a 1, se calcula el centroide de cada clúster y si estos valores son mayores a \textit{LS\_MS}  entonces todas las observaciones del clúster serán atípicas, por lo que, su etiqueta será 1. Por otra parte, si el número de clústeres es igual a 1, entonces la etiqueta será igual a -2, puesto que solo se formó un único clúster. Ahora bien, al momento  de considerar o no los valores repetidos, la mayoría de los casos se comportaban como lo que ya se expuso anteriormente. Sin embargo, existían casos en donde al eliminar los duplicados, el promedio de los cinco mejores años era un único valor, por lo cual, cuando se daban estos casos, la etiqueta era -1. Los resultados se presentan en la tabla \ref{tab:resul_kmean_pre}, cuyos valores hacen mención a las personas que al menos tienen un sueldo que corresponde a una categoría  de los cuatro casos anteriores.

\begingroup\scriptsize
\setlength\extrarowheight{1pt}
\setlength\aboverulesep{-0.5pt}
\setlength\belowrulesep{0pt}
\fontsize{7}{8}\selectfont
\begin{longtable}[H]{r|r|r|r|r|r|r|r|r|r|r|r|r } 
\caption{\headlinecolor{\underline{Resultados previos de aplicar k-mean}}}
\label{tab:resul_kmean_pre}\\[-0.1cm]

\toprule
\rowcolor{naranja}
& \multicolumn{12}{c}{\textbf{Clasificación}} \\ \hline

data
& \multicolumn{3}{c|}{\textit{ATI\_KM\_M1}}
& \multicolumn{3}{c|}{\textit{ATI\_KM\_M2}}
& \multicolumn{3}{c|}{\textit{ATI\_KM\_M3}}
& \multicolumn{3}{c}{\textit{ATI\_KM\_M4}}\\ \cmidrule{2-13}

& -2 & -1 & 1
& -2 & -1 & 1
& -2 & -1 & 1
& -2 & -1 & 1 \\\hline


\midrule
\endfirsthead

\toprule
\rowcolor{naranja}
& \multicolumn{12}{c}{\textbf{Clasificación}} \\ \hline

data
& \multicolumn{3}{c|}{\textit{ATI\_KM\_M1}}
& \multicolumn{3}{c|}{\textit{ATI\_KM\_M2}}
& \multicolumn{3}{c|}{\textit{ATI\_KM\_M3}}
& \multicolumn{3}{c}{\textit{ATI\_KM\_M4}}\\ \cmidrule{2-13}

& -2 & -1 & 1
& -2 & -1 & 1
& -2 & -1 & 1
& -2 & -1 & 1 \\\hline


\midrule
\endhead

  \hline \multicolumn{13}{r}{continúa...} \\
  \endfoot

  \bottomrule
  %\caption*{\scriptsize \textbf{Fuente}: Datos administrativos del IESS.\\\textbf{Elaborado}: DAIE.}
  \endlastfoot
  
  ul 
  & 39.768 & 0 & 64.785 
  & 0      & 39.768 & 37.479
  & 39.768 & 0 & 64.795
  & 39.768 & 0 & 37.388 \\\hline
  
  ml 
  & 244 & 0 & 21.635
  & 0      & 244 & 12.984
  & 244 & 0 & 21.639
  &244 & 0 & 12.962 \\


\end{longtable}
\endgroup

Como se puede apreciar en la tabla anterior, practicamente los cuatro casos nos dan la misma clasificación en cantidad de personas, la diferencia solo radica en el tiempo de procesamiento de los resultados, puesto que, cuando se trabajaba con los datos sin normalizar y con duplicados, el tiempo de ejecución era muy elevado en comparación al caso de los datos normalizados y sin duplicados. En los resultados de la aplicación de K-means se deben hacer las mismas correcciones que para el clúster jerárquico.

Una vez realizadas las correcciones respectivas, se procede a crear una variable que considere los cuatro casos y determine la etiqueta de si el sueldo es o no atípico. La regla a utilizar es considerar de las cuatros caso, el máximo de su valor, es decir, si tres variables para un sueldo determinado tienen el valor 0  y en la otra tiene el valor de 1, entonces la etiqueta será 1. Todo esto se realiza a nivel de persona y a nivel de sueldo , considerando los valores de las variables \textit{ATI\_KM\_M1}, \textit{ATI\_KM\_M2}, \textit{ATI\_KM\_M3} y \textit{ATI\_KM\_M4}. El atributo que contiene esta información será llamado \textit{ATI\_KM}.

\begin{landscape}
Los resultados se muestran en la figura \ref{fig:algoritmo_km_depu}.
\begin{figure}[H]  
    \centering
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_km_8804_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_km_3071_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_km_20857054_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_km_10133_1.png} 
    \end{minipage}
   
   \vfill 
  \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_km_20013447_1.png} 
    \end{minipage}
     \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_km_3608_1.png}  
        
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_km_135752_1.png}  
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_km_154409_1.png}  
    \end{minipage}

\caption{\headlinecolor{\underline{Resultados de la aplicación de k-means }}}
\label{fig:algoritmo_km_depu}  
    
\end{figure}



Para que el lector pueda tener una visión más detallada del proceso, puede revisar el script \textit{VIU\_k\_means.ipynb} de \legalcite{CristianVIUTFM}.

\end{landscape}


\section{Dbscan} \label{sec:apr_no_sup_db}

Debido a las desventajas de utilizar K-means al momento de agrupar datos que tienen diferentes tamaños, densidades y forma (forma no globular) se opta por implementar el algoritmo DBSCAN, pues el mismo presenta la capacidad de identificación de clústeres con formas arbitrarias y densidades variables, lo que ayuda a la detección de valores atípicos en datos no homogéneos \citep{boucher2020outlier}. De igual forma, este método, al basarse en la densidad de los datos, es más preciso en la identificación de atípicos locales significativos, debido a su flexibilidad al identificarlos en áreas de menor densidad y su capacidad de manejar el ruido \citep{smiti2020outlier}.

Una vez más, se sigue un proceso similar a lo expuesto en clúster jerárquico con respecto a las consideraciones para \textit{GRUPO\_SEL}, \textit{data\_l}, \textit{ul}, \textit{ml} y \textit{LS\_MS}.

En un ejercicio de determinar los parámetros (MinPts y Eps) que el algoritmo necesita, se implementa la función \textit{valor\_epsilon} de la sección \ref{sec:alg_dbscan} de la parte de anexos. Esta función toma los K-ésismos vecinos más cercanos en un rango de 1 a 12\footnote{Se considera este valor  debido a que se esperaría que los 12 meses de aporte de un grupo de los mejores años tengan el mismo comportamiento} (MinPts) y determina el valor de \textit{epsilon} a través del método del codo. Si todas las distancias dadas por los k-esimos vecinos tienen el mismo valor, entonces el valor de \textit{epsilon} (Eps) es cero, puesto que se estará en el caso de un mismo valor de sueldo para los mejores años de sueldo. Con la función \textit{esti\_eps\_out} para un rango de valores de Eps, dados por MinPts, se calcula el número de cluster y de atípicos generados por DBSCAN.

El proceso anterior nos da resultados para varias combinaciones de valores, por lo que, la función \textit{cal\_eps\_out} de la sección \ref{sec:alg_dbscan}, determiná los valores de Eps y MinPts  con los cuales se va a aplicar el algoritmo de DBSCAN, haciendo la consideración de que la selección abarque la mayor cantidad de valores atípicos con la menor cantidad de cluster. Bajo esta criterio tenemos que en \textit{ul} existen 316.552 personas con alguno registro de suledo atípico y en \textit{ml} existen 68.596 personas con tienen al menos una aportación atípica.

Nuevamente es neceario hacer las correcciones indicadas en los dos métodos anteriores, por lo que, una vez realizas las correcciones, enb la figura \ref{fig:algoritmo_db_depu} se muestran los resultados.

Para que el lector pueda tener una visión más detallada del proceso, puede revisar el script \textit{VIU\_dbscan.ipynb} de \legalcite{CristianVIUTFM}.

\begin{landscape}

\begin{figure}[H]  
    \centering
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_8804_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_3071_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_20857054_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_10133_1.png} 
    \end{minipage}
   
   \vfill 
  \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_20013447_1.png} 
    \end{minipage}
     \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.19]{graficos/algoritmo_db_3608_1.png}  
        
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_135752_1.png}  
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_154409_1.png}  
    \end{minipage}

\caption{\headlinecolor{\underline{Clasificación de DBSCAN }}}
\label{fig:algoritmo_db_clasi}  
 \vfill
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_ati_8804_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_ati_3071_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_ati_20857054_1.png} 
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_ati_10133_1.png} 
    \end{minipage}
   
   \vfill 
  \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_ati_20013447_1.png} 
    \end{minipage}
     \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_ati_3608_1.png}  
        
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_ati_135752_1.png}  
    \end{minipage}
    \hfill  %
    \begin{minipage}{0.35\textwidth}
        \centering
        \includegraphics[scale=0.17]{graficos/algoritmo_db_ati_154409_1.png}  
    \end{minipage}

\caption{\headlinecolor{\underline{Resultados de la aplicación de DBSCAN}}}
\label{fig:algoritmo_db_depu}  
    
\end{figure}


\end{landscape}

