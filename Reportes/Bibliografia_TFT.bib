@book{ SS_OIT,
  author = {Humblet, M and Silva, R},
  year = {2002},
  title = {Normas para el siglo XXI: Seguridad social.},
  publisher = {Organización Internacional del Trabajo}
}

@book{coip_2014,
shorttitle = {{Código Orgánico Integral Penal de la República del Ecuador}},
  title     = {Código Orgánico Integral Penal},
  author    = {Asamblea Nacional del Ecuador},
  year      = {2014},
  publisher = {Registro Oficial},
  address   = {Quito},
  note      = {Suplemento N° 180, 10 de febrero de 2014}
}

@legislation{ConsEcu:2008,
  shorttitle = {{Constitución de la República del Ecuador}},
  title = {{Constitución de la República del Ecuador}},
  author = {{Asamblea Constituyente de la República del Ecuador}},
  publisher = {{Constitución de la República del Ecuador}},
  series = {{Registro Oficial, 449}},
  year = {2008},
  date = {2008-10-20},
  address = {Quito}
}

@legislation{LeySS,
  shorttitle = {{Ley de Seguridad Social}},
  title = {{Ley de Seguridad Social}},
  author = {{Congreso Nacional del Ecuador}},
  publisher = {{Congreso Nacional del Ecuador}},
  series = {{Suplemento del Registro Oficial, 465}},
  year = {2001},
  date = {2001-11-30},
  address = {Quito},
  note = {{(Incluidas todas las reformas vigentes.)}}
}

@book{iessboletin2022,
  shorttitle = {{Boletín estadístico No. 27}},
  title     = {{Boletín estadístico No. 27}},
  author    = {{Instituto Ecuatoriano de Seguridad Social}},
  publisher = {Instituto Ecuatoriano de Seguridad Social},
  year      = {2022},
  url       = {https://www.iess.gob.ec/documents/10162/8421754/08_BOLETIN_ESTADISTICO_27_2022}
}

@book{ iessivm2020,
  shorttitle = {{Valuación Actuarial IVM, DAIE}},
  title = {{Valuación Actuarial del Seguro Vejez, Invalidez y Muerte del Seguro General Obligatorio}},
  author = {{Instituto Ecuatoriano de Seguridad Social}},
  publisher = {Instituto Ecuatoriano de Seguridad Social},
  year = {2020},
  date = {2020-09-16},
  address = {Quito, Ecuador}
}

@legislation{ ResIESS_CD656,
  shorttitle = {{Resolución No. C.D. 656}},
  title = {{Resolución No. C.D. 656, Reformar la Resolución No. C.D. 625 de 31 de Diciembre de 2020, que expidió el Reglamento de Aseguramiento, Recaudación y Gestión de Cartera del IESS, Libro I}},
  author = {{Consejo Directivo del IESS}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social, IESS}},
  year = {2023},
  date = {2023-04-04},
  address = {Quito}
}

@legislation{ ResIESS_CD100,
  shorttitle = {{Resolución No. C.D. 100}},
  title = {{Resolución No. C.D. 100, Reglamento Interno del Régimen de Transición del Seguro de 
  Invalidez, Vejez y Muerte}},
  author = {{Consejo Directivo del IESS}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social, IESS}},
  series = {{Registro Oficial No. 225}},
  year = {2006},
  date = {2006-03-09},
  address = {Quito}
}

@report{ILO:2001,
  author       = {{Organización Internacional del Trabajo}},
  title        = {Seguridad social: Un nuevo consenso},
  year         = {2001},
  institution  = {Organización Internacional del Trabajo},
  url          = {https://webapps.ilo.org/public/spanish/standards/relm/ilc/ilc89/pdf/rep-vi.pdf},
  note         = {Informe VI de la Conferencia Internacional del Trabajo, 89ª Reunión},
}

@report{UN:2019,
  author       = {{United Nations, Department of Economic and Social Affairs, Population Division}},
  title        = {World Population Prospects 2019: Highlights},
  year         = {2019},
  institution  = {United Nations},
  url          = {https://population.un.org/wpp/publications/files/wpp2019_highlights.pdf},
  note         = {ST/ESA/SER.A/423},
}

@online{ CristianVIUTFM,
  shorttitle = {{Repositorio Github-Trabajo de Fin de máster-VIU\_TFM}},
  title = {{Repositorio Github-Trabajo de Fin de máster-VIU\_TFM}},
  author = {Cristian Guatemal },
  year = {2024},
  url = {https://github.com/cristianguatemalwork/VIU_TFM}
}

@legislation{ ResIESS_CI150,
  shorttitle = {{Resolución No. C.I. 150}},
  title = {{Resolución No. C.I. 150}},
  author = {{Comisión Interventora}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social}},
  year = {2003},
  date = {2003-01-21},
  address = {Quito}
}

@legislation{ ResIESS_CD081,
  shorttitle = {{Resolución No. C.D. 081}},
  title = {{Resolución No. C.D. 081}},
  author = {{Consejo Directivo del IESS}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social}},
  year = {2005},
  date = {2005-10-13},
  address = {Quito}
}

@legislation{ ResIESS_CD501,
  shorttitle = {{Resolución No. C.D. 501}},
  title = {{Resolución No. C.D. 501, Consolidación de tablas de distribución de las tasas de 
  aportación al IESS}},
  author = {{Consejo Directivo del IESS}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social}},
  series = {{Registro Oficial No. 703}},
  year = {2016},
  date = {2016-03-02},
  address = {Quito}
}

@legislation{ ResIESS_CD515,
  shorttitle = {{Resolución No. C.D. 515}},
  title = {{Resolución No. C.D. 515, Reglamento para la aplicación de la cesantía y seguro de 
  desempleo}},
  author = {{Consejo Directivo del IESS}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social, IESS}},
  series = {{Registro Oficial No. 794}},
  year = {2016},
  date = {2016-06-11},
  address = {Quito}
}

@legislation{ ResIESS_CD609,
  shorttitle = {{Resolución No. C.D. 609}},
  title = {{Prima para el Financiamiento de las Décimas Tercera y Cuarta Remuneración y Auxilios 
  Funerales para cubrir el aporte que dejo de percibir del 2,76\% que realizaban los Pensionistas y 
  el Seguro de Desempleo.}},
  author = {{Consejo Directivo del IESS}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social, IESS}},
  series = {{}},
  year = {2020},
  date = {2020-09-19},
  address = {Quito}
}

@legislation{ ResIESS_CI141,
  shorttitle = {{Resolución No. C.I. 141}},
  title = {{Resolución No. C.I. 141}},
  author = {{Consejo Interventora}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social}},
  series = {{}},
  year = {2002},
  date = {2002-07-16},
  address = {Quito}
}  

@legislation{ ResIESS_CD459,
  shorttitle = {{Resolución No. C.D. 459}},
  title = {{Resolución No. C.D. 459, Responsabilidad de la actualización de las tablas biométricas; 
  y, la tasa actuarial, Vejez y Muerte}},
  author = {{Consejo Directivo del IESS}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social}},
  series = {{Registro Oficial No. 113}},
  year = {2013},
  date = {2013-10-31},
  address = {Quito}
}

@legislation{ ResIESS_CD596,
  shorttitle = {{Resolución No. C.D. 596}},
  title = {{Resolución No. C.D. 596}},
  author = {{Consejo Directivo del IESS}},
  publisher = {{Instituto Ecuatoriano de Seguridad Social}},
  series = {{Edición Especial del Registro Oficial No. 175}},
  year = {2020},
  date = {2020-04-02},
  address = {Quito}
}

@online{bce_salarios,
  author       = {{Banco Central del Ecuador}},
  title        = {Menú Salarios - Banco Central del Ecuador},
  year         = {2024},
  url          = {https://contenido.bce.fin.ec/documentos/Administracion/bi_menuSalarios.html},
  note         = {Accedido: 2024-10-3}
}

@article{Ecua_sucre_dolar,
  author = {Jameson, Kenneth},
  year = {2004},
  month = {06},
  pages = {},
  title = {Dollarization in Ecuador: A Post-Keynesian Institutionalist Analysis} 
}

@online{git_ver,
  author = {{Git Documentation}},
  title = {Git - Distributed Version Control System},
  year = {2024},
  url = {https://git-scm.com/},
  note = {Accedido: 2024-10-13}
}

@online{github2024,
  author = {{GitHub Documentation}},
  title = {About GitHub and Git},
  year = {2024},
  url = {https://docs.github.com/es/get-started/start-your-journey/about-github-and-git},
  note = {Accedido: 2024-10-13}
}

@article{scikit_learn_kmeans,
  author = {Scikit-Learn},
  title = {K-Means Clustering in Python: Efficiency of Preprocessing},
  journal = {Scikit-Learn Documentation},
  year = {2023},
  url = {https://scikit-learn.org/stable/modules/clustering.html#k-means}
}

@online{AdventuresinMachineLearning,
  title = {The Importance of Clean and Precise Data: Removing Duplicates with Pandas},
  author = {{Adventures in Machine Learning}},
  year = {2024},
  url = {https://www.adventuresinmachinelearning.com/the-importance-of-clean-and-precise-data-removing-duplicates-with-pandas/},
  note = {Accedido: 2024-10-07}
}

@thesis{tesis_guatemal_epn,
  author    = {Cristian Guatemal },
  title     = {Comparaciones de perfiles de salud de individuos sanos en diferentes sectores económicos},
  school    = {Escuela Politécnica Nacional},
  year      = {2019},
  address   = {Quito, Ecuador},
  url       = {https://bibdigital.epn.edu.ec/handle/15000/20478}
}

@book{texbook,
  author = {Donald E. Knuth},
  year = {1986},
  title = {The {\TeX} Book},
  publisher = {Addison-Wesley Professional}
}

@book{latex:companion,
  author = {Mittelbach, Frank and Gossens, Michel 
            and Braams, Johannes and Carlisle, David
            and Rowley, Chris},
  year = {2004},
  title = {The {\LaTeX} Companion},
  publisher = {Addison-Wesley Professional},
  edition = {2}
}

@book{latex2e,
  author = {Lamport, Leslie},
  year = {1994},
  title = {{\LaTeX}: a Document Preparation System},
  publisher = {Addison Wesley},
  address = {Massachusetts},
  edition = {2}
}

@article{knuth:1984,
  title={Literate Programming},
  author={Donald E. Knuth},
  journal={The Computer Journal},
  volume={27},
  number={2},
  pages={97--111},
  year={1984},
  publisher={Oxford University Press}
}

@inproceedings{lesk:1977,
  title={Computer Typesetting of Technical Journals on {UNIX}},
  author={Lesk, Michael and Kernighan, Brian},
  booktitle={Proceedings of American Federation of
             Information Processing Societies: 1977
             National Computer Conference},
  pages={879--888},
  year={1977},
  address={Dallas, Texas}
}

@Inbook{ElNaqa2015,
author="El Naqa, Issam
and Murphy, Martin J.",
editor="El Naqa, Issam
and Li, Ruijiang
and Murphy, Martin J.",
title="What Is Machine Learning?",
bookTitle="Machine Learning in Radiation Oncology: Theory and Applications",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="3--11",
abstract="Machine learning is an evolving branch of computational algorithms that are designed to emulate human intelligence by learning from the surrounding environment. They are considered the working horse in the new era of the so-called big data. Techniques based on machine learning have been applied successfully in diverse fields ranging from pattern recognition, computer vision, spacecraft engineering, finance, entertainment, and computational biology to biomedical and medical applications. More than half of the patients with cancer receive ionizing radiation (radiotherapy) as part of their treatment, and it is the main treatment modality at advanced stages of local disease. Radiotherapy involves a large set of processes that not only span the period from consultation to treatment but also extend beyond that to ensure that the patients have received the prescribed radiation dose and are responding well. The degrees of the complexity of these processes can vary and may involve several stages of sophisticated human-machine interactions and decision making, which would naturally invite the use of machine learning algorithms into optimizing and automating these processes including but not limited to radiation physics quality assurance, contouring and treatment planning, image-guided radiotherapy, respiratory motion management, treatment response modeling, and outcomes prediction. The ability of machine learning algorithms to learn from current context and generalize into unseen tasks would allow improvements in both the safety and efficacy of radiotherapy practice leading to better outcomes.",
isbn="978-3-319-18305-3",
doi="10.1007/978-3-319-18305-3_1",
url="https://doi.org/10.1007/978-3-319-18305-3_1"
}

@book{geron2023hands,
  title = {Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow},
  author = {Aurélien Géron},
  year = {2023},
  edition = {3rd},
  publisher = {O'Reilly Media},
  address = {Sebastopol, CA},
  isbn = {978-1-098-12597-4}
}

@incollection{alloghani2020systematic,
  title={A systematic review on supervised and unsupervised machine learning algorithms for data science},
  author={Alloghani, M. and Al-Jumeily, D. and Mustafina, J. and Hussain, A. and Al-Jaaf, A. J.},
  booktitle={Supervised and unsupervised learning for data science},
  pages={3--21},
  year={2020}
}


@article{naeem2023unsupervised,
  title={An Unsupervised Machine Learning Algorithms: Comprehensive Review},
  author={Naeem, Samreen and Ali, Aqib and Anam, Sania and Ahmed, Muhammad Munawar},
  journal={International Journal of Computing and Digital Systems},
  volume={13},
  number={1},
  pages={911--921},
  year={2023},
  doi={10.12785/ijcds/130172},
  url={http://journals.uob.edu.bh},
  publisher={University of Bahrain}
}

@inproceedings{kanagala2016comparative,
shorttitle={{A comparative study of K-means, DBSCAN, and OPTICS}},
  title={{A comparative study of K-means, DBSCAN, and OPTICS}},
  author={Kanagala, Hari Krishna and Jaya Rama Krishnaiah, V. V.},
  booktitle={{2016 International Conference on Computer Communication and Informatics (ICCCI)}},
  pages={1--5},
  year={2016},
  organization={IEEE},
  doi={10.1109/ICCCI.2016.7479992}
}

@article{shetty2021hierarchical,
  title={Hierarchical Clustering: A Survey},
  author={Shetty, Pranav and Singh, Suraj},
  year={2021},
  journal={ResearchGate},
  url={https://www.researchgate.net/publication/351076785_Hierarchical_Clustering_A_Survey}
}

@techreport{unnoba2020tratamiento,
  title = {Tratamiento Masivo de Datos Utilizando Técnicas de Machine Learning},
  author = {{Universidad Nacional del Noroeste de la Provincia de Buenos Aires (UNNOBA)}},
  year = {2020},
  institution = {Universidad Nacional del Noroeste de la Provincia de Buenos Aires (UNNOBA)},
  url = {https://repositorio.unnoba.edu.ar/xmlui/bitstream/handle/23601/107/1_resource.pdf?sequence=1&isAllowed=y}
}

@ARTICLE{9314060,
  author={Zhang, Shichao},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Challenges in KNN Classification}, 
  year={2022},
  volume={34},
  number={10},
  pages={4663-4675},
  keywords={Training;Nearest neighbor methods;Data mining;Prediction algorithms;Training data;Partitioning algorithms;Licenses;Data mining;lazy learning;KNN classification;classification rule},
  doi={10.1109/TKDE.2021.3049250}}

@article{kingsford2008decisiontrees,
  title = {What are decision trees?},
  author = {Kingsford, Carl and Salzberg, Steven},
  journal = {Nature Biotechnology},
  volume = {26},
  pages = {1011--1013},
  year = {2008},
  doi = {10.1038/nbt0908-1011}
}

@incollection{SUTTON2005303,
title = {11 - Classification and Regression Trees, Bagging, and Boosting},
editor = {C.R. Rao and E.J. Wegman and J.L. Solka},
series = {Handbook of Statistics},
publisher = {Elsevier},
volume = {24},
pages = {303-329},
year = {2005},
booktitle = {Data Mining and Data Visualization},
issn = {0169-7161},
doi = {10.1016/S0169-7161(04)24011-1},
url = {https://www.sciencedirect.com/science/article/pii/S0169716104240111},
author = {Clifton D. Sutton},
abstract = {Publisher Summary
This chapter discusses tree-based classification and regression, as well as bagging and boosting. It introduces some general information of the methods and describes how the methods work. Tree-structured classification and regression are alternative approaches to classification and regression that are not based on assumptions of normality and user-specified model statements, as are some older methods such as discriminant analysis and ordinary least squares regression. Tree-structured classification and regression are nonparametric computationally intensive methods that have greatly increased in popularity during the past several years. They can be applied to data sets having both a large number of cases and a large number of variables, and they are extremely resistant to outliers. Bagging and boosting are general techniques for improving prediction rules. They can be applied to tree-based methods to increase the accuracy of the resulting predictions, although it should be emphasized that they can be used with methods other than tree-based methods, such as neural networks.}
}


@INPROCEEDINGS{8123782,
  author={Awoyemi, John O. and Adetunmbi, Adebayo O. and Oluwadare, Samuel A.},
  booktitle={2017 International Conference on Computing Networking and Informatics (ICCNI)}, 
  shorttitle={Credit card fraud detection using machine learning techniques: A comparative analysis}, 
  title={Credit card fraud detection using machine learning techniques: A comparative analysis}, 
  year={2017},
  volume={},
  number={},
  pages={1-9},
  keywords={Credit cards;Logistics;Support vector machines;Decision trees;Data mining;Bayes methods;Neural networks;credit card fraud;data mining;naïve bayes;decision tree;logistic regression;comparative analysis},
  doi={10.1109/ICCNI.2017.8123782}}

@INPROCEEDINGS{8717766,
  author={Varmedja, Dejan and Karanovic, Mirjana and Sladojevic, Srdjan and Arsenovic, Marko and Anderla, Andras},
  booktitle={2019 18th International Symposium INFOTEH-JAHORINA (INFOTEH)}, 
  title={Credit Card Fraud Detection - Machine Learning methods}, 
  shorttitle={Credit Card Fraud Detection - Machine Learning methods}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  keywords={Credit cards;Classification algorithms;Machine learning algorithms;Companies;Radio frequency;Neural networks;Machine learning;Fraud;Logistic Regression;Multilayer Perceptron;Naive Bayes;Random Forest},
  doi={10.1109/INFOTEH.2019.8717766}}

@INPROCEEDINGS{9103880,
  author={Zhang, Yixuan and Tong, Jialiang and Wang, Ziyi and Gao, Fengqiang},
  booktitle={2020 International Conference on Computer Engineering and Application (ICCEA)}, 
  title={Customer Transaction Fraud Detection Using Xgboost Model}, 
  shorttitle={Customer Transaction Fraud Detection Using Xgboost Model}, 
  year={2020},
  volume={},
  number={},
  pages={554-558},
  keywords={Forestry;Data mining;Logistics;Task analysis;Support vector machines;Vegetation;Feature extraction;Fraud detection;Xgboost;Binary classification;Data Mining},
  doi={10.1109/ICCEA50009.2020.00122}}

@article{aibar2012fraude,
shorttitle={La lucha contra el fraude en el ingreso de recursos de la Seguridad Social},
  title={La lucha contra el fraude en el ingreso de recursos de la Seguridad Social},
  author={Aibar Bernad, Javier},
  journal={Revista Técnica de Seguridad Social},
  number={351},
  pages={97--122},
  year={2012},
  publisher={CEF}
}

@article{Rodriguez1999,
shorttitle = {Incrementos injustificados de las bases de cotización ante la proximidad de la jubilación},
  title = {Incrementos injustificados de las bases de cotización ante la proximidad de la jubilación},
  author = {Javier Rodríguez Gutiérrez},
  journal = {Estudios de Deusto},
  volume = {47},
  number = {2},
  pages = {151-169},
  year = {1999},
  month = {julio-diciembre},
  publisher = {Universidad de Deusto},
}

@book{moreno2023manual,
  title={Manual pr{\'a}ctico de inteligencia artificial en entornos sanitarios},
  author={Moreno, Emilia Cond{\'e}s and Sanz, Julo Bonis},
  year={2023},
  publisher={Elsevier Health Sciences}
}

@article{flores2018revision,
  title={Revisión de algoritmos para la detección de valores atípicos},
  shorttitle={Revisión de algoritmos para la detección de valores atípicos},
  author={Flores Urgiles, Cristina Mariuxi and Ortiz Amoroso, Martin Sebastian},
  journal={Revista Killkana Técnica},
  volume={2},
  number={1},
  pages={19--26},
  year={2018},
  publisher={Universidad Católica de Cuenca},
  doi={10.26871/killkana_tecnica.v2i1.287},
  issn={2528-8024},
  issn_e={2588-0888}
}

@mastersthesis{boucher2020outlier,
  title={Outlier Detection Methods Applied to Financial Fraud},
  shorttitle={Outlier Detection Methods Applied to Financial Fraud},
  author={Boucher, Églantine},
  school={Lund University},
  year={2020},
  type={Master's thesis},
  note={LU-CS-EX: 2020-62},
  url={https://lup.lub.lu.se/student-papers/record/9006357},
  supervisor={Pierre Nugues},
  examiner={Jörn Janneck}
}

@article{smiti2020outlier,
  title={A critical overview of outlier detection methods},
  shorttitle={A critical overview of outlier detection methods},
  author={Smiti, Abir},
  journal={Computer Science Review},
  volume={38},
  pages={100306},
  year={2020},
  publisher={Elsevier},
  doi={10.1016/j.cosrev.2020.100306}
}

@inproceedings{Pamula2011,
  author    = {Rajendra Pamula and Jatindra Kumar Deka and Sukumar Nandi},
  title     = {An Outlier Detection Method Based on Clustering},
  shorttitle     = {An Outlier Detection Method Based on Clustering},
  booktitle = {2011 Second International Conference on Emerging Applications of Information Technology},
  year      = {2011},
  pages     = {253-256},
  doi       = {10.1109/EAIT.2011.25},
  publisher = {IEEE},
}

@article{perols2011,
  author    = {Johan Perols},
  title     = {Financial Statement Fraud Detection: An Analysis of Statistical and Machine Learning Algorithms},
  shorttitle     = {Financial Statement Fraud Detection: An Analysis of Statistical and Machine Learning Algorithms},
  journal   = {AUDITING: A Journal of Practice \& Theory},
  volume    = {30},
  number    = {2},
  pages     = {19-50},
  year      = {2011},
  month     = {May},
  abstract  = {This study compares the performance of six popular statistical and machine learning models in detecting financial statement fraud under different assumptions of misclassification costs and ratios of fraud firms to nonfraud firms. The results show, somewhat surprisingly, that logistic regression and support vector machines perform well relative to an artificial neural network, bagging, C4.5, and stacking. The results also reveal some diversity in predictors used across the classification algorithms. Out of 42 predictors examined, only six are consistently selected and used by different classification algorithms: auditor turnover, total discretionary accruals, Big 4 auditor, accounts receivable, meeting or beating analyst forecasts, and unexpected employee productivity. These findings extend financial statement fraud research and can be used by practitioners and regulators to improve fraud risk models. Data Availability: A list of fraud companies used in this study is available from the author upon request. All other data sources are described in the text.},
  issn      = {0278-0380},
  doi       = {10.2308/ajpt-50009},
  url       = {https://doi.org/10.2308/ajpt-50009},
}

@article{batista2004balancing,
shorttitle={A study of the behavior of several methods for balancing machine learning training data},
  title={A study of the behavior of several methods for balancing machine learning training data},
  author={Batista, Gustavo and Prati, Ronaldo and Monard, Maria Carolina},
  journal={ACM SIGKDD Explorations Newsletter},
  volume={6},
  number={1},
  pages={20--29},
  year={2004},
  publisher={ACM New York, NY, USA}
}

@article{Koul2018,
  title={Cross-Validation Approaches for Replicability in Psychology},
  author={Koul, Atesh and Becchio, Cristina and Cavallo, Andrea},
  journal={Frontiers in Psychology},
  volume={9},
  pages={1117},
  year={2018},
  publisher={Frontiers Media SA},
  doi={10.3389/fpsyg.2018.01117},
  url={https://www.frontiersin.org/articles/10.3389/fpsyg.2018.01117/full}
}

@article{yuan2019kvalue,
shorttitle={Research on {K-Value} Selection Method of {K-Means} Clustering Algorithm},
  title={Research on {K-Value} Selection Method of {K-Means} Clustering Algorithm},
  author={Yuan, Chunhui and Yang, Haitao},
  journal={Journal of Open Innovation: Technology, Market, and Complexity},
  volume={2},
  number={2},
  pages={226--235},
  year={2019},
  doi={10.3390/j2020016},
  url={http://www.mdpi.com/2571-8800/2/2/16}
}


@misc{wiskott2009pca,
  author       = {Laurenz Wiskott},
  title        = {Lecture Notes on Principal Component Analysis},
  year         = {2009},
  revision     = {21 February 2013},
  note         = {Institut für Neuroinformatik, Ruhr-Universität Bochum},
  url          = {http://www.ini.rub.de/PEOPLE/wiskott/},
}

@article{natekin2013gradient,
  title={Gradient boosting machines, a tutorial},
  author={Natekin, Alexey and Knoll, Alois},
  journal={Frontiers in neurorobotics},
  volume={7},
  pages={21},
  year={2013},
  publisher={Frontiers},
  doi={10.3389/fnbot.2013.00021}
}

@inproceedings{8906396,
  author    = {Najmeddine Dhieb and Hakim Ghazzai and Hichem Besbes and Yehia Massoud},
  booktitle = {2019 IEEE International Conference on Vehicular Electronics and Safety (ICVES)},
  title     = {Extreme Gradient Boosting Machine Learning Algorithm for Safe Auto Insurance Operations},
  year      = {2019},
  pages     = {1-5},
  keywords  = {Data analysis; Auto Insurance; Fraud Detection; Machine Learning; XGBoost},
  doi       = {10.1109/ICVES.2019.8906396}
}


@techreport{Ali2014,
  author    = {{Peshawa J. Muhammad Ali and Rezhna H. Faraj}},
  shorttitle     = {{Data Normalization and Standardization: A Technical Report}},
  title     = {{Data Normalization and Standardization: A Technical Report}},
  institution = {{The Machine Learning Lab. at Koya University}},
  address   = {Koya, Erbil, Iraq},
  year      = {2014},
  journal   = {Machine Learning Technical Reports},
  volume    = {1},
  number    = {1},
  pages     = {1-6},
  url       = {https://docs.google.com/document/d/1x0A1nUz1WWtMCZb5oVzF0SVMY7a_58KQulqQVT8LaVA/edit#}
}

@article{aribido2021self,
  author    = {Oluwaseun Joseph Aribido and Ghassan AlRegib and Yazeed Alaudah},
  title     = {Self-Supervised Delineation of Geological Structures using Orthogonal Latent Space Projection},
  journal   = {Geophysics},
  volume    = {86},
  number    = {6},
  year      = {2021},
}

@misc{towardsdatascience_kmeans,
  title = {K-Means: A Complete Introduction},
  author = {Jeffares Alan},
  year = {2019},
  url = {https://towardsdatascience.com/k-means-a-complete-introduction-1702af9cd8c},
  note = {Accessed: 2024-10-07}
}

@misc{iess2024web,
  author       = {{Instituto Ecuatoriano de Seguridad Social}},
  title        = {Jubilación Ordinaria por Vejez},
  year         = {2024},
  url          = {https://iess.gob.ec/es/web/guest/jubilacion-ordinaria-vejez}
}

@manual{meyer2009svm,
  title        = {Support Vector Machines: The Interface to libsvm in package e1071},
  author       = {David Meyer},
  organization = {Technische Universität Wien, Austria},
  year         = {2009},
  month        = {January},
  note         = {Available at: http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.ps.gz}
}

@article{FAWCETT2006861,
title = {An introduction to ROC analysis},
shorttitle = {An introduction to ROC analysis},
journal = {Pattern Recognition Letters},
volume = {27},
number = {8},
pages = {861-874},
year = {2006},
note = {ROC Analysis in Pattern Recognition},
issn = {0167-8655},
doi = {10.1016/j.patrec.2005.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S016786550500303X},
author = {Tom Fawcett},
keywords = {ROC analysis, Classifier evaluation, Evaluation metrics},
abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.}
}

@article{opthip,
author = {Bergstra, James and Bengio, Yoshua},
title = {Random search for hyper-parameter optimization},
shorttitle = {Random search for hyper-parameter optimization},
year = {2012},
issue_date = {3/1/2012},
publisher = {JMLR.org},
volume = {13},
number = {null},
issn = {1532-4435},
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent "High Throughput" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
journal = {J. Mach. Learn. Res.},
month = feb,
pages = {281–305},
numpages = {25},
keywords = {deep learning, global optimization, model selection, neural networks, response surface modeling}
}

@article{Hodge2004,
  title = {A Survey of Outlier Detection Methodologies},
  shorttitle = {A Survey of Outlier Detection Methodologies},
  author = {Victoria Hodge and Jim Austin},
  journal = {Artificial Intelligence Review},
  volume = {22},
  number = {2},
  pages = {85--126},
  year = {2004},
  doi = {10.1023/B:AIRE.0000045502.10941.a9},
  url = {https://doi.org/10.1023/B:AIRE.0000045502.10941.a9},
  issn = {1573-7462}
}

@article{orellana2020deteccion,
  title = {Detección de valores atípicos con técnicas de minería de datos y métodos estadísticos},
  author = {Marcos Orellana and Priscila Cedillo},
  journal = {Enfoque UTE},
  volume = {11},
  number = {1},
  pages = {56--67},
  year = {2020},
  doi = {10.29019/enfoqueute.v11n1.471},
  url = {http://ingenieria.ute.edu.ec/enfoqueute/},
  issn = {1390-6542},
  publisher = {Universidad UTE}
}

@misc{wei2019msd,
  title={MSD-Kmeans: A Novel Algorithm for Efficient Detection of Global and Local Outliers},
  author={Yuanyuan Wei and Julian Jang-Jaccard and Fariza Sabrina and Timothy McIntosh},
  year={2019},
  eprint={1910.06588},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@article{he2018random,
  title={Random Forest as a Predictive Analytics Alternative to Regression in Institutional Research},
  author={He, Lingjun and Levine, Richard A. and Fan, Juanjuan and Beemer, Joshua and Stronach, Jeanne},
  journal={Practical Assessment, Research \& Evaluation},
  volume={23},
  number={1},
  year={2018},
  publisher={Practical Assessment, Research \& Evaluation},
  url={http://pareonline.net/getvn.asp?v=23&n=1}
}

@article{evolutionary_bagging_2022,
  title={Evolutionary Bagging for Ensemble Learning},
  author={Jiang, Tao and Xu, Lin and Zhang, Xiaofeng},
  journal={arXiv preprint arXiv:2208.02400},
  year={2022},
  url={https://arxiv.org/abs/2208.02400}
}

@article{syriopoulos2023knn,
  title={kNN Classification: a review},
  author={Syriopoulos, Panos K. and Kalampalikis, Nektarios G. and Kotsiantis, Sotiris B. and Vrahatis, Michael N.},
  journal={Annals of Mathematics and Artificial Intelligence},
  year={2023},
  doi={10.1007/s10472-023-09882-x}
}

@article{lecun2015,
  author    = {Yann LeCun and Yoshua Bengio and Geoffrey Hinton},
  title     = {Deep learning},
  journal   = {Nature},
  volume    = {521},
  pages     = {436--444},
  year      = {2015},
  publisher = {Macmillan Publishers Limited},
  doi       = {10.1038/nature14539}
}

@article{fayyad1996kdd,
  title={From Data Mining to Knowledge Discovery in Databases},
  author={Fayyad, Usama and Piatetsky-Shapiro, Gregory and Smyth, Padhraic},
  journal={AI Magazine},
  volume={17},
  number={3},
  pages={37--54},
  year={1996},
  publisher={American Association for Artificial Intelligence}
}

@misc{oit_sostenibilidad_2021,
  title     = {Guía para evaluar la sostenibilidad de los proyectos de la OIT},
  author    = {OIT},
  year      = {2021},
  url       = {https://www.ilo.org}
}

@misc{oit_pisos_2024,
  author       = {OIT},
  title        = {Fortalecimiento de la protección social en Ecuador: Hacia pisos de protección social},
  year         = {2024},
  url          = {https://www.ilo.org/es/fortalecimiento-de-la-proteccion-social-en-ecuador#pisos}
}

@article{ROUSSEEUW198753,
title = {Silhouettes: A graphical aid to the interpretation and validation of cluster analysis},
journal = {Journal of Computational and Applied Mathematics},
volume = {20},
pages = {53-65},
year = {1987},
issn = {0377-0427},
doi = {10.1016/0377-0427(87)90125-7},
url = {https://www.sciencedirect.com/science/article/pii/0377042787901257},
author = {Peter J. Rousseeuw},
keywords = {Graphical display, cluster analysis, clustering validity, classification},
abstract = {A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects lie well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an ‘appropriate’ number of clusters.}
}

@manual{Python2024,
  title        = {Python Documentation},
  author       = {{Python Software Foundation}},
  year         = {2024},
  url          = {https://docs.python.org/3/},
}

@manual{R2024,
  title        = {R: A Language and Environment for Statistical Computing},
  author       = {{R Core Team}},
  year         = {2024},
  organization = {R Foundation for Statistical Computing},
  address      = {Vienna, Austria},
  url          = {https://www.R-project.org/},
}