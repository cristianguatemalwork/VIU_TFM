{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb12dac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:50:24.605596Z",
     "start_time": "2024-08-13T14:50:07.631346Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importación de librearías necesarias\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle  #Para guardar archivos\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "from pympler import asizeof #Para liberar memoria\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, to_rgb\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import kneed\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "semilla = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7a9f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:50:24.614659Z",
     "start_time": "2024-08-13T14:50:24.605596Z"
    }
   },
   "outputs": [],
   "source": [
    "#Path general de archivos\n",
    "if socket.gethostname()=='LAPTOP-PUSGG08B': #Ip de la laptop\n",
    "    ruta = \"E:/Cristian Guatemal/Master/Big Data y Ciencia de Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"E:/Cristian Guatemal/Master/Big Data y Ciencia de Datos/VIU_TFM/RData/TFM/\"\n",
    "elif socket.gethostname()=='PCUIOMTDAIE6382': #Ip del working\n",
    "    ruta =   \"D:/Master/Big_Data_Ciencia_Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"D:/Master/Big_Data_Ciencia_Datos/VIU_TFM/RData/TFM/\"\n",
    "# Ruta del archivo de pensionistas de vejez\n",
    "ruta_vj = ruta + 'POB_VEJ_CD656_NEW.dsv'\n",
    "# Ruta del archivo de historia laboral de pensionistas\n",
    "ruta_afi = ruta + 'APORTES_CD656_new.dsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e15e93b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:52:09.364061Z",
     "start_time": "2024-08-13T14:50:24.614659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_clean_afi_sel_g_all_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    data_l = pickle.load( archivo )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9249e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:52:09.374649Z",
     "start_time": "2024-08-13T14:52:09.366107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62130167, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_l.shape #(62130167, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217c4de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:53:09.274792Z",
     "start_time": "2024-08-13T14:52:09.376176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución es: 0.0 horas con 1.0 minutos y 28.824524879455566 segundos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "data_l = data_l.sort_values( by=[\"CEDULA_COD\",\"ANIO\", \"MES\"], ascending=[ True, True, True] )\n",
    "data_l.reset_index(inplace=True)\n",
    "data_l.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "data_l.drop(columns=['nuevo_indice'], inplace=True)\n",
    "data_l['INDICE'] = data_l.index\n",
    "\n",
    "#Casos de no análisis\n",
    "data_no_grupo = data_l[ (data_l['GRUPO_SEL']==0) ].copy()\n",
    "data_no_grupo['CLA_KM_M1'] = np.nan\n",
    "data_no_grupo['CLA_KM_M2'] = np.nan\n",
    "data_no_grupo['CLA_KM_MS2'] = np.nan\n",
    "data_no_grupo['CLA_KM_M3'] = np.nan\n",
    "data_no_grupo['CLA_KM_M4'] = np.nan\n",
    "data_no_grupo['CLA_KM_MS4'] = np.nan\n",
    "\n",
    "data_no_grupo['ATI_KM_M1'] = np.nan\n",
    "data_no_grupo['ATI_KM_M2'] = np.nan \n",
    "data_no_grupo['ATI_KM_MS2'] = np.nan \n",
    "data_no_grupo['ATI_KM_M3'] = np.nan\n",
    "data_no_grupo['ATI_KM_M4'] = np.nan\n",
    "data_no_grupo['ATI_KM_MS4'] = np.nan \n",
    "\n",
    "data_no_grupo['NUM_CODO_M1'] = np.nan\n",
    "data_no_grupo['NUM_CODO_M2'] = np.nan\n",
    "data_no_grupo['NUM_CODO_M3'] = np.nan\n",
    "data_no_grupo['NUM_CODO_M4'] = np.nan \n",
    "\n",
    "data_no_grupo['NUM_SILU_M1'] = np.nan\n",
    "data_no_grupo['NUM_SILU_M2'] = np.nan\n",
    "data_no_grupo['NUM_SILU_M3'] = np.nan\n",
    "data_no_grupo['NUM_SILU_M4'] = np.nan\n",
    "\n",
    "data_no_grupo['CEN1_M1'] = np.nan\n",
    "data_no_grupo['CEN1_M2'] = np.nan\n",
    "data_no_grupo['CEN1_M3'] = np.nan\n",
    "data_no_grupo['CEN1_M4'] = np.nan\n",
    "\n",
    "data_no_grupo['CEN2_M1'] = np.nan\n",
    "data_no_grupo['CEN2_M2'] = np.nan\n",
    "data_no_grupo['CEN2_M3'] = np.nan\n",
    "data_no_grupo['CEN2_M4'] = np.nan\n",
    "\n",
    "data_no_grupo['LS_M1'] = np.nan\n",
    "data_no_grupo['LS_M2'] = np.nan\n",
    "data_no_grupo['LS_M3'] = np.nan\n",
    "data_no_grupo['LS_M4'] = np.nan\n",
    "\n",
    "#Casos de análisis\n",
    "data = data_l[ (data_l['GRUPO_SEL']==1) ].copy()\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin-inicio\n",
    "print('Tiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60, 'segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d7b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTiempo de ejecución es: 0.0 horas con 6.0 minutos y 41.65670084953308 segundos\n"
     ]
    }
   ],
   "source": [
    "#Se calculo los bigotes superiores para toda la historia laboral\n",
    "inicio = time.time() \n",
    "dataa = data_l.copy()\n",
    "dic_aux = dataa.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['SAL_PROM1'] =  np.nanmean(salarios)\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': [], 'SAL_PROM1': [] }\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "    data1['SAL_PROM1'].append( val['SAL_PROM1'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l.loc[:, 'LS1'] = data_l['CEDULA_COD'].map(LS)\n",
    "\n",
    "SPROM = pd.DataFrame( data1 )\n",
    "SPROM = SPROM.groupby('CEDULA_COD')['SAL_PROM1'].first()\n",
    "data_l.loc[:, 'SAL_PROM1'] = data_l['CEDULA_COD'].map(SPROM)\n",
    "\n",
    "del dataa, data1, dic_aux, LS, salarios, SPROM\n",
    "gc.collect()\n",
    "\n",
    "##Se calculo los bigotes superiores para toda la historia laboral, a partir del año 2000 en adelante.\n",
    "dataa = data_l[data_l['ANIO']>=2000].copy()\n",
    "dic_aux = dataa.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['SAL_PROM2'] =  np.nanmean(salarios)\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': [], 'SAL_PROM2': []  }\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "    data1['SAL_PROM2'].append( val['SAL_PROM2'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l.loc[:, 'LS2'] = data_l['CEDULA_COD'].map(LS)\n",
    "\n",
    "SPROM = pd.DataFrame( data1 )\n",
    "SPROM = SPROM.groupby('CEDULA_COD')['SAL_PROM2'].first()\n",
    "data_l.loc[:, 'SAL_PROM2'] = data_l['CEDULA_COD'].map(SPROM)\n",
    "\n",
    "del dataa, data1, dic_aux, LS, salarios, SPROM\n",
    "gc.collect()\n",
    "\n",
    "fin = time.time() \n",
    "tm = fin-inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc5d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l # cedulas unicas 442570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ffac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CEDULA_COD'].nunique() #442570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7000c4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:49:38.325494Z",
     "start_time": "2024-08-12T14:48:38.201577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTiempo de ejecución es: 0.0 horas con 0.0 minutos y 46.39535665512085 segundos\n"
     ]
    }
   ],
   "source": [
    "#Algortimos K-means\n",
    "inicio = time.time() \n",
    "\n",
    "cedula_1 = data.groupby('CEDULA_COD')['NUM_SEC_MES'].apply( lambda x: (x != 1).any() )\n",
    "cedula_dist = cedula_1[ cedula_1 ].index\n",
    "ul = data[ ~data['CEDULA_COD'].isin( cedula_dist )]\n",
    "ml = data[  data['CEDULA_COD'].isin( cedula_dist )]\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin - inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos')\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ceb5caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de cédulas en ul 373069\n",
      "Número de cédulas en ml 69501\n"
     ]
    }
   ],
   "source": [
    "print('Número de cédulas en ul', ul['CEDULA_COD'].nunique()) #cedulas unicas 373069\n",
    "print('Número de cédulas en ml', ml['CEDULA_COD'].nunique()) #cedulas unicas 69501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4483c47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTiempo de ejecución es: 0.0 horas con 1.0 minutos y 40.654988288879395 segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se calculo los bigotes superiores para la historia laboral de los mejores años\n",
    "inicio = time.time() \n",
    "dataa = ul.copy()\n",
    "dic_aux = dataa.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': []}\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l.loc[ ~data_l['CEDULA_COD'].isin( cedula_dist ), 'LS_MS'] = data_l['CEDULA_COD'].map(LS)\n",
    "\n",
    "del dataa, data1, dic_aux, LS\n",
    "gc.collect()\n",
    "\n",
    "dataa = ml.copy()\n",
    "dic_aux = dataa.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': []}\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l.loc[  data_l['CEDULA_COD'].isin( cedula_dist ), 'LS_MS'] = data_l['CEDULA_COD'].map(LS)\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin - inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos')\n",
    "\n",
    "del dataa, data1, dic_aux, LS\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be54109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_l[ (~data_l['CEDULA_COD'].isin( cedula_dist )) & (data_l['LS_MS'].isna()) ]\n",
    "data_l[data_l['CEDULA_COD']==216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7019233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificación de valores LS calculados\n",
    "a = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                        if isinstance(sal, str) \n",
    "                                        else [float(sal)]\n",
    "                                        for sal in data_l[ (data_l['CEDULA_COD']==216)]['SALARIO_SECTOR']\n",
    "                                    ]\n",
    "# Aplanar la lista de listas de SALARIO_SECTOR\n",
    "salarios = None\n",
    "salarios = [salario for sublist in a for salario in sublist]\n",
    "salarios\n",
    "print('sal promedio', np.nanmean(salarios))\n",
    "q1=  np.percentile(salarios, 25)\n",
    "q3 =  np.percentile(salarios, 75)\n",
    "iqr = q3 -  q1\n",
    "print('Ls', q3+1.5*iqr)\n",
    "\n",
    "b = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                        if isinstance(sal, str) \n",
    "                                        else [float(sal)]\n",
    "                                        for sal in ml[ (ml['CEDULA_COD']==216) ]['SALARIO_SECTOR']\n",
    "                                    ]\n",
    "salarios = None\n",
    "salarios = [salario for sublist in b for salario in sublist]\n",
    "salarios\n",
    "print('sal promedio', np.nanmean(salarios))\n",
    "q1=  np.percentile(salarios, 25)\n",
    "q3 =  np.percentile(salarios, 75)\n",
    "iqr = q3 -  q1\n",
    "print('LS_MS', q3+1.5*iqr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749dcf13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:49:38.356073Z",
     "start_time": "2024-08-12T14:49:38.329610Z"
    }
   },
   "outputs": [],
   "source": [
    "#Determinación del número de cluster según el método del codo y Silueta\n",
    "# Normalización de datos\n",
    "def data_norm( df1 ):\n",
    "    df = df1.copy()\n",
    "    me = df.groupby('CEDULA_COD')['SALARIO'].mean()\n",
    "    st = df.groupby('CEDULA_COD')['SALARIO'].std(0)\n",
    "    df['ME'] = df['CEDULA_COD'].map( me )\n",
    "    df['ST'] = df['CEDULA_COD'].map( st )\n",
    "    df['SALARIO_NORM'] = ( df['SALARIO'] - df['ME'] ) / df['ST'] \n",
    "    return df\n",
    "\n",
    "#Determinación del número de cluster por el método de la silueta\n",
    "def max_clust_silueta( silhouettes ):\n",
    "    silhouettes = np.array(silhouettes)\n",
    "    diferencias = np.abs(1 - silhouettes)\n",
    "    indice_cercano = np.argmin( diferencias )\n",
    "    return indice_cercano + 2\n",
    "\n",
    "#Determinar el número de cluster por el método del codo\n",
    "def num_cluster( data, num, num_sample, tipo, duplicados ):\n",
    "    print('*' * 102)\n",
    "    print('Determinación del número de clúster por el método del codo y silueta')\n",
    "    inicio = time.time()\n",
    "    \n",
    "    data_si_dic = data.copy()\n",
    "    \n",
    "    if( num_sample != 'todo' ):\n",
    "        sample_size = num_sample\n",
    "        sample_keys = random.sample( list(data_si_dic.keys()), min(sample_size, len(data_si_dic))) #Seleccion de cedulas\n",
    "        data_filt = {key: data_si_dic[key] for key in sample_keys if key in data_si_dic}\n",
    "    if (num_sample == 'todo' ):\n",
    "        data_filt = data_si_dic\n",
    "        \n",
    "    for ced  in data_filt:\n",
    "        \n",
    "        if( duplicados=='si'):\n",
    "            aux = np.array( data_filt[ced][ tipo ]).reshape(-1, 1)\n",
    "        \n",
    "        if( duplicados=='no'):\n",
    "            aux = np.unique( np.array( data_filt[ced][ tipo ])).reshape(-1, 1)\n",
    "        \n",
    "        if len(aux) <= 1:\n",
    "            data_filt[ced]['num_codo'] = 1\n",
    "            data_filt[ced]['max_silueta'] = 1\n",
    "           \n",
    "        \n",
    "        tf = min(num, len(aux) - 1) + 1\n",
    "        \n",
    "        distorsion = []\n",
    "        silueta = []\n",
    "\n",
    "        for i in range( 2, tf ):\n",
    "            km = KMeans( i, init = 'k-means++', n_init = 1, max_iter = 300, tol = 1e-4, random_state = semilla )\n",
    "            clustering = km.fit_predict( aux )\n",
    "\n",
    "            if( len( np.unique( clustering ) ) > 1):\n",
    "                distorsion.append( km.inertia_ )\n",
    "                silueta.append( metrics.silhouette_score(aux, clustering))\n",
    "            \n",
    "            else:\n",
    "                distorsion.append(0)\n",
    "                silueta.append(0)\n",
    "    \n",
    "        if( len(distorsion) > 1 and len(silueta) > 1 ):\n",
    "            data_filt[ced]['num_codo'] = kneed.KneeLocator(range(2, tf), distorsion[:tf], curve=\"convex\", \n",
    "                                                             direction=\"decreasing\").elbow or 1\n",
    "    \n",
    "            data_filt[ced]['max_silueta'] =  max_clust_silueta( silueta )\n",
    "        \n",
    "        else:\n",
    "            data_filt[ced]['num_codo'] = 1\n",
    "            data_filt[ced]['max_silueta'] = 1\n",
    "\n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "    print('*' * 102)\n",
    "    return data_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9a5f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:52:38.145409Z",
     "start_time": "2024-08-12T14:49:38.358065Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalización de datos-Z-core\n",
    "print('*' * 40, 'Normalización Z-Score ', '*' * 40)\n",
    "inicio = time.time()\n",
    "ul1 =  data_norm( ul )\n",
    "ml1 =  data_norm( ml )\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "print('*' * 102)\n",
    "\n",
    "del ul, ml\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2ad25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:52:39.780477Z",
     "start_time": "2024-08-12T14:52:38.299091Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Cedulas que tienen un único sector', ul1['CEDULA_COD'].nunique()) #373069\n",
    "print('Cedulas que tienen más de un único sector', ml1['CEDULA_COD'].nunique()) #69501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5eea52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:53:30.352553Z",
     "start_time": "2024-08-12T14:52:39.850621Z"
    }
   },
   "outputs": [],
   "source": [
    "ul_dic = ul1.groupby('CEDULA_COD').agg({'SALARIO': list,'SALARIO_NORM': list, 'INDICE': list}).to_dict(orient='index')\n",
    "ml_dic = ml1.groupby('CEDULA_COD').agg({'SALARIO': list,'SALARIO_NORM': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "del ul1, ml1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se aplica un muestreo para ver como funciona el algoritmo\n",
    "num = 5 # Número de cluster por defecto--máximo 5 se hace el supuesto por ser los mejores años\n",
    "muestra = 'todo' # muestra = 'todo' #Para que sea en todas las cedulas\n",
    "t1='SALARIO'\n",
    "#t2='SALARIO_NORM'\n",
    "duplicados = 'si'\n",
    "ul_dic_cluster1 = num_cluster( ul_dic, num, muestra, t1, duplicados ) \n",
    "ml_dic_cluster1 = num_cluster( ml_dic, num, muestra, t1, duplicados ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster1_ul.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto1 = ul_dic_cluster1\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto1, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster1_ml.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto2 = ml_dic_cluster1\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto2, archivo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5 \n",
    "muestra = 'todo' \n",
    "t1='SALARIO'\n",
    "#t2='SALARIO_NORM'\n",
    "duplicados = 'no'\n",
    "ul_dic_cluster2 = num_cluster( ul_dic, num, muestra, t1, duplicados )\n",
    "ml_dic_cluster2 = num_cluster( ml_dic, num, muestra, t1, duplicados )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78730d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster2_ul.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto3 = ul_dic_cluster2\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto3, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster2_ml.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto4 = ml_dic_cluster2\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto4, archivo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c53ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:02:53.409337Z",
     "start_time": "2024-08-08T15:02:42.217248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se redondea la variable 'SALARIO_NORM' a 4 decimales\n",
    "for key, value in ul_dic.items():\n",
    "    value['SALARIO_NORM'] = [ round(num, 4) for num in value['SALARIO_NORM'] ]\n",
    "    \n",
    "for key, value in ml_dic.items():\n",
    "    value['SALARIO_NORM'] = [ round(num, 4) for num in value['SALARIO_NORM'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1922a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:03:03.365910Z",
     "start_time": "2024-08-08T15:03:03.361640Z"
    }
   },
   "outputs": [],
   "source": [
    "def valores_nan(data):\n",
    "    result = {}\n",
    "    for cedula, info in data.items():\n",
    "        salario_norm_array = np.array(info['SALARIO_NORM'])\n",
    "        if np.isnan(salario_norm_array).any() or np.isinf(salario_norm_array).any():\n",
    "            result[cedula] = True\n",
    "        else:\n",
    "            result[cedula] = False\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32790a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:03:29.241683Z",
     "start_time": "2024-08-08T15:03:28.666770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtener resultados\n",
    "veri = valores_nan( ml_dic )\n",
    "ced_nan = []\n",
    "for cedula, has_na in veri .items():\n",
    "    if has_na:\n",
    "        ced_nan.append(cedula)\n",
    "ced_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092dc8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:00:53.351694Z",
     "start_time": "2024-08-12T15:00:52.996559Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_dic[2802556]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c6f864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:01:41.259383Z",
     "start_time": "2024-08-12T15:00:59.436623Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se filtran los valores nan e infinitos para que no tenga problemas el kmeans\n",
    "ul_dic_filt_no_nan = { key: value for key, value in ul_dic.items()\n",
    "                      if not (np.isnan(value['SALARIO_NORM']).any() or np.isinf(value['SALARIO_NORM']).any())}\n",
    "\n",
    "ml_dic_filt_no_nan = { key: value for key, value in ml_dic.items()\n",
    "                      if not (np.isnan(value['SALARIO_NORM']).any() or np.isinf(value['SALARIO_NORM']).any())}\n",
    "\n",
    "ul_dic_filt_si_nan = { key: value for key, value in ul_dic.items()\n",
    "                       if any(np.isnan(x) or np.isinf(x) for x in value['SALARIO_NORM'])}\n",
    "ml_dic_filt_si_nan = { key: value for key, value in ml_dic.items()\n",
    "                       if any(np.isnan(x) or np.isinf(x) for x in value['SALARIO_NORM'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5 \n",
    "muestra = 'todo'\n",
    "#t1='SALARIO'\n",
    "t2='SALARIO_NORM'\n",
    "duplicados = 'si'\n",
    "ul_dic_cluster3 = num_cluster( ul_dic_filt_no_nan , num, muestra, t2, duplicados )\n",
    "ml_dic_cluster3 = num_cluster( ml_dic_filt_no_nan, num, muestra, t2, duplicados )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster3_ul.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto5 = ul_dic_cluster3\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto5, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster3_ml.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto6 = ml_dic_cluster3\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto6, archivo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8992734",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-08T15:05:17.429Z"
    }
   },
   "outputs": [],
   "source": [
    "num = 5 \n",
    "muestra = 'todo'\n",
    "#t1='SALARIO'\n",
    "t2='SALARIO_NORM'\n",
    "duplicados = 'no'\n",
    "ul_dic_cluster4 = num_cluster( ul_dic_filt_no_nan, num, muestra, t2, duplicados )\n",
    "ml_dic_cluster4 = num_cluster( ml_dic_filt_no_nan, num, muestra, t2, duplicados )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster4_ul.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto7 = ul_dic_cluster4\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto7, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster4_ml.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto8 = ml_dic_cluster4\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto8, archivo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436ed6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:34:07.631473Z",
     "start_time": "2024-08-12T15:30:21.810019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster1_ul.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster1 = pickle.load( archivo ) \n",
    "    \n",
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster1_ml.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster1 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b321ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster2_ul.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster2 = pickle.load( archivo ) \n",
    "    \n",
    "# Cargar archivo-------------------------                                                                                                                    -----------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster2_ml.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster2 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster3_ul.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster3 = pickle.load( archivo ) \n",
    "    \n",
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster3_ml.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster3 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42002070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:18:39.656700Z",
     "start_time": "2024-08-12T15:18:39.467594Z"
    }
   },
   "outputs": [],
   "source": [
    "for clave in ul_dic_filt_si_nan:\n",
    "    ul_dic_filt_si_nan[clave]['num_codo'] = 1\n",
    "    ul_dic_filt_si_nan[clave]['max_silueta'] = 1\n",
    "    \n",
    "for clave in ml_dic_filt_si_nan:\n",
    "    ml_dic_filt_si_nan[clave]['num_codo'] = 1\n",
    "    ml_dic_filt_si_nan[clave]['max_silueta'] = 1\n",
    "    \n",
    "#ul_dic_cluster3_all = ul_dic_cluster3 | ul_dic_filt_si_nan\n",
    "#ml_dic_cluster3_all = ml_dic_cluster3 | ml_dic_filt_si_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster4_ul.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster4 = pickle.load( archivo ) \n",
    "    \n",
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster4_ml.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster4 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62edce89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:23:09.812786Z",
     "start_time": "2024-08-12T19:23:09.765040Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se escojen dos cluster para trabajar\n",
    "def clasificacion_kmean( data_dic, n, val, tipo, duplicados ):\n",
    "    print('*' * 102)\n",
    "    print('Clasificación de las observaciones según cluster')\n",
    "    inicio = time.time()\n",
    "    \n",
    "    c_tipo = 'CLA_KM_M' + str( tipo )\n",
    "    n_tipo = 'ATI_KM_M' + str( tipo )\n",
    "    \n",
    "    nm1 = 'cent1_M'+ str( tipo )\n",
    "    nm2 = 'cent2_M'+ str( tipo )\n",
    "    ls = 'LS_M' + str( tipo)\n",
    "            \n",
    "    for ced in data_dic:\n",
    "        aux = None\n",
    "        \n",
    "        if( duplicados =='si'):\n",
    "            aux = np.array( data_dic[ced][ val ] ).reshape(-1, 1)\n",
    "        if( duplicados =='no'):\n",
    "            aux = np.unique( np.array( data_dic[ced][ val ] ) ).reshape(-1, 1)\n",
    "            \n",
    "        Q1 = np.quantile(aux, 0.25)\n",
    "        Q3 = np.quantile(aux, 0.75)\n",
    "        IQR = Q3-Q1\n",
    "        LI = Q1 - 1.5 * IQR\n",
    "        LS = Q3 + 1.5 * IQR\n",
    "\n",
    "        data_dic[ced][ls] = LS    \n",
    "            \n",
    "        if aux.shape[0] >= n:\n",
    "            \n",
    "            kmeans = KMeans( n_clusters = n, init = 'k-means++', n_init = 1, random_state = semilla)\n",
    "            clu = kmeans.fit_predict( aux ) + 1 \n",
    "            \n",
    "            data_dic[ced][c_tipo] = clu\n",
    "            \n",
    "            ncl = np.unique( clu )\n",
    "            centroide = np.array([[ np.nanmean( aux[clu == i], axis=0)[0], i ] for i in range(1, len(ncl) + 1)] ) \n",
    "            \n",
    "            if len( ncl ) == 1:\n",
    "                data_dic[ced][n_tipo] =  [-2] * len( aux ) #Clasificacion unica de todos los valores\n",
    "                data_dic[ced][nm1] = centroide[:,0][0]\n",
    "                data_dic[ced][nm2] = centroide[:,0][0]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                data_dic[ced][nm1] =  centroide[:,0][0]\n",
    "                data_dic[ced][nm2] =  centroide[:,0][1]\n",
    "\n",
    "                cl_at = np.where( centroide[:,0] > (LS +  1e-8) )[0]\n",
    "                \n",
    "                mod_aux = np.zeros((len( aux ), 2) )\n",
    "                mod_aux[:, 0] = aux[:, 0]  \n",
    "                mod_aux[np.isin( clu, centroide[cl_at][:, 1]), 1] = 1\n",
    "                \n",
    "                data_dic[ced][n_tipo] = mod_aux[:, 1].tolist()\n",
    "                \n",
    "#                 if len(cl_at) ==0:\n",
    "#                     data_dic[ced][nm1] =  np.nanmean( aux )\n",
    "#                     data_dic[ced][nm2] =  np.nanmean( aux )\n",
    "                    \n",
    "#                 if len(cl_at)!=0: \n",
    "#                     data_dic[ced][nm1] =  centroide[:,0][0]\n",
    "#                     data_dic[ced][nm2] =  centroide[:,0][1]\n",
    "            \n",
    "        else:\n",
    "            data_dic[ced][n_tipo] =  [-1] * len( aux )\n",
    "            data_dic[ced][c_tipo] = np.nan\n",
    "            data_dic[ced][nm1] =  np.nan\n",
    "            data_dic[ced][nm2] =  np.nan\n",
    "\n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "    print('*' * 102)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a03d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T20:04:42.826098Z",
     "start_time": "2024-08-12T19:23:17.447206Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 2\n",
    "val = 'SALARIO'\n",
    "tipo = 1\n",
    "duplicados = 'si'\n",
    "\n",
    "clasificacion_kmean( ul_dic_cluster1, n, val, tipo, duplicados )\n",
    "clasificacion_kmean( ml_dic_cluster1, n, val, tipo, duplicados )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster1_ul_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto10 = ul_dic_cluster1\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto10, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster1_ml_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto11 = ml_dic_cluster1\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto11, archivo) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47543e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extensión para el caso de no duplicados\n",
    "def exten_duplicados( data_dic, val, tipo ):\n",
    "    cla = 'CLA_KM_M' + str( tipo)\n",
    "    clas = 'CLA_KM_MS' + str( tipo)\n",
    "    nom = 'ATI_KM_M' + str( tipo)\n",
    "    noms = 'ATI_KM_MS' + str( tipo )\n",
    "\n",
    "    for ced in data_dic:\n",
    "        cl = np.array( data_dic[ced][ cla ] )\n",
    "        ati = np.array( data_dic[ced][ nom ] )\n",
    "        contador = Counter( data_dic[ced][ val ] )\n",
    "\n",
    "        valores = np.array(list(contador.keys()))\n",
    "        cantidades = np.array(list(contador.values()))\n",
    "\n",
    "        # Crear un array estructurado\n",
    "        array_np = np.column_stack((valores, cantidades, ati, cl ))\n",
    "        valores_repetidos = []\n",
    "        valores_columna3 = []\n",
    "        valores_columna4 = []\n",
    "\n",
    "        for fila in array_np:\n",
    "            valor_columna1 = fila[0]\n",
    "            num_repeticiones = int(fila[1])\n",
    "            valor_columna3 = fila[2]\n",
    "            valor_columna4 = fila[3]\n",
    "            valores_columna3.extend([valor_columna3] * num_repeticiones)\n",
    "            valores_columna4.extend([valor_columna4] * num_repeticiones)\n",
    "\n",
    "        data_dic[ced][noms] = valores_columna3\n",
    "        data_dic[ced][clas] = valores_columna4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa8f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "val = 'SALARIO'\n",
    "tipo = 2\n",
    "duplicados = 'no'\n",
    "\n",
    "clasificacion_kmean( ul_dic_cluster2, n, val, tipo, duplicados )\n",
    "clasificacion_kmean( ml_dic_cluster2, n, val, tipo, duplicados )\n",
    "\n",
    "exten_duplicados( ul_dic_cluster2, val, tipo )\n",
    "exten_duplicados( ml_dic_cluster2, val, tipo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c842bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster2_ul_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto12 = ul_dic_cluster2\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto12, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster2_ml_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto13 = ml_dic_cluster2\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto13, archivo) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a10763",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "val = 'SALARIO_NORM'\n",
    "tipo = 3\n",
    "duplicados = 'si'\n",
    "\n",
    "clasificacion_kmean( ul_dic_cluster3, n, val, tipo, duplicados )\n",
    "clasificacion_kmean( ml_dic_cluster3, n, val, tipo, duplicados )\n",
    "\n",
    "for clave in ul_dic_filt_si_nan:\n",
    "    ul_dic_filt_si_nan[clave]['CLA_KM_M3'] = [1] * len( ul_dic_filt_si_nan[clave]['SALARIO_NORM'])\n",
    "    ul_dic_filt_si_nan[clave]['ATI_KM_M3'] = [-2] * len( ul_dic_filt_si_nan[clave]['SALARIO_NORM']) \n",
    "    ul_dic_filt_si_nan[clave]['LS_M3'] = np.nan\n",
    "    ul_dic_filt_si_nan[clave]['cent1_M3'] = np.nan\n",
    "    ul_dic_filt_si_nan[clave]['cent2_M3'] = np.nan \n",
    "    \n",
    "for clave in ml_dic_filt_si_nan:\n",
    "    ml_dic_filt_si_nan[clave]['CLA_KM_M3'] = [1] * len( ml_dic_filt_si_nan[clave]['SALARIO_NORM'])\n",
    "    ml_dic_filt_si_nan[clave]['ATI_KM_M3'] = [-2] * len( ml_dic_filt_si_nan[clave]['SALARIO_NORM']) \n",
    "    ml_dic_filt_si_nan[clave]['LS_M3'] = np.nan\n",
    "    ml_dic_filt_si_nan[clave]['cent1_M3'] = np.nan\n",
    "    ml_dic_filt_si_nan[clave]['cent2_M3'] = np.nan \n",
    "    \n",
    "ul_dic_cluster3_all = ul_dic_cluster3 | ul_dic_filt_si_nan\n",
    "ml_dic_cluster3_all = ml_dic_cluster3 | ml_dic_filt_si_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster3_ul_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto14 = ul_dic_cluster3_all\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto14, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster3_ml_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto15 = ml_dic_cluster3_all\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto15, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "val = 'SALARIO_NORM'\n",
    "tipo = 4\n",
    "duplicados = 'no'\n",
    "\n",
    "clasificacion_kmean( ul_dic_cluster4, n, val, tipo, duplicados )\n",
    "clasificacion_kmean( ml_dic_cluster4, n, val, tipo, duplicados )\n",
    "\n",
    "exten_duplicados( ul_dic_cluster4, val, tipo )\n",
    "exten_duplicados( ml_dic_cluster4, val, tipo )\n",
    "\n",
    "ul_dic_filt_si_nan_4 = { key: {k: v for k, v in value.items() if k not in ['CLA_KM_M3','ATI_KM_M3','LS_M3', 'cent1_M3', 'cent2_M3']}\n",
    "                         for key, value in ul_dic_filt_si_nan.items()}\n",
    "\n",
    "ml_dic_filt_si_nan_4 = { key: {k: v for k, v in value.items() if k not in ['CLA_KM_M3','ATI_KM_M3','LS_M3', 'cent1_M3', 'cent2_M3']}\n",
    "                         for key, value in ml_dic_filt_si_nan.items()}\n",
    "\n",
    "for clave in ul_dic_filt_si_nan_4:\n",
    "    ul_dic_filt_si_nan_4[clave]['CLA_KM_M4'] = [1] * len( ul_dic_filt_si_nan_4[clave]['SALARIO_NORM'])\n",
    "    ul_dic_filt_si_nan_4[clave]['CLA_KM_MS4'] = [1] * len( ul_dic_filt_si_nan_4[clave]['SALARIO_NORM'])\n",
    "    ul_dic_filt_si_nan_4[clave]['ATI_KM_M4'] = [-2] * len( ul_dic_filt_si_nan_4[clave]['SALARIO_NORM'])  \n",
    "    ul_dic_filt_si_nan_4[clave]['ATI_KM_MS4'] = [-2] * len( ul_dic_filt_si_nan_4[clave]['SALARIO_NORM']) \n",
    "    ul_dic_filt_si_nan_4[clave]['LS_M4'] = np.nan\n",
    "    ul_dic_filt_si_nan_4[clave]['cent1_M4'] = np.nan\n",
    "    ul_dic_filt_si_nan_4[clave]['cent2_M4'] = np.nan \n",
    "    \n",
    "for clave in ml_dic_filt_si_nan_4:\n",
    "    ml_dic_filt_si_nan_4[clave]['CLA_KM_M4'] = [1] * len( ml_dic_filt_si_nan_4[clave]['SALARIO_NORM'])\n",
    "    ml_dic_filt_si_nan_4[clave]['CLA_KM_MS4'] = [1] * len( ml_dic_filt_si_nan_4[clave]['SALARIO_NORM'])\n",
    "    ml_dic_filt_si_nan_4[clave]['ATI_KM_M4'] = [-2] * len( ml_dic_filt_si_nan_4[clave]['SALARIO_NORM']) \n",
    "    ml_dic_filt_si_nan_4[clave]['ATI_KM_MS4'] = [-2] * len( ml_dic_filt_si_nan_4[clave]['SALARIO_NORM']) \n",
    "    ml_dic_filt_si_nan_4[clave]['LS_M4'] = np.nan\n",
    "    ml_dic_filt_si_nan_4[clave]['cent1_M4'] = np.nan\n",
    "    ml_dic_filt_si_nan_4[clave]['cent2_M4'] = np.nan \n",
    "    \n",
    "    \n",
    "ul_dic_cluster4_all = ul_dic_cluster4 | ul_dic_filt_si_nan_4\n",
    "ml_dic_cluster4_all = ml_dic_cluster4 | ml_dic_filt_si_nan_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2080948",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster4_ul_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto16 = ul_dic_cluster4_all\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto16, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster4_ml_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto17 = ml_dic_cluster4_all\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto17, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b3dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "del objeto10, objeto11, objeto12, objeto13, objeto14, objeto15, objeto16, objeto17\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54f30c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T15:10:37.235655Z",
     "start_time": "2024-08-13T15:09:57.731152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster4_ul_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster4 = pickle.load( archivo ) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster4_ml_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster4 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e866c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T15:17:57.617298Z",
     "start_time": "2024-08-13T15:17:55.985442Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_dic_cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb3f9744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T20:03:49.219281Z",
     "start_time": "2024-08-13T20:03:49.025085Z"
    }
   },
   "outputs": [],
   "source": [
    "#Para unir los resultados\n",
    "def extend_data( data_val_ati, k ):\n",
    "    inicio = time.time()\n",
    "    print('Extensión a dataframe de los diccionarios')\n",
    "    \n",
    "    if k in [2,4]:\n",
    "        nom = 'ATI_KM_MS'   + str(k)\n",
    "        cla = 'CLA_KM_MS'   + str(k)\n",
    "    else:\n",
    "        nom = 'ATI_KM_M'   + str(k)\n",
    "        cla = 'CLA_KM_M' + str(k)\n",
    "    \n",
    "    codo = 'num_codo'\n",
    "    silu = 'max_silueta'\n",
    "    ls = 'LS_M' + str( k )\n",
    "    cent1 = 'cent1_M'+ str(k)\n",
    "    cent2 = 'cent2_M'+ str(k)\n",
    "    \n",
    "    data1 = { 'CEDULA_COD': [], 'SALARIO': [], cla:[], nom : [], 'INDICE':[], codo:[], silu:[], ls:[],cent1:[], cent2:[] }\n",
    "\n",
    "    # Llenar las listas con los datos del diccionario\n",
    "    for cedula, values in data_val_ati.items():\n",
    "        salario = values['SALARIO']\n",
    "        clasi = values[ cla ]\n",
    "        atipico = values[ nom ]\n",
    "        indice = values['INDICE']\n",
    "        numcodo = values[codo]\n",
    "        numsilu = values[silu]\n",
    "        numls = values[ls]\n",
    "        ncl1 = values[cent1]\n",
    "        ncl2 = values[cent2]\n",
    "        num_rows = len(salario)\n",
    "\n",
    "        # Extender las listas en el diccionario de datos\n",
    "        data1['CEDULA_COD'].extend([cedula] * num_rows)\n",
    "        data1['SALARIO'].extend(salario)\n",
    "        data1[ cla ].extend(clasi)\n",
    "        data1[ nom ].extend(atipico)\n",
    "        data1[ codo ].extend([numcodo] * num_rows)\n",
    "        data1[ silu ].extend([numsilu] * num_rows)\n",
    "        data1[ ls ].extend([numls] * num_rows)\n",
    "        data1[ cent1 ].extend([ ncl1 ] * num_rows)\n",
    "        data1[ cent2 ].extend([ ncl2 ] * num_rows)\n",
    "        data1['INDICE'].extend(indice)\n",
    "        \n",
    "    data1 = pd.DataFrame( data1 )\n",
    "    data1.rename(columns={ codo: f'NUM_CODO_M{str(k)}', silu: f'NUM_SILU_M{str(k)}',\n",
    "                           ls: f'LS_M{str(k)}', cent1: f'CEN1_M{str(k)}', cent2:f'CEN2_M{str(k)}'}, inplace=True)\n",
    "    \n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b23ee18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T19:46:27.441672Z",
     "start_time": "2024-08-13T19:43:09.304632Z"
    }
   },
   "outputs": [],
   "source": [
    "#Union de resultados con el dataframe data_l\n",
    "def union_dic( data, data_no_grupo, data_dic, k):\n",
    "    inicio = time.time()\n",
    "    print('*' * 102)\n",
    "    print('Unión de la extensión con los datos originales para el caso', str(k))\n",
    "    \n",
    "    if k in [2,4]:\n",
    "        nom = 'ATI_KM_MS'   + str(k)\n",
    "        cla = 'CLA_KM_MS'   + str(k)\n",
    "    else:\n",
    "        nom = 'ATI_KM_M'   + str(k)\n",
    "        cla = 'CLA_KM_M' + str(k)\n",
    "    \n",
    "    sil = 'NUM_SILU_M' + str(k)\n",
    "    cod = 'NUM_CODO_M' + str(k)\n",
    "    ls = 'LS_M' + str(k)\n",
    "    cen1= 'CEN1_M' +str(k)\n",
    "    cen2= 'CEN2_M' +str(k)\n",
    "\n",
    "    data1 = extend_data( data_dic, k ) \n",
    "    data_kmean = None\n",
    "    data_kmean = pd.concat( [ data_no_grupo[['CEDULA_COD', 'SALARIO', cla, nom, cod, sil, ls, cen1, cen2, 'INDICE']],\n",
    "                              data1[['CEDULA_COD', 'SALARIO', cla, nom, cod, sil, ls, cen1, cen2, 'INDICE']] ], axis=0)\n",
    "\n",
    "\n",
    "    data_kmean = data_kmean.sort_values( by=[\"INDICE\"], ascending=[ True ] )\n",
    "    data_kmean.reset_index(inplace=True)\n",
    "    data_kmean.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "    data_kmean.drop(columns=['nuevo_indice'], inplace=True)\n",
    "\n",
    "    col = [cla, nom, cod, sil, ls, cen1, cen2]\n",
    "    data[ col ] = np.nan\n",
    "\n",
    "    for nom_col in col:\n",
    "        aux = None\n",
    "        aux = data_kmean[ nom_col ].to_numpy()\n",
    "        data.iloc[:, data.columns.get_loc( nom_col )] = aux\n",
    "    \n",
    "    del data1, data_kmean\n",
    "    \n",
    "    print('Concatenación con el dataframe original')    \n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8861428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************\n",
      "Unión de la extensión con los datos originales para el caso 1\n",
      "Extensión a dataframe de los diccionarios\n",
      "\tTiempo de ejecución es:  0.0  horas con  0.0  minutos y 50.302165269851685  segundos\n",
      "Concatenación con el dataframe original\n",
      "\tTiempo de ejecución es:  0.0  horas con  2.0  minutos y 0.9397082328796387  segundos\n"
     ]
    }
   ],
   "source": [
    "data_dic_union = ul_dic_cluster1 | ml_dic_cluster1\n",
    "union_dic( data_l, data_no_grupo, data_dic_union, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcdca120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************\n",
      "Unión de la extensión con los datos originales para el caso 2\n",
      "Extensión a dataframe de los diccionarios\n",
      "\tTiempo de ejecución es:  0.0  horas con  0.0  minutos y 48.7096312046051  segundos\n",
      "Concatenación con el dataframe original\n",
      "\tTiempo de ejecución es:  0.0  horas con  1.0  minutos y 14.593064546585083  segundos\n"
     ]
    }
   ],
   "source": [
    "data_dic_union = ul_dic_cluster2 | ml_dic_cluster2\n",
    "union_dic( data_l, data_no_grupo, data_dic_union, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed3a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************\n",
      "Unión de la extensión con los datos originales para el caso 3\n",
      "Extensión a dataframe de los diccionarios\n",
      "\tTiempo de ejecución es:  0.0  horas con  0.0  minutos y 53.260382890701294  segundos\n",
      "Concatenación con el dataframe original\n",
      "\tTiempo de ejecución es:  0.0  horas con  1.0  minutos y 22.17986822128296  segundos\n"
     ]
    }
   ],
   "source": [
    "data_dic_union = ul_dic_cluster3 | ml_dic_cluster3\n",
    "union_dic( data_l, data_no_grupo, data_dic_union, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbebdfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************\n",
      "Unión de la extensión con los datos originales para el caso 4\n",
      "Extensión a dataframe de los diccionarios\n",
      "\tTiempo de ejecución es:  0.0  horas con  0.0  minutos y 47.82336068153381  segundos\n",
      "Concatenación con el dataframe original\n",
      "\tTiempo de ejecución es:  0.0  horas con  1.0  minutos y 12.567283153533936  segundos\n"
     ]
    }
   ],
   "source": [
    "data_dic_union = ul_dic_cluster4 | ml_dic_cluster4\n",
    "union_dic( data_l, data_no_grupo, data_dic_union, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98037f06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ul_dic_filt_si_nan_4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5848\\4026979294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mdata_dic_union\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_no_grupo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mul_dic_cluster3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_dic_cluster3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mul_dic_cluster4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_dic_cluster4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mul_dic_cluster2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_dic_cluster2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mul_dic_cluster1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_dic_cluster1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mul_dic_filt_si_nan_4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_dic_filt_si_nan_4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mul_dic_filt_si_nan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_dic_filt_si_nan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ul_dic_filt_si_nan_4' is not defined"
     ]
    }
   ],
   "source": [
    "del data_dic_union, data_no_grupo, ul_dic_cluster3, ml_dic_cluster3, \n",
    "ul_dic_cluster4, ml_dic_cluster4,\n",
    "ul_dic_cluster2, ml_dic_cluster2, ul_dic_cluster1, ml_dic_cluster1, ul_dic_filt_si_nan_4, ml_dic_filt_si_nan_4,\n",
    "ul_dic_filt_si_nan, ml_dic_filt_si_nan\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75c11b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificación de errores\n",
    "nombre_archivo = 'viu_k_mean_data_l_cl.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto18 = data_l\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto18, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf4dd083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del objeto18\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f99294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "inicio = time.time()\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_data_l_cl.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    data_l = pickle.load( archivo ) \n",
    "\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa9bc22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             382.4950\n",
       "1             382.4950\n",
       "2             382.4950\n",
       "3             382.4950\n",
       "4             382.4950\n",
       "               ...    \n",
       "62130162    17232.8625\n",
       "62130163    17232.8625\n",
       "62130164    17232.8625\n",
       "62130165    17232.8625\n",
       "62130166    17232.8625\n",
       "Name: LS2, Length: 62130167, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_l['LS2' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3ab32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_norm_m( df1 ):\n",
    "    df = df1.copy()\n",
    "    dfs = df[df['GRUPO_SEL']==1]\n",
    "    me = dfs.groupby('CEDULA_COD')['SALARIO'].mean()\n",
    "    st = dfs.groupby('CEDULA_COD')['SALARIO'].std(0)\n",
    "    df['ME'] = df['CEDULA_COD'].map( me )\n",
    "    df['ST'] = df['CEDULA_COD'].map( st )\n",
    "    df['SALARIO_NORM'] = ( df['SALARIO'] - df['ME'] ) / df['ST'] \n",
    "    return df\n",
    "\n",
    "def graf_meses(data_i, ced, val, modelo = 1, grupo_sel = 0):\n",
    "    #Adecuación de la base de datos\n",
    "    idx = data_i.columns.get_loc('LS1')\n",
    "    columnas_requeridas = ['CEDULA_COD', 'ANIO', 'MES', val, 'GRUPO_SEL', 'INDICE', 'BASE_CAL'] + list(data_i.columns[idx:])\n",
    "    data = data_i[data_i['CEDULA_COD'] == ced][columnas_requeridas]\n",
    "    \n",
    "    # Establecer el modelo escogido\n",
    "    if modelo == 1:\n",
    "        mod = '1'\n",
    "        numero = '1'\n",
    "    elif modelo == 2:\n",
    "        mod = 'S2'\n",
    "        numero = '2'\n",
    "    elif modelo == 3:\n",
    "        mod = '3'\n",
    "        numero = '3'\n",
    "    else:\n",
    "        mod = 'S4'\n",
    "        numero = '4'\n",
    "            \n",
    "    data_aux = data.copy()\n",
    "    \n",
    "    # Establecer si se quieren todos o solos los 5 mejores años\n",
    "    if(grupo_sel == 1):\n",
    "        data = data[data['GRUPO_SEL']==1]\n",
    "    \n",
    "    # Establecer variables según el modelo escogido\n",
    "    CLA_KM = 'CLA_KM_M' + mod\n",
    "    ATI_KM = 'ATI_KM_M' + mod\n",
    "    NUM_CODO = 'NUM_CODO_M' + numero\n",
    "    NUM_SILU = 'NUM_SILU_M' + numero\n",
    "    LS = 'LS_M' + numero\n",
    "    CEN1 = 'CEN1_M' + numero\n",
    "    CEN2 = 'CEN2_M' + numero\n",
    "    \n",
    "    #Número de clusters\n",
    "    if(int(data[data['GRUPO_SEL'] == 1][NUM_CODO].iloc[0]) < 1):\n",
    "        numero_clusters_codo = 1\n",
    "    else: \n",
    "        numero_clusters_codo = int(data[data['GRUPO_SEL'] == 1][NUM_CODO].iloc[0])\n",
    "        \n",
    "    if(int(data[data['GRUPO_SEL'] == 1][NUM_SILU].iloc[0]) < 1):\n",
    "        numero_clusters_silueta = 1\n",
    "    else: \n",
    "        numero_clusters_silueta = int(data[data['GRUPO_SEL'] == 1][NUM_SILU].iloc[0])\n",
    "    \n",
    "    \n",
    "    #Fecha para eje x\n",
    "    anios = data['ANIO'].tolist()\n",
    "    meses = data['MES'].tolist()\n",
    "    fechas = [datetime(year=anio, month=mes, day=1) for anio, mes in zip(anios, meses)]\n",
    "    data['FECHA']= pd.to_datetime(fechas)\n",
    "    data = data.sort_values(by='FECHA')\n",
    "    \n",
    "    #Paleta de colores\n",
    "    palette = sns.color_palette(\"deep\", 10)  \n",
    "\n",
    "    # Gráfico\n",
    "    plt.figure(figsize=(12, 8))  \n",
    "    marker_dict = {1: 'o', 2: 'x'} \n",
    "    \n",
    "    \n",
    "    # Datos no tomados en cuenta\n",
    "    if(len(data[data['GRUPO_SEL']==0]['SALARIO'])>0):\n",
    "        Grupo00 = data[data['GRUPO_SEL'] == 0]\n",
    "        plt.scatter(Grupo00['FECHA'], Grupo00[val], marker='^', color=palette[0], label='Variables no consideradas')\n",
    "    \n",
    "    # Datos de los 5 mejores años\n",
    "    if(len(data[data['GRUPO_SEL']==1][CLA_KM].unique()) >=2):\n",
    "        tipo1= data[(data['GRUPO_SEL']==1) & (data[CLA_KM]==1)][ATI_KM].unique()\n",
    "        tipo2= data[(data['GRUPO_SEL']==1) & (data[CLA_KM]==2)][ATI_KM].unique()\n",
    "        if(1 in tipo1):\n",
    "            Grupo11_c1= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == 1) & (data[CLA_KM] == 1)]\n",
    "            plt.scatter(Grupo11_c1['FECHA'], Grupo11_c1[val], marker= marker_dict[1], color=palette[2], label='Cluster 1 / 1: atípico')\n",
    "        if(-2 in tipo1):\n",
    "            Grupo1_2_c1= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == -2) & (data[CLA_KM] == 1)]\n",
    "            plt.scatter(Grupo1_2_c1['FECHA'], Grupo1_2_c1[val], marker= marker_dict[1], color=palette[6], label='Cluster 1 / -2: un solo salario')\n",
    "        if(0 in tipo1):\n",
    "            Grupo10_c1 = data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == 0) & (data[CLA_KM] == 1)]\n",
    "            plt.scatter(Grupo10_c1['FECHA'], Grupo10_c1[val], marker= marker_dict[1], color=palette[8], label='Cluster 1 / 0: no atípico')\n",
    "        if( -1 in tipo1):\n",
    "            Grupo1_1_c1= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == -1) & (data[CLA_KM] == 1)]\n",
    "            plt.scatter(Grupo1_1_c1['FECHA'], Grupo1_1_c1[val], marker= marker_dict[1], color=palette[5], label='Cluster 1 / -1: no clasificados')\n",
    "        if(1 in tipo2):\n",
    "            Grupo11_c2= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == 1) & (data[CLA_KM] == 2)]\n",
    "            plt.scatter(Grupo11_c2['FECHA'], Grupo11_c2[val], marker= marker_dict[2], color=palette[2], label='Cluster 2 / 1: atípico')\n",
    "        if(0 in tipo2):\n",
    "            Grupo10_c2 = data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == 0) & (data[CLA_KM] == 2)]\n",
    "            plt.scatter(Grupo10_c2['FECHA'], Grupo10_c2[val], marker= marker_dict[2], color=palette[8], label='Cluster 2 / 0: no atípico')\n",
    "        if( -1 in tipo2):\n",
    "            Grupo1_1_c2= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == -1) & (data[CLA_KM] == 2)]\n",
    "            plt.scatter(Grupo1_1_c2['FECHA'], Grupo1_1_c2[val], marker= marker_dict[2], color=palette[5], label='Cluster 2 / -1: no clasificados')\n",
    "        if(-2 in tipo2):\n",
    "            Grupo1_2_c2= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == -2) & (data[CLA_KM] == 2)]\n",
    "            plt.scatter(Grupo1_2_c2['FECHA'], Grupo1_2_c2[val], marker= marker_dict[2], color=palette[6], label='Cluster 2 / -2: un solo salario')\n",
    "   \n",
    "    else: \n",
    "        tipo1= data[(data['GRUPO_SEL']==1) ][ATI_KM].unique()\n",
    "        if(1 in tipo1):\n",
    "            Grupo11_c1= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == 1) ]\n",
    "            plt.scatter(Grupo11_c1['FECHA'], Grupo11_c1[val], marker= marker_dict[1], color=palette[2], label='Cluster / 1: atípico')\n",
    "        if(0 in tipo1):\n",
    "            Grupo10_c1 = data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == 0) ]\n",
    "            plt.scatter(Grupo10_c1['FECHA'], Grupo10_c1[val], marker= marker_dict[1], color=palette[8], label='Cluster / 0: no atípico')\n",
    "        if( -1 in tipo1):\n",
    "            Grupo1_1_c1= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == -1)]\n",
    "            plt.scatter(Grupo1_1_c1['FECHA'], Grupo1_1_c1[val], marker= marker_dict[1], color=palette[5], label='Cluster / -1: no clasificados')\n",
    "        if(-2 in tipo1):\n",
    "            Grupo1_2_c1= data[(data['GRUPO_SEL'] == 1) & (data[ATI_KM] == -2)]\n",
    "            plt.scatter(Grupo1_2_c1['FECHA'], Grupo1_2_c1[val], marker= marker_dict[1], color=palette[6], label='Cluster / -2: un solo salario')\n",
    "    \n",
    "    \n",
    "    # Añadir líneas horizontales para promedio y LS\n",
    "    \n",
    "    plt.axhline(y= data['SAL_PROM2'].iloc[0], color=palette[1], linestyle='-', label='Promedio Salarios')\n",
    "    plt.axhline(y=data['LS2'].iloc[0], alpha=0.5, color= '#FF00E8', linestyle=':', label='LS2')\n",
    "    \n",
    "    if modelo==1 or modelo == 2:\n",
    "        #LS_M\n",
    "        if not np.isnan(data[data['GRUPO_SEL']==1][LS].iloc[0]):\n",
    "            plt.axhline(y=data[data['GRUPO_SEL']==1][LS].iloc[0], color= \"#F1F42C\", linestyle='--', label= LS)\n",
    "        # Añadir los clusters\n",
    "        data1 = data[data[CLA_KM] == 1]\n",
    "        data2 = data[data[CLA_KM] == 2]\n",
    "        # Verificar si los data.frames están vacíos\n",
    "        if data1.shape[0] != 0 and not np.isnan(data1[CEN1].iloc[0]):\n",
    "            d = round(data1.shape[0]/2)\n",
    "            c1_i = data1['FECHA'].iloc[d]\n",
    "            plt.scatter(c1_i, data1[CEN1].iloc[0], label= 'Centroide 1', color='red', marker= 'D')\n",
    "        if data2.shape[0] != 0 and not np.isnan(data2[CEN2].iloc[0]):\n",
    "            d = round(data2.shape[0]/2)\n",
    "            c2_i = data2['FECHA'].iloc[d]\n",
    "            plt.scatter(c2_i, data2[CEN2].iloc[0], label= 'Centroide 2', color='blue', marker= 'D') \n",
    "\n",
    "        del(data1)\n",
    "        del(data2)\n",
    "        \n",
    "    plt.axhline(y=np.mean(data['BASE_CAL'].iloc[0]), color= '#2E5F00' , linestyle=':', label='Base de cálculo')\n",
    "    \n",
    "    # Añadir el número de clusters por método\n",
    "    \n",
    "    plt.scatter(data['FECHA'].iloc[0], data[val].iloc[0], facecolors='none', edgecolors='none', label =\"Número de clusters según el método del codo: {}\".format(numero_clusters_codo))\n",
    "    plt.scatter(data['FECHA'].iloc[0], data[val].iloc[0], facecolors='none', edgecolors='none', label =\"Número de clusters según el método de la silueta: {}\".format(numero_clusters_silueta) )\n",
    "    \n",
    "    # Añadir títulos y etiquetas\n",
    "    plt.title('Gráfico')\n",
    "    plt.xlabel('FECHA')\n",
    "    plt.ylabel(f\"{val}\")\n",
    "    \n",
    "    # Crear la leyenda\n",
    "    leyenda = plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sal_agru( data ):\n",
    "    ml1 = data.copy()\n",
    "    dic_aux = ml1.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "    for cedula in dic_aux:\n",
    "        dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                                if isinstance(sal, str) \n",
    "                                                else [float(sal)]\n",
    "                                                for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                            ]\n",
    "        # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "        salarios = None\n",
    "        salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist] #Crea una lista individual\n",
    "        dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "        dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "        dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "        dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "        dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "    data1 = { 'CEDULA_COD': [], 'LS': [] }\n",
    "\n",
    "    for cedula, val in dic_aux.items():\n",
    "        data1['CEDULA_COD'].append(cedula)\n",
    "        data1['LS'].append( val['LS'] )\n",
    "\n",
    "    LS = pd.DataFrame( data1 )\n",
    "    LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "    data.loc[:, 'LS_AS'] = data['CEDULA_COD'].map(LS)\n",
    "\n",
    "    del dic_aux, data1\n",
    "\n",
    "    dic_sim = ml1.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'LS2':list,'LS_AS':list,'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "    for cedula in dic_sim:\n",
    "        dic_sim[cedula]['SALARIO_SECTOR'] = [[float(val) for val in sal.split(';')] if isinstance(sal, str) else [sal] \n",
    "                                              for sal in dic_sim[cedula]['SALARIO_SECTOR']]\n",
    "        \n",
    "        min_ls = [min(ls2, ls_as) for ls2, ls_as in zip(dic_sim[cedula]['LS2'], dic_sim[cedula]['LS_AS'])]\n",
    "        \n",
    "        dic_sim[cedula]['ATI_KM_AS'] = [ 1 if any(sal > ls for sal in salarios) else 0 \n",
    "                                        for salarios, ls in zip( dic_sim[cedula]['SALARIO_SECTOR'], min_ls )]\n",
    "\n",
    "    data1 = { 'CEDULA_COD': [], 'SALARIO_SECTOR': [], \n",
    "              'LS_AS' : [], 'ATI_KM_AS':[],  'INDICE':[]}\n",
    "\n",
    "    # Llenar las listas con los datos del diccionario\n",
    "    for cedula, values in dic_sim.items():\n",
    "        salario = values['SALARIO_SECTOR']\n",
    "        ls = values[ 'LS_AS' ]\n",
    "        atipico = values[ 'ATI_KM_AS' ]\n",
    "        indice = values['INDICE']\n",
    "        num_rows = len(salario)\n",
    "\n",
    "        # Extender las listas en el diccionario de datos\n",
    "        data1['CEDULA_COD'].extend([cedula] * num_rows)\n",
    "        data1['SALARIO_SECTOR'].extend(salario)\n",
    "        data1['LS_AS' ].extend(ls)\n",
    "        data1['ATI_KM_AS' ].extend(atipico)\n",
    "        data1['INDICE'].extend(indice)\n",
    "\n",
    "    data1 = pd.DataFrame( data1 )\n",
    "    data1.set_index('INDICE', inplace=True )\n",
    "    cedul = list(dic_sim.keys())  #total de 111903\n",
    "    filtro = data1[ data1['CEDULA_COD'].isin(cedul )] # 111903 cedulas\n",
    "    indi = filtro.index\n",
    "    data.loc[ indi, 'ATI_KM_AS'] = filtro['ATI_KM_AS']\n",
    "\n",
    "    del data1, filtro, dic_sim , indi, cedul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfc8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data_l['CEDULA_COD'].drop_duplicates().sample(n=20000, random_state=1)\n",
    "muestra = data_l[data_l['CEDULA_COD'].isin(grouped)]\n",
    "muestra.to_csv('muestra.txt', sep='\\t', index=False)# Agrupar por CEDULA_COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52929e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobación de la clasificación del k-mean\n",
    "# valor de - 2 implica salarios clasificados en un único cluster\n",
    "# valor de -1 implica un unico valor en la clasificación. \n",
    "# valor de 0 no es atipico\n",
    "# valor de 1 es atípico\n",
    "\n",
    "inicio = time.time()\n",
    "#Se trabaja primero con las cédulas que tienen un único sector\n",
    "data = data_l[data_l['GRUPO_SEL']==1]\n",
    "nodata = data_l[data_l['GRUPO_SEL']==0]\n",
    "del data_l\n",
    "gc.collect()\n",
    "\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()\n",
    "cedula_1 = data.groupby('CEDULA_COD')['NUM_SEC_MES'].apply( lambda x: (x != 1).any() )\n",
    "cedula_dist = cedula_1[ cedula_1 ].index\n",
    "ul = data[ ~data['CEDULA_COD'].isin( cedula_dist )]\n",
    "ml = data[  data['CEDULA_COD'].isin( cedula_dist )]\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df112442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores de la clasificación\n",
    "#ul['ATI_KM_M1'].unique() # [0.,  1., -2.])\n",
    "#ul['ATI_KM_MS2'].unique() # [ 0.,  1., -1.]\n",
    "#ul['ATI_KM_M3'].unique() # [ 0.,  1., -2.]\n",
    "#ul['ATI_KM_MS4'].unique() # array([ 0.,  1., -2.])\n",
    "\n",
    "#ml['ATI_KM_M1'].unique() # [0.,  1., -2.]\n",
    "#ml['ATI_KM_MS2'].unique() # [ 0.,  1., -1.]\n",
    "#ml['ATI_KM_M3'].unique() # [ 0.,  1., -2.]\n",
    "ml['ATI_KM_MS4'].unique() # [ 0.,  1., -2.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se analiza los casos con únicos sectores\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ul[ (ul['ATI_KM_M1']==-2)]['CEDULA_COD'].nunique()) # 39768\n",
    "print('\\tCedulas con valor -1:', ul[ (ul['ATI_KM_M1']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ul[ (ul['ATI_KM_M1']== 0)]['CEDULA_COD'].nunique()) # 328434\n",
    "print('\\tCedulas con valor 1:',  ul[ (ul['ATI_KM_M1']== 1)]['CEDULA_COD'].nunique()) # 64785\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ul[ (ul['ATI_KM_MS2']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ul[ (ul['ATI_KM_MS2']==-1)]['CEDULA_COD'].nunique()) # 39768\n",
    "print('\\tCedulas con valor 0:',  ul[ (ul['ATI_KM_MS2']== 0)]['CEDULA_COD'].nunique()) # 333275\n",
    "print('\\tCedulas con valor 1:',  ul[ (ul['ATI_KM_MS2']== 1)]['CEDULA_COD'].nunique()) # 37479\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ul[ (ul['ATI_KM_M3']==-2)]['CEDULA_COD'].nunique()) # 39768\n",
    "print('\\tCedulas con valor -1:', ul[ (ul['ATI_KM_M3']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ul[ (ul['ATI_KM_M3']== 0)]['CEDULA_COD'].nunique()) # 328460\n",
    "print('\\tCedulas con valor 1:',  ul[ (ul['ATI_KM_M3']== 1)]['CEDULA_COD'].nunique()) # 64795\n",
    "print('*' * 50, 'Caso ', str( 4 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ul[ (ul['ATI_KM_MS4']==-2)]['CEDULA_COD'].nunique()) # 39768\n",
    "print('\\tCedulas con valor -1:', ul[ (ul['ATI_KM_MS4']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ul[ (ul['ATI_KM_MS4']== 0)]['CEDULA_COD'].nunique()) #  333276\n",
    "print('\\tCedulas con valor 1:',  ul[ (ul['ATI_KM_MS4']== 1)]['CEDULA_COD'].nunique()) #  37388"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3639487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se analiza los casos con MULTIPLES sectores\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ml[ (ml['ATI_KM_M1']==-2)]['CEDULA_COD'].nunique()) # 244\n",
    "print('\\tCedulas con valor -1:', ml[ (ml['ATI_KM_M1']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ml[ (ml['ATI_KM_M1']== 0)]['CEDULA_COD'].nunique()) # 68241\n",
    "print('\\tCedulas con valor 1:',  ml[ (ml['ATI_KM_M1']== 1)]['CEDULA_COD'].nunique()) # 21635\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ml[ (ml['ATI_KM_MS2']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ml[ (ml['ATI_KM_MS2']==-1)]['CEDULA_COD'].nunique()) # 244\n",
    "print('\\tCedulas con valor 0:',  ml[ (ml['ATI_KM_MS2']== 0)]['CEDULA_COD'].nunique()) # 69253\n",
    "print('\\tCedulas con valor 1:',  ml[ (ml['ATI_KM_MS2']== 1)]['CEDULA_COD'].nunique()) # 12984\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ml[ (ml['ATI_KM_M3']==-2)]['CEDULA_COD'].nunique()) # 244\n",
    "print('\\tCedulas con valor -1:', ml[ (ml['ATI_KM_M3']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ml[ (ml['ATI_KM_M3']== 0)]['CEDULA_COD'].nunique()) # 68244\n",
    "print('\\tCedulas con valor 1:',  ml[ (ml['ATI_KM_M3']== 1)]['CEDULA_COD'].nunique()) # 21639\n",
    "print('*' * 50, 'Caso ', str( 4 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ml[ (ml['ATI_KM_MS4']==-2)]['CEDULA_COD'].nunique()) # 244\n",
    "print('\\tCedulas con valor -1:', ml[ (ml['ATI_KM_MS4']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ml[ (ml['ATI_KM_MS4']== 0)]['CEDULA_COD'].nunique()) # 69253\n",
    "print('\\tCedulas con valor 1:',  ml[ (ml['ATI_KM_MS4']== 1)]['CEDULA_COD'].nunique()) # 12962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d06abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 1\n",
    "\n",
    "if  tp in [1,3]:\n",
    "    val=['CEDULA_COD', 'ANIO', 'MES', 'SALARIO', 'NUM_SEC_MES','GRUPO_SEL','SAL_PROM2','BASE_CAL','SBU','LS1','LS2','CLA_KM_M'+str(tp),\n",
    "         'ATI_KM_M'+str(tp),'NUM_CODO_M'+str(tp),'NUM_SILU_M'+str(tp),'LS_M'+str(tp),'CEN1_M'+str(tp),'CEN2_M'+str(tp)]\n",
    "if tp in [2,4]:\n",
    "    val=['CEDULA_COD', 'ANIO', 'MES', 'SALARIO', 'NUM_SEC_MES','GRUPO_SEL','SAL_PROM2','BASE_CAL','SBU','LS1','LS2','CLA_KM_MS'+str(tp),\n",
    "         'ATI_KM_MS'+str(tp),'ATI_KM_AS','NUM_CODO_M'+str(tp),'NUM_SILU_M'+str(tp),'LS_M'+str(tp),'CEN1_M'+str(tp),'CEN2_M'+str(tp)]\n",
    "\n",
    "#ul[ul['CEDULA_COD']==8851][val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab1dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se analizar los tipos de casos\n",
    "##Primero para el valor de -2\n",
    "#result = ul[ul['ATI_KM_M1'] == 1].groupby('CEDULA_COD')['SALARIO'].nunique()  #6037\n",
    "#filtered_result = result[result > 1]\n",
    "#filtered_result\n",
    "#result\n",
    "#ul[ (ul['ATI_KM_MS4']==-1)]['CEDULA_COD'].unique()\n",
    "#ul[ (ul['LS_M1'] < ul['CEN1_M1']) & (ul['LS_M1'] < ul['CEN2_M1'])]['CEDULA_COD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fef698",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_meses(ul ,5786, 'SALARIO', 1, grupo_sel = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul[ul['CEDULA_COD']==5786][val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ba470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ul[ (ul['ATI_KM_M1']==1) & (ul['SALARIO'] <= ul['SBU'])][val]\n",
    "#ul[ (ul['ATI_KM_MS4']==-2) & (ul['SALARIO'] > ul['LS2'])][val]\n",
    "#ul[ (ul['ATI_KM_M1']==1) & (ul['SALARIO'] <= ul['SBU'])][val]\n",
    "ul[ (ul['ATI_KM_M1']==1) & (ul['SALARIO'] <= ul['SBU'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -1, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_M1']==-1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -1, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_M1']==-1) & (ul['SALARIO'] > ul['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -2, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_M1']==-2)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -2, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_M1']==-2) & (ul['SALARIO'] > ul['LS2']) ]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_M1']==0) & (ul['SALARIO'] > ul['LS2'])]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como  1, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_M1']==1) & (ul['SALARIO'] <= ul['SBU']) ]['CEDULA_COD'].nunique())\n",
    "\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -1, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_MS2']==-1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -1, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_MS2']==-1) & (ul['SALARIO'] > ul['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -2, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_MS2']==-2)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -2, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_MS2']==-2) & (ul['SALARIO'] > ul['LS2']) ]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_MS2']==0) & (ul['SALARIO'] > ul['LS2'])]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como  1, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_MS2']==1) & (ul['SALARIO'] <= ul['SBU']) ]['CEDULA_COD'].nunique())\n",
    "\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -1, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_M3']==-1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -1, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_M3']==-1) & (ul['SALARIO'] > ul['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -2, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_M3']==-2)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -2, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_M3']==-2) & (ul['SALARIO'] > ul['LS2']) ]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_M3']==0) & (ul['SALARIO'] > ul['LS2'])]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como  1, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_M3']==1) & (ul['SALARIO'] <= ul['SBU']) ]['CEDULA_COD'].nunique())\n",
    "\n",
    "print('*' * 50, 'Caso ', str( 4 ), '*' * 50)\n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -1, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_MS4']==-1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -1, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_MS4']==-1) & (ul['SALARIO'] > ul['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -2, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_MS4']==-2)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como -2, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_MS4']==-2) & (ul['SALARIO'] > ul['LS2']) ]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ul[ (ul['ATI_KM_MS4']==0) & (ul['SALARIO'] > ul['LS2'])]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen un sector y que fue clasificado como  1, que se modificaran a no atipico:',\n",
    "ul[ (ul['ATI_KM_MS4']==1) & (ul['SALARIO'] <= ul['SBU']) ]['CEDULA_COD'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcciones para los salarios de sectores unicos\n",
    "##CASO1\n",
    "#El valor de -2 indica que una persona durante los menores años, siempre aporto lo mismo, por lo que no es atipico\n",
    "ul.loc[ (ul['ATI_KM_M1']== -1), 'ATI_KM_M1'] = 0\n",
    "ul.loc[ (ul['ATI_KM_M1']==-1) & (ul['SALARIO'] > ul['LS2']), 'ATI_KM_M1'] = 1\n",
    "ul.loc[ (ul['ATI_KM_M1']==-2) , 'ATI_KM_M1'] = 0\n",
    "ul.loc[ (ul['ATI_KM_M1']==-2) & (ul['SALARIO'] > ul['LS2']), 'ATI_KM_M1'] = 1\n",
    "#No hay valores de -1\n",
    "## ul[ (ul['ATI_KM_M1']==-1)]\n",
    "#Para los que se clasifican como no atipicos, pero su salario es mayor al LS2 (desde el 2000) de su HL\n",
    "ul.loc[ (ul['ATI_KM_M1']==0) & (ul['SALARIO'] > ul['LS2']) , 'ATI_KM_M1'] = 1\n",
    "# #Para los que se clasifican como atipicos, pero su valor es el SBU\n",
    "ul.loc[ (ul['ATI_KM_M1']==1) & (ul['SALARIO'] <= ul['SBU']) , 'ATI_KM_M1'] = 0\n",
    "\n",
    "##CASO2\n",
    "# #El valor de -1 indica que una persona durante los menores años, siempre aporto lo mismo, por lo que no es atipico\n",
    "ul.loc[ (ul['ATI_KM_MS2']== -1) , 'ATI_KM_MS2'] = 0\n",
    "ul.loc[ (ul['ATI_KM_MS2']==-1) & (ul['SALARIO'] > ul['LS2']), 'ATI_KM_MS2'] = 1\n",
    "ul.loc[ (ul['ATI_KM_MS2']==-2) , 'ATI_KM_MS2'] = 0\n",
    "ul.loc[ (ul['ATI_KM_MS2']==-2) & (ul['SALARIO'] > ul['LS2']), 'ATI_KM_MS2'] = 1\n",
    "#Para los que se clasifican como no atipicos, pero su valor es mayor al LS2 de su HL\n",
    "ul.loc[ (ul['ATI_KM_MS2']==0) & (ul['SALARIO'] > ul['LS2']) , 'ATI_KM_MS2'] = 1\n",
    "#Para los que se clasifican como atipicos, pero su valor es el SBU\n",
    "ul.loc[ (ul['ATI_KM_MS2']==1) & (ul['SALARIO'] <= ul['SBU']) , 'ATI_KM_MS2'] = 0\n",
    "\n",
    "##CASO3\n",
    "ul.loc[ (ul['ATI_KM_M3']== -1) , 'ATI_KM_M3'] = 0\n",
    "ul.loc[ (ul['ATI_KM_M3']==-1) & (ul['SALARIO'] > ul['LS2']), 'ATI_KM_M3'] = 1\n",
    "ul.loc[ (ul['ATI_KM_M3']== -2) , 'ATI_KM_M3'] = 0\n",
    "ul.loc[ (ul['ATI_KM_M3']==-2) & (ul['SALARIO'] > ul['LS2']), 'ATI_KM_M3'] = 1\n",
    "#Para los que se clasifican como no atipicos, pero su valor es mayor al LS2 de su HL\n",
    "ul.loc[ (ul['ATI_KM_M3']==0) & (ul['SALARIO'] > ul['LS2']) , 'ATI_KM_M3'] = 1\n",
    "#Para los que se clasifican como atipicos, pero su valor es el SBU\n",
    "ul.loc[ (ul['ATI_KM_M3']==1) & (ul['SALARIO'] <= ul['SBU']) , 'ATI_KM_M3'] = 0\n",
    "\n",
    "##CASO4\n",
    "#El valor de -1 indica que una persona durante los menores años, siempre aporto lo mismo, por lo que no es atipico\n",
    "ul.loc[ (ul['ATI_KM_MS4']== -1) , 'ATI_KM_MS4'] = 0\n",
    "ul.loc[ (ul['ATI_KM_MS4']==-1) & (ul['SALARIO'] > ul['LS2']), 'ATI_KM_MS4'] = 1\n",
    "ul.loc[ (ul['ATI_KM_MS4']== -2) , 'ATI_KM_MS4'] = 0\n",
    "ul.loc[ (ul['ATI_KM_MS4']==-2) & (ul['SALARIO'] > ul['LS2']), 'ATI_KM_MS4'] = 1\n",
    "#Para los que se clasifican como no atipicos, pero su valor es mayor al LS2 de su HL\n",
    "ul.loc[ (ul['ATI_KM_MS4']==0) & (ul['SALARIO'] > ul['LS2']) , 'ATI_KM_MS4'] = 1\n",
    "#Para los que se clasifican como atipicos, pero su valor es el SBU\n",
    "ul.loc[ (ul['ATI_KM_MS4']==1) & (ul['SALARIO'] <= ul['SBU']) , 'ATI_KM_MS4'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4f14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_meses(ul ,5786, 'SALARIO', 1, grupo_sel = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d61b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ml[ml['ATI_KM_M1'] == 1].groupby('CEDULA_COD')['SALARIO'].nunique()  #472   \n",
    "result\n",
    "#filtered_result = result[result > 1]\n",
    "#filtered_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_meses(ml ,472, 'SALARIO', 1, grupo_sel = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb828a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_agru( ml )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fc213",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b33f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -1, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_M1']==-1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -1, que se modificaran a  atipico:',\n",
    "ml[ (ml['ATI_KM_M1']==-1) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -2, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_M1']==-2)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -2, que se modificaran a  atipico:',\n",
    "ml[ (ml['ATI_KM_M1']==-2) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ml[ (ml['ATI_KM_M1']==0) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_M1']==1) & (ml['SALARIO'] <= ml['SBU']) ]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  1, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_M1'] == 1) & (ml['ATI_KM_AS'] == 0)]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ml[ (ml['ATI_KM_M1'] == 0) & (ml['ATI_KM_AS'] == 1)]['CEDULA_COD'].nunique())\n",
    "\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -1, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_MS2']==-1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -1, que se modificaran a  atipico:',\n",
    "ml[ (ml['ATI_KM_MS2']==-1) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -2, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_MS2']==-2)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -2, que se modificaran a  atipico:',\n",
    "ml[ (ml['ATI_KM_MS2']==-2) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ml[ (ml['ATI_KM_MS2']==0) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_MS2']==1) & (ml['SALARIO'] <= ml['SBU']) ]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  1, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_MS2'] == 1) & (ml['ATI_KM_AS'] == 0)]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ml[ (ml['ATI_KM_MS2'] == 0) & (ml['ATI_KM_AS'] == 1)]['CEDULA_COD'].nunique())\n",
    "\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -1, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_M3']==-1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -1, que se modificaran a  atipico:',\n",
    "ml[ (ml['ATI_KM_M3']==-1) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -2, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_M3']==-2)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -2, que se modificaran a  atipico:',\n",
    "ml[ (ml['ATI_KM_M3']==-2) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ml[ (ml['ATI_KM_M3']==0) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_M3']==1) & (ml['SALARIO'] <= ml['SBU']) ]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  1, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_M3'] == 1) & (ml['ATI_KM_AS'] == 0)]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ml[ (ml['ATI_KM_M3'] == 0) & (ml['ATI_KM_AS'] == 1)]['CEDULA_COD'].nunique())\n",
    "\n",
    "print('*' * 50, 'Caso ', str( 4 ), '*' * 50)\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -1, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_MS4']==-1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -1, que se modificaran a  atipico:',\n",
    "ml[ (ml['ATI_KM_MS4']==-1) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -2, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_MS4']==-2)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como -2, que se modificaran a  atipico:',\n",
    "ml[ (ml['ATI_KM_MS4']==-2) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ml[ (ml['ATI_KM_MS4']==0) & (ml['SALARIO'] > ml['LS2'])]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_MS4']==1) & (ml['SALARIO'] <= ml['SBU']) ]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  1, que se modificaran a no atipico:',\n",
    "ml[ (ml['ATI_KM_MS4'] == 1) & (ml['ATI_KM_AS'] == 0)]['CEDULA_COD'].nunique())\n",
    "print('\\tCedulas que tienen varios sectores y que fue clasificado como  0, que se modificaran a atipico:',\n",
    "ml[ (ml['ATI_KM_MS4'] == 0) & (ml['ATI_KM_AS'] == 1)]['CEDULA_COD'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CASO 1\n",
    "#El valor de -2 indica que una persona durante los menores años, siempre aporto lo mismo, por lo que no es atipico\n",
    "ml.loc[ (ml['ATI_KM_M1']==-1) , 'ATI_KM_M1'] = 0\n",
    "ml.loc[ (ml['ATI_KM_M1']==-1) & (ml['SALARIO'] > ml['LS2']), 'ATI_KM_M1'] = 1\n",
    "ml.loc[ (ml['ATI_KM_M1']==-2) , 'ATI_KM_M1'] = 0 \n",
    "ml.loc[ (ml['ATI_KM_M1']==-2) & (ml['SALARIO'] > ml['LS2']), 'ATI_KM_M1'] = 1\n",
    "#Para los que se clasifican como atipicos, pero su valor es el SBU\n",
    "ml.loc[ (ml['ATI_KM_M1']==0) & (ml['SALARIO'] > ml['LS2']) , 'ATI_KM_M1'] = 1\n",
    "ml.loc[ (ml['ATI_KM_M1']==1) & (ml['SALARIO'] <= ml['SBU']) , 'ATI_KM_M1'] = 0\n",
    "#Para cuando un valor de la suma de salarios es mayor al LS, como si fueran un solo aporte individual\n",
    "ml.loc[(ml['ATI_KM_M1'] == 1) & (ml['ATI_KM_AS'] == 0), 'ATI_KM_M1'] = ml['ATI_KM_AS']\n",
    "ml.loc[(ml['ATI_KM_M1'] == 0) & (ml['ATI_KM_AS'] == 1), 'ATI_KM_M1'] = ml['ATI_KM_AS']\n",
    "\n",
    "##CASO 2\n",
    "#El valor de -1 indica que una persona durante los menores años, siempre aporto lo mismo, por lo que no es atipico\n",
    "ml.loc[ (ml['ATI_KM_MS2']==-1) , 'ATI_KM_MS2'] = 0\n",
    "ml.loc[ (ml['ATI_KM_MS2']==-1) & (ml['SALARIO'] > ml['LS2']), 'ATI_KM_MS2'] = 1\n",
    "ml.loc[ (ml['ATI_KM_MS2']==-2 ) , 'ATI_KM_MS2'] = 0\n",
    "ml.loc[ (ml['ATI_KM_MS2']==-2) & (ml['SALARIO'] > ml['LS2']), 'ATI_KM_MS2'] = 1\n",
    "#Para los que se clasifican como atipicos, pero su valor es el SBU\n",
    "ml.loc[ (ml['ATI_KM_MS2']==0) & (ml['SALARIO'] > ml['LS2']) , 'ATI_KM_MS2'] = 1\n",
    "ml.loc[ (ml['ATI_KM_MS2']==1) & (ml['SALARIO'] <= ml['SBU']), 'ATI_KM_MS2'] = 0\n",
    "\n",
    "ml.loc[ (ml['ATI_KM_MS2'] == 1) & (ml['ATI_KM_AS'] == 0), 'ATI_KM_MS2'] = ml['ATI_KM_AS']\n",
    "ml.loc[ (ml['ATI_KM_MS2'] == 0) & (ml['ATI_KM_AS'] == 1), 'ATI_KM_MS2'] = ml['ATI_KM_AS']\n",
    "\n",
    "#Caso 3\n",
    "#El valor de -2 indica que una persona durante los menores años, siempre aporto lo mismo, por lo que no es atipico\n",
    "ml.loc[ (ml['ATI_KM_M3']==-1) , 'ATI_KM_M3'] = 0\n",
    "ml.loc[ (ml['ATI_KM_M3']==-1) & (ml['SALARIO'] > ml['LS2']), 'ATI_KM_M3'] = 1\n",
    "ml.loc[ (ml['ATI_KM_M3']==-2) , 'ATI_KM_M3'] = 0 \n",
    "ml.loc[ (ml['ATI_KM_M3']==-2) & (ml['SALARIO'] > ml['LS2']), 'ATI_KM_M3'] = 1\n",
    "#Para los que se clasifican como atipicos, pero su valor es el SBU\n",
    "ml.loc[ (ml['ATI_KM_M3']==0) & (ml['SALARIO'] > ml['LS2']) , 'ATI_KM_M3'] = 1\n",
    "ml.loc[ (ml['ATI_KM_M3']==1) & (ml['SALARIO'] <= ml['SBU']), 'ATI_KM_M3'] = 0\n",
    "#Para cuando un valor de la suma de salarios es mayor al LS, como si fueran un solo aporte individual\n",
    "ml.loc[(ml['ATI_KM_M3'] == 1) & (ml['ATI_KM_AS'] == 0), 'ATI_KM_M3'] = ml['ATI_KM_AS']\n",
    "ml.loc[(ml['ATI_KM_M3'] == 0) & (ml['ATI_KM_AS'] == 1), 'ATI_KM_M3'] = ml['ATI_KM_AS']\n",
    "\n",
    "##CASO 4\n",
    "#El valor de -1 indica que una persona durante los menores años, siempre aporto lo mismo, por lo que no es atipico\n",
    "ml.loc[ (ml['ATI_KM_MS4'] ==-1 ) , 'ATI_KM_MS4'] = 0\n",
    "ml.loc[ (ml['ATI_KM_MS4'] ==-1) & (ml['SALARIO'] > ml['LS2']), 'ATI_KM_MS4'] = 1\n",
    "ml.loc[ (ml['ATI_KM_MS4'] ==-2 ) , 'ATI_KM_MS4'] = 0\n",
    "ml.loc[ (ml['ATI_KM_MS4'] ==-2) & (ml['SALARIO'] > ml['LS2']), 'ATI_KM_MS4'] = 1\n",
    "#Para los que se clasifican como atipicos, pero su valor es el SBU\n",
    "ml.loc[ (ml['ATI_KM_MS4']==0) & (ml['SALARIO'] > ml['LS2']) , 'ATI_KM_MS4'] = 1\n",
    "ml.loc[ (ml['ATI_KM_MS4']==1) & (ml['SALARIO'] <= ml['SBU']) , 'ATI_KM_MS4'] = 0\n",
    "\n",
    "ml.loc[(ml['ATI_KM_MS4'] == 1) & (ml['ATI_KM_AS'] == 0), 'ATI_KM_MS4'] = ml['ATI_KM_AS']\n",
    "ml.loc[(ml['ATI_KM_MS4'] == 0) & (ml['ATI_KM_AS'] == 1), 'ATI_KM_MS4'] = ml['ATI_KM_AS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdbde46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cedulas que tiene datos atípicos luego de la corrección---------------------------------------------------------------------\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      ul[ (ul['ATI_KM_M1']==1) ]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      ml[ (ml['ATI_KM_M1']==1)]['CEDULA_COD'].nunique())\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      ul[ (ul['ATI_KM_MS2']==1) ]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      ml[ (ml['ATI_KM_MS2']==1)]['CEDULA_COD'].nunique())\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      ul[ (ul['ATI_KM_M3']==1) ]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      ml[ (ml['ATI_KM_M3']==1)]['CEDULA_COD'].nunique())\n",
    "print('*' * 50, 'Caso ', str( 4 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      ul[ (ul['ATI_KM_MS4']==1) ]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      ml[ (ml['ATI_KM_MS4']==1)]['CEDULA_COD'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d771c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se analiza los casos con únicos sectores\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ul[ (ul['ATI_KM_M1']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ul[ (ul['ATI_KM_M1']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ul[ (ul['ATI_KM_M1']== 0)]['CEDULA_COD'].nunique()) # 368349\n",
    "print('\\tCedulas con valor 1:',  ul[ (ul['ATI_KM_M1']== 1)]['CEDULA_COD'].nunique()) #  99151\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ul[ (ul['ATI_KM_MS2']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ul[ (ul['ATI_KM_MS2']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ul[ (ul['ATI_KM_MS2']== 0)]['CEDULA_COD'].nunique()) # 373021\n",
    "print('\\tCedulas con valor 1:',  ul[ (ul['ATI_KM_MS2']== 1)]['CEDULA_COD'].nunique()) # 83908\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ul[ (ul['ATI_KM_M3']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ul[ (ul['ATI_KM_M3']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ul[ (ul['ATI_KM_M3']== 0)]['CEDULA_COD'].nunique()) # 368371\n",
    "print('\\tCedulas con valor 1:',  ul[ (ul['ATI_KM_M3']== 1)]['CEDULA_COD'].nunique()) #  99165\n",
    "print('*' * 50, 'Caso ', str( 4 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ul[ (ul['ATI_KM_MS4']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ul[ (ul['ATI_KM_MS4']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ul[ (ul['ATI_KM_MS4']== 0)]['CEDULA_COD'].nunique()) #  373022\n",
    "print('\\tCedulas con valor 1:',  ul[ (ul['ATI_KM_MS4']== 1)]['CEDULA_COD'].nunique()) #  83894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66308f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se analiza los casos con MULTIPLES sectores\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ml[ (ml['ATI_KM_M1']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ml[ (ml['ATI_KM_M1']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ml[ (ml['ATI_KM_M1']== 0)]['CEDULA_COD'].nunique()) # 69484\n",
    "print('\\tCedulas con valor 1:',  ml[ (ml['ATI_KM_M1']== 1)]['CEDULA_COD'].nunique()) # 24549\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ml[ (ml['ATI_KM_MS2']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ml[ (ml['ATI_KM_MS2']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ml[ (ml['ATI_KM_MS2']== 0)]['CEDULA_COD'].nunique()) # 69484\n",
    "print('\\tCedulas con valor 1:',  ml[ (ml['ATI_KM_MS2']== 1)]['CEDULA_COD'].nunique()) # 24549\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ml[ (ml['ATI_KM_M3']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ml[ (ml['ATI_KM_M3']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ml[ (ml['ATI_KM_M3']== 0)]['CEDULA_COD'].nunique()) # 69484\n",
    "print('\\tCedulas con valor 1:',  ml[ (ml['ATI_KM_M3']== 1)]['CEDULA_COD'].nunique()) # 24549\n",
    "print('*' * 50, 'Caso ', str( 4 ), '*' * 50)\n",
    "print('\\tCedulas con valor -2:', ml[ (ml['ATI_KM_MS4']==-2)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor -1:', ml[ (ml['ATI_KM_MS4']==-1)]['CEDULA_COD'].nunique()) # 0\n",
    "print('\\tCedulas con valor 0:',  ml[ (ml['ATI_KM_MS4']== 0)]['CEDULA_COD'].nunique()) # 69484\n",
    "print('\\tCedulas con valor 1:',  ml[ (ml['ATI_KM_MS4']== 1)]['CEDULA_COD'].nunique()) # 24549"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffab4127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ul['CEDULA_COD'].nunique())\n",
    "print(ml['CEDULA_COD'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b97e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores de la clasificación\n",
    "#ul['ATI_KM_M1'].unique() # [0., 1.]\n",
    "#ul['ATI_KM_MS2'].unique() # [0., 1.]\n",
    "#ul['ATI_KM_M3'].unique() #[0., 1.]\n",
    "#ul['ATI_KM_MS4'].unique() # [0., 1.]\n",
    "\n",
    "#ml['ATI_KM_M1'].unique() # [0., 1.]\n",
    "#ml['ATI_KM_MS2'].unique() # [0., 1.]\n",
    "#ml['ATI_KM_M3'].unique() # [0., 1.]\n",
    "#ml['ATI_KM_MS4'].unique() #[0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0352b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se guardan resultados\n",
    "nombre_archivo = 'viu_k_mean_ul_cl_ati.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(ul, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_ml_cl_ati.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(ml, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_nodata_cl_ati.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(nodata, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del nodata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_ul_cl_ati.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul = pickle.load( archivo ) \n",
    "\n",
    "nombre_archivo = 'viu_k_mean_ml_cl_ati.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml = pickle.load( archivo ) \n",
    "\n",
    "nombre_archivo = 'viu_k_mean_nodata_cl_ati.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    nodata = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = ['CEDULA_COD', 'ANIO', 'MES', 'SALARIO', 'SALARIO_SECTOR', 'SECTOR_A','NUM_SEC_MES', '%_NUM_SECTOR', 'GRUPO', \n",
    "       'SAL_PROM_GRUPO', 'GRUPO_SEL', 'INI_CAL', 'FIN_CAL', 'BASE_CAL', 'SBU', 'ID_SBU', 'INDICE', 'LS1', 'SAL_PROM1',\n",
    "       'LS2', 'SAL_PROM2', 'CLA_KM_M1', 'ATI_KM_M1', 'CLA_KM_MS2', 'ATI_KM_MS2', 'CLA_KM_M3', 'ATI_KM_M3', 'CLA_KM_MS4',\n",
    "       'ATI_KM_MS4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43749fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kmean = pd.concat([nodata[val], ul[val], ml[val]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54576044",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_data_union_cl_ati.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(data_kmean, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351004d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.columns "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
