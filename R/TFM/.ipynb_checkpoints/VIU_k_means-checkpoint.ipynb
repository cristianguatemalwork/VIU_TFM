{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb12dac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:50:24.605596Z",
     "start_time": "2024-08-13T14:50:07.631346Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importación de librearías necesarias\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle  #Para guardar archivos\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "from pympler import asizeof #Para liberar memoria\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, to_rgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import kneed\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "semilla = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7a9f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:50:24.614659Z",
     "start_time": "2024-08-13T14:50:24.605596Z"
    }
   },
   "outputs": [],
   "source": [
    "#Path general de archivos\n",
    "if socket.gethostname()=='LAPTOP-PUSGG08B': #Ip de la laptop\n",
    "    ruta = \"E:/Cristian Guatemal/Master/Big Data y Ciencia de Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"E:/Cristian Guatemal/Master/Big Data y Ciencia de Datos/VIU_TFM/RData/TFM/\"\n",
    "elif socket.gethostname()=='PCUIOMTDAIE6382': #Ip del working\n",
    "    ruta =   \"D:/Master/Big_Data_Ciencia_Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"D:/Master/Big_Data_Ciencia_Datos/VIU_TFM/RData/TFM/\"\n",
    "# Ruta del archivo de pensionistas de vejez\n",
    "ruta_vj = ruta + 'POB_VEJ_CD656_NEW.dsv'\n",
    "# Ruta del archivo de historia laboral de pensionistas\n",
    "ruta_afi = ruta + 'APORTES_CD656_new.dsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e15e93b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:52:09.364061Z",
     "start_time": "2024-08-13T14:50:24.614659Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_clean_afi_sel_g_all_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    data_l = pickle.load( archivo )     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9249e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:52:09.374649Z",
     "start_time": "2024-08-13T14:52:09.366107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62130167, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_l.shape #(62130167, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217c4de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:53:09.274792Z",
     "start_time": "2024-08-13T14:52:09.376176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución es:  0.0  horas con  1.0  minutos y 35.826311349868774  segundos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "data_l = data_l.sort_values( by=[\"CEDULA_COD\",\"ANIO\", \"MES\"], ascending=[ True, True, True] )\n",
    "data_l.reset_index(inplace=True)\n",
    "data_l.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "data_l.drop(columns=['nuevo_indice'], inplace=True)\n",
    "data_l['INDICE'] = data_l.index\n",
    "\n",
    "#Casos de no análisis\n",
    "data_no_grupo = data_l[ (data_l['GRUPO_SEL']==0) ].copy()\n",
    "data_no_grupo['ATI_KM_M1'] = np.nan\n",
    "data_no_grupo['ATI_KM_M2'] = np.nan \n",
    "data_no_grupo['ATI_KM_M3'] = np.nan\n",
    "data_no_grupo['ATI_KM_M4'] = np.nan\n",
    "\n",
    "data_no_grupo['NUM_CODO_M1'] = np.nan\n",
    "data_no_grupo['NUM_CODO_M2'] = np.nan\n",
    "data_no_grupo['NUM_CODO_M3'] = np.nan\n",
    "data_no_grupo['NUM_CODO_M4'] = np.nan \n",
    "\n",
    "data_no_grupo['NUM_SILU_M1'] = np.nan\n",
    "data_no_grupo['NUM_SILU_M2'] = np.nan\n",
    "data_no_grupo['NUM_SILU_M3'] = np.nan\n",
    "data_no_grupo['NUM_SILU_M4'] = np.nan\n",
    "\n",
    "data_no_grupo['CEN1_M1'] = np.nan\n",
    "data_no_grupo['CEN1_M2'] = np.nan\n",
    "data_no_grupo['CEN1_M3'] = np.nan\n",
    "data_no_grupo['CEN1_M4'] = np.nan\n",
    "\n",
    "data_no_grupo['CEN2_M1'] = np.nan\n",
    "data_no_grupo['CEN2_M2'] = np.nan\n",
    "data_no_grupo['CEN2_M3'] = np.nan\n",
    "data_no_grupo['CEN2_M4'] = np.nan\n",
    "\n",
    "data_no_grupo['LS_M1'] = np.nan\n",
    "data_no_grupo['LS_M2'] = np.nan\n",
    "data_no_grupo['LS_M3'] = np.nan\n",
    "data_no_grupo['LS_M4'] = np.nan\n",
    "\n",
    "#Casos de análisis\n",
    "data = data_l[ (data_l['GRUPO_SEL']==1) ].copy()\n",
    "\n",
    "fin = time.time()  \n",
    "print('Tiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7388e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T14:58:33.541399Z",
     "start_time": "2024-08-13T14:53:09.442762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTiempo de ejecución es:  0.0  horas con  4.0  minutos y 17.910932302474976  segundos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se calcula los límites máximos y mínimos según el diagrama de caja y bigote\n",
    "##Caso 1: Para toda la historia laboral\n",
    "inicio = time.time()   \n",
    "grupo1 = data_l.copy()\n",
    "Q1 = grupo1.groupby('CEDULA_COD')['SALARIO'].quantile(0.25)\n",
    "Q3 = grupo1.groupby('CEDULA_COD')['SALARIO'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "LI = Q1 - 1.5 * IQR\n",
    "LS = Q3 + 1.5 * IQR\n",
    "data['LS1'] = data['CEDULA_COD'].map( LS )\n",
    "data_l['LS1'] = data_l['CEDULA_COD'].map( LS )\n",
    "\n",
    "##Caso 2: Para la historia laboral a partir del año 2000\n",
    "grupo2 = data_l[ data_l['ANIO']>=2000 ].copy()\n",
    "Q1 = grupo2.groupby('CEDULA_COD')['SALARIO'].quantile(0.25)\n",
    "Q3 = grupo2.groupby('CEDULA_COD')['SALARIO'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "LI = Q1 - 1.5 * IQR\n",
    "LS = Q3 + 1.5 * IQR\n",
    "data['LS2'] = data['CEDULA_COD'].map( LS )\n",
    "data_l['LS2'] = data_l['CEDULA_COD'].map( LS )\n",
    "\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos')\n",
    "\n",
    "del grupo1, grupo2, Q1, Q3, IQR, LI, LS\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176cf8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T15:03:30.186708Z",
     "start_time": "2024-08-13T15:03:29.043930Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf13b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:48:35.762933Z",
     "start_time": "2024-08-12T14:48:35.704893Z"
    }
   },
   "outputs": [],
   "source": [
    "#Funciones para hacer gráficos\n",
    "def graf_obs( data_filt, ced, tipo ):\n",
    "    valores = data_filt[ced][ tipo ]\n",
    "    plt.figure( figsize=(10, 6))\n",
    "    plt.scatter(range(len(valores)), valores, color='blue', marker='o')\n",
    "\n",
    "    # Etiquetas y título\n",
    "    plt.ylabel(\"USD\")\n",
    "    plt.title(\"Gráfico del Salario\")\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def graf_obs_kmean( data_filt, ced):\n",
    "    valores = np.array([[i + 1, valor] for i, valor in enumerate(data_filt[ced]['SALARIO'])])\n",
    "    n = data_filt[ced]['num_codo']\n",
    "    \n",
    "    # Aplicar KMeans\n",
    "    kmeans = KMeans(n_clusters=n, init='k-means++', n_init=10, random_state=42)\n",
    "    y_pred = kmeans.fit_predict(valores)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Colormap para los clusters\n",
    "    cmap = plt.get_cmap(\"jet\")\n",
    "    \n",
    "    scatter = plt.scatter(valores[:, 0], valores[:, 1], c=y_pred, cmap=cmap, label='_nolegend_')\n",
    "    \n",
    "    \n",
    "    plt.scatter(kmeans.cluster_centers_[:, 0],\n",
    "                kmeans.cluster_centers_[:, 1],\n",
    "                marker='^',\n",
    "                c=list(range(0,n)),\n",
    "                s=100,\n",
    "                linewidth=2,\n",
    "                edgecolor='black',\n",
    "                cmap=\"jet\",\n",
    "                label=[f'Clúster {i+1}' for i in range(n)])\n",
    "    plt.xlabel(\"Datos\")\n",
    "    plt.ylabel(\"USD\")\n",
    "    plt.title(\"Gráfico de Clústeres con Centroides\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "     # Crear manejadores de leyenda para los puntos\n",
    "    handles, labels = scatter.legend_elements(prop=\"colors\", alpha=0.6)\n",
    "    \n",
    "    # Añadir la leyenda para los puntos y los centroides\n",
    "    plt.legend( handles = handles, labels = [f'Clúster {i+1}' for i in range(n)], loc='best')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e91003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:48:38.199568Z",
     "start_time": "2024-08-12T14:48:35.764940Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7000c4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:49:38.325494Z",
     "start_time": "2024-08-12T14:48:38.201577Z"
    }
   },
   "outputs": [],
   "source": [
    "#Algortimos K-means\n",
    "cedula_1 = data.groupby('CEDULA_COD')['NUM_SEC_MES'].apply( lambda x: (x != 1).any() )\n",
    "cedula_dist = cedula_1[ cedula_1 ].index\n",
    "ul = data[ ~data['CEDULA_COD'].isin( cedula_dist )]\n",
    "ml = data[  data['CEDULA_COD'].isin( cedula_dist )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749dcf13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:49:38.356073Z",
     "start_time": "2024-08-12T14:49:38.329610Z"
    }
   },
   "outputs": [],
   "source": [
    "#Determinación del número de cluster según el método del codo y Silueta\n",
    "# Normalización de datos\n",
    "def data_norm( df1 ):\n",
    "    df = df1.copy()\n",
    "    me = df.groupby('CEDULA_COD')['SALARIO'].mean()\n",
    "    st = df.groupby('CEDULA_COD')['SALARIO'].std(0)\n",
    "    df['ME'] = df['CEDULA_COD'].map( me )\n",
    "    df['ST'] = df['CEDULA_COD'].map( st )\n",
    "    df['SALARIO_NORM'] = ( df['SALARIO'] - df['ME'] ) / df['ST'] \n",
    "    return df\n",
    "\n",
    "#Determinación del número de cluster por el método de la silueta\n",
    "def max_clust_silueta( silhouettes ):\n",
    "    silhouettes = np.array(silhouettes)\n",
    "    diferencias = np.abs(1 - silhouettes)\n",
    "    indice_cercano = np.argmin( diferencias )\n",
    "    return indice_cercano + 2\n",
    "\n",
    "#Determinar el número de cluster por el método del codo\n",
    "def num_cluster( data, num, num_sample, tipo, duplicados ):\n",
    "    print('*' * 102)\n",
    "    print('Determinación del número de clúster por el método del codo y silueta')\n",
    "    inicio = time.time()\n",
    "    \n",
    "    data_si_dic = data.copy()\n",
    "    \n",
    "    if( num_sample != 'todo' ):\n",
    "        sample_size = num_sample\n",
    "        sample_keys = random.sample( list(data_si_dic.keys()), min(sample_size, len(data_si_dic))) #Seleccion de cedulas\n",
    "        data_filt = {key: data_si_dic[key] for key in sample_keys if key in data_si_dic}\n",
    "    if (num_sample == 'todo' ):\n",
    "        data_filt = data_si_dic\n",
    "        \n",
    "    for ced  in data_filt:\n",
    "        \n",
    "        if( duplicados=='si'):\n",
    "            aux = np.array( data_filt[ced][ tipo ]).reshape(-1, 1)\n",
    "        \n",
    "        if( duplicados=='no'):\n",
    "            aux = np.unique( np.array( data_filt[ced][ tipo ])).reshape(-1, 1)\n",
    "        \n",
    "        if len(aux) <= 1:\n",
    "            data_filt[ced]['num_codo'] = 1\n",
    "            data_filt[ced]['max_silueta'] = 1\n",
    "           \n",
    "        \n",
    "        tf = min(num, len(aux) - 1) + 1\n",
    "        \n",
    "        distorsion = []\n",
    "        silueta = []\n",
    "\n",
    "        for i in range( 2, tf ):\n",
    "            km = KMeans( i, init = 'k-means++', n_init = 1, max_iter = 300, tol = 1e-4, random_state = semilla )\n",
    "            clustering = km.fit_predict( aux )\n",
    "\n",
    "            if( len( np.unique( clustering ) ) > 1):\n",
    "                distorsion.append( km.inertia_ )\n",
    "                silueta.append( metrics.silhouette_score(aux, clustering))\n",
    "            \n",
    "            else:\n",
    "                distorsion.append(0)\n",
    "                silueta.append(0)\n",
    "    \n",
    "        if( len(distorsion) > 1 and len(silueta) > 1 ):\n",
    "            data_filt[ced]['num_codo'] = kneed.KneeLocator(range(2, tf), distorsion[:tf], curve=\"convex\", \n",
    "                                                             direction=\"decreasing\").elbow or 1\n",
    "    \n",
    "            data_filt[ced]['max_silueta'] =  max_clust_silueta( silueta )\n",
    "        \n",
    "        else:\n",
    "            data_filt[ced]['num_codo'] = 1\n",
    "            data_filt[ced]['max_silueta'] = 1\n",
    "\n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "    print('*' * 102)\n",
    "    return data_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a9a5f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:52:38.145409Z",
     "start_time": "2024-08-12T14:49:38.358065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** Normalización Z-Score  ****************************************\n",
      "\tTiempo de ejecución es:  0.0  horas con  0.0  minutos y 6.184971809387207  segundos\n",
      "******************************************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalización de datos-Z-core\n",
    "print('*' * 40, 'Normalización Z-Score ', '*' * 40)\n",
    "inicio = time.time()\n",
    "ul1 =  data_norm( ul )\n",
    "ml1 =  data_norm( ml )\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "print('*' * 102)\n",
    "\n",
    "del ul, ml\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a2ad25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:52:39.780477Z",
     "start_time": "2024-08-12T14:52:38.299091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de cédulas 442570\n",
      "Cedulas que tienen un único sector 373069\n",
      "Cedulas que tienen más de un único sector 69501\n"
     ]
    }
   ],
   "source": [
    "print('Total de cédulas', data['CEDULA_COD'].nunique()) #442570\n",
    "print('Cedulas que tienen un único sector', ul1['CEDULA_COD'].nunique()) #373069\n",
    "print('Cedulas que tienen más de un único sector', ml1['CEDULA_COD'].nunique()) #69501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d5eea52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:53:30.352553Z",
     "start_time": "2024-08-12T14:52:39.850621Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ul_dic = ul1.groupby('CEDULA_COD').agg({'SALARIO': list,'SALARIO_NORM': list, 'INDICE': list}).to_dict(orient='index')\n",
    "ml_dic = ml1.groupby('CEDULA_COD').agg({'SALARIO': list,'SALARIO_NORM': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "del ul1, ml1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se aplica un muestreo para ver como funciona el algoritmo\n",
    "num = 5 # Número de cluster por defecto--máximo 5 se hace el supuesto por ser los mejores años\n",
    "muestra = 'todo' # muestra = 'todo' #Para que sea en todas las cedulas\n",
    "t1='SALARIO'\n",
    "#t2='SALARIO_NORM'\n",
    "duplicados = 'si'\n",
    "ul_dic_cluster1 = num_cluster( ul_dic, num, muestra, t1, duplicados ) \n",
    "ml_dic_cluster1 = num_cluster( ml_dic, num, muestra, t1, duplicados ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster1_ul.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto1 = ul_dic_cluster1\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto1, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster1_ml.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto2 = ml_dic_cluster1\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto2, archivo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5 \n",
    "muestra = 'todo' \n",
    "t1='SALARIO'\n",
    "#t2='SALARIO_NORM'\n",
    "duplicados = 'no'\n",
    "ul_dic_cluster2 = num_cluster( ul_dic, num, muestra, t1, duplicados )\n",
    "ml_dic_cluster2 = num_cluster( ml_dic, num, muestra, t1, duplicados )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78730d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster2_ul.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto3 = ul_dic_cluster2\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto3, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster2_ml.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto4 = ml_dic_cluster2\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto4, archivo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c53ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:02:53.409337Z",
     "start_time": "2024-08-08T15:02:42.217248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se redondea la variable 'SALARIO_NORM' a 4 decimales\n",
    "for key, value in ul_dic.items():\n",
    "    value['SALARIO_NORM'] = [ round(num, 4) for num in value['SALARIO_NORM'] ]\n",
    "    \n",
    "for key, value in ml_dic.items():\n",
    "    value['SALARIO_NORM'] = [ round(num, 4) for num in value['SALARIO_NORM'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1922a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:03:03.365910Z",
     "start_time": "2024-08-08T15:03:03.361640Z"
    }
   },
   "outputs": [],
   "source": [
    "def valores_nan(data):\n",
    "    result = {}\n",
    "    for cedula, info in data.items():\n",
    "        salario_norm_array = np.array(info['SALARIO_NORM'])\n",
    "        if np.isnan(salario_norm_array).any() or np.isinf(salario_norm_array).any():\n",
    "            result[cedula] = True\n",
    "        else:\n",
    "            result[cedula] = False\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32790a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T15:03:29.241683Z",
     "start_time": "2024-08-08T15:03:28.666770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtener resultados\n",
    "veri = valores_nan( ml_dic )\n",
    "ced_nan = []\n",
    "for cedula, has_na in veri .items():\n",
    "    if has_na:\n",
    "        ced_nan.append(cedula)\n",
    "ced_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092dc8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:00:53.351694Z",
     "start_time": "2024-08-12T15:00:52.996559Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_dic[2802556]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1c6f864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:01:41.259383Z",
     "start_time": "2024-08-12T15:00:59.436623Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se filtran los valores nan e infinitos para que no tenga problemas el kmeans\n",
    "ul_dic_filt_no_nan = { key: value for key, value in ul_dic.items()\n",
    "                      if not (np.isnan(value['SALARIO_NORM']).any() or np.isinf(value['SALARIO_NORM']).any())}\n",
    "\n",
    "ml_dic_filt_no_nan = { key: value for key, value in ml_dic.items()\n",
    "                      if not (np.isnan(value['SALARIO_NORM']).any() or np.isinf(value['SALARIO_NORM']).any())}\n",
    "\n",
    "ul_dic_filt_si_nan = { key: value for key, value in ul_dic.items()\n",
    "                       if any(np.isnan(x) or np.isinf(x) for x in value['SALARIO_NORM'])}\n",
    "ml_dic_filt_si_nan = { key: value for key, value in ml_dic.items()\n",
    "                       if any(np.isnan(x) or np.isinf(x) for x in value['SALARIO_NORM'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5 \n",
    "muestra = 'todo'\n",
    "#t1='SALARIO'\n",
    "t2='SALARIO_NORM'\n",
    "duplicados = 'si'\n",
    "ul_dic_cluster3 = num_cluster( ul_dic_filt_no_nan , num, muestra, t2, duplicados )\n",
    "ml_dic_cluster3 = num_cluster( ml_dic_filt_no_nan, num, muestra, t2, duplicados )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster3_ul.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto5 = ul_dic_cluster3\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto5, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster3_ml.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto6 = ml_dic_cluster3\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto6, archivo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8992734",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-08-08T15:05:17.429Z"
    }
   },
   "outputs": [],
   "source": [
    "num = 5 \n",
    "muestra = 'todo'\n",
    "#t1='SALARIO'\n",
    "t2='SALARIO_NORM'\n",
    "duplicados = 'no'\n",
    "ul_dic_cluster4 = num_cluster( ul_dic_filt_no_nan, num, muestra, t2, duplicados )\n",
    "ml_dic_cluster4 = num_cluster( ml_dic_filt_no_nan, num, muestra, t2, duplicados )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c823cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster4_ul.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto7 = ul_dic_cluster4\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto7, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster4_ml.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto8 = ml_dic_cluster4\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto8, archivo)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436ed6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:34:07.631473Z",
     "start_time": "2024-08-12T15:30:21.810019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster1_ul.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster1 = pickle.load( archivo ) \n",
    "    \n",
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster1_ml.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster1 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f843782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:56:17.746944Z",
     "start_time": "2024-08-12T14:56:17.700514Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se crea la función para agregar el número de cluster a la data por el método del codo y silueta\n",
    "def agregar_num_cluster( data, colname, data_dic1, data_dic2, tipo):\n",
    "    aux1 = None\n",
    "    aux2 = None\n",
    "    aux = None\n",
    "    all_aux = None\n",
    "    \n",
    "    aux1 = {key: {tipo: value[tipo]} for key, value in data_dic1.items()}\n",
    "    aux2 = {key: {tipo: value[tipo]} for key, value in data_dic2.items()}\n",
    "\n",
    "    aux = aux1 | aux2\n",
    "    \n",
    "    all_aux = pd.DataFrame.from_dict( aux, orient='index').reset_index().rename(columns={'index': 'CEDULA_COD'})\n",
    "    all_aux = all_aux.sort_values( by=[\"CEDULA_COD\"], ascending=[True] )  \n",
    "        \n",
    "    data[colname] = data['CEDULA_COD'].map( all_aux.set_index('CEDULA_COD')[tipo] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607bc6cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:56:20.880041Z",
     "start_time": "2024-08-12T14:56:20.245487Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62e123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:57:47.575375Z",
     "start_time": "2024-08-12T14:57:41.277440Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se agrega el número de cluster para el caso 1 con el método del codo\n",
    "colname = 'NUM_CODO_1'\n",
    "tipo = 'num_codo'\n",
    "agregar_num_cluster( data, colname, ul_dic_cluster1, ml_dic_cluster1, tipo)\n",
    "\n",
    "colname = 'NUM_SILUE_1'\n",
    "tipo = 'max_silueta'\n",
    "agregar_num_cluster( data, colname, ul_dic_cluster1, ml_dic_cluster1, tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11276fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:57:50.050399Z",
     "start_time": "2024-08-12T14:57:50.006364Z"
    }
   },
   "outputs": [],
   "source": [
    "data #442570 casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b321ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster2_ul.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster2 = pickle.load( archivo ) \n",
    "    \n",
    "# Cargar archivo-------------------------                                                                                                                    -----------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster2_ml.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster2 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660871bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:59:17.964246Z",
     "start_time": "2024-08-12T14:59:12.454962Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se agrega el número de cluster para el caso 2 con el método del codo\n",
    "colname = 'NUM_CODO_2'\n",
    "tipo = 'num_codo'\n",
    "agregar_num_cluster( data, colname, ul_dic_cluster2, ml_dic_cluster2, tipo)\n",
    "\n",
    "colname = 'NUM_SILUE_2'\n",
    "tipo = 'max_silueta'\n",
    "agregar_num_cluster( data, colname, ul_dic_cluster2, ml_dic_cluster2, tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604429e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T14:59:49.121057Z",
     "start_time": "2024-08-12T14:59:21.767043Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2784483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster3_ul.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster3 = pickle.load( archivo ) \n",
    "    \n",
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster3_ml.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster3 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42002070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:18:39.656700Z",
     "start_time": "2024-08-12T15:18:39.467594Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ul_dic_cluster3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21308\\495109440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mml_dic_filt_si_nan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclave\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_silueta'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mul_dic_cluster3_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mul_dic_cluster3\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mul_dic_filt_si_nan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mml_dic_cluster3_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mml_dic_cluster3\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mml_dic_filt_si_nan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ul_dic_cluster3' is not defined"
     ]
    }
   ],
   "source": [
    "for clave in ul_dic_filt_si_nan:\n",
    "    ul_dic_filt_si_nan[clave]['num_codo'] = -2\n",
    "    ul_dic_filt_si_nan[clave]['max_silueta'] = -2\n",
    "    \n",
    "for clave in ml_dic_filt_si_nan:\n",
    "    ml_dic_filt_si_nan[clave]['num_codo'] = -2\n",
    "    ml_dic_filt_si_nan[clave]['max_silueta'] = -2\n",
    "    \n",
    "ul_dic_cluster3_all = ul_dic_cluster3 | ul_dic_filt_si_nan\n",
    "ml_dic_cluster3_all = ml_dic_cluster3 | ml_dic_filt_si_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a15f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:19:24.866987Z",
     "start_time": "2024-08-12T15:19:18.422754Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se agrega el número de cluster para el caso 3 con el método del codo\n",
    "colname = 'NUM_CODO_3'\n",
    "tipo = 'num_codo'\n",
    "\n",
    "agregar_num_cluster( data, colname, ul_dic_cluster3_all, ml_dic_cluster3_all, tipo)\n",
    "\n",
    "colname = 'NUM_SILUE_3'\n",
    "tipo = 'max_silueta'\n",
    "agregar_num_cluster( data, colname, ul_dic_cluster3_all, ml_dic_cluster3_all, tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4284a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:27:13.161737Z",
     "start_time": "2024-08-12T15:19:27.774856Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster4_ul.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster4 = pickle.load( archivo ) \n",
    "    \n",
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster4_ml.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster4 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0765d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:34:39.696183Z",
     "start_time": "2024-08-12T15:34:39.580393Z"
    }
   },
   "outputs": [],
   "source": [
    "ul_dic_cluster4_all = ul_dic_cluster4 | ul_dic_filt_si_nan\n",
    "ml_dic_cluster4_all = ml_dic_cluster4 | ml_dic_filt_si_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f86d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:35:01.754377Z",
     "start_time": "2024-08-12T15:34:55.356430Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se agrega el número de cluster para el caso 4 con el método del codo\n",
    "colname = 'NUM_CODO_4'\n",
    "tipo = 'num_codo'\n",
    "agregar_num_cluster( data, colname, ul_dic_cluster4_all, ml_dic_cluster4_all, tipo)\n",
    "\n",
    "colname = 'NUM_SILUE_4'\n",
    "tipo = 'max_silueta'\n",
    "agregar_num_cluster( data, colname, ul_dic_cluster4_all, ml_dic_cluster4_all, tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d079e85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:35:56.936299Z",
     "start_time": "2024-08-12T15:35:04.974084Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293ef9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T15:41:03.334637Z",
     "start_time": "2024-08-12T15:38:44.632874Z"
    }
   },
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_data_num_clust.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto9 = data\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto9, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62edce89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:23:09.812786Z",
     "start_time": "2024-08-12T19:23:09.765040Z"
    }
   },
   "outputs": [],
   "source": [
    "#Se escojen dos cluster para trabajar\n",
    "def clasificacion_kmean( data_dic, n, val, tipo, duplicados ):\n",
    "    print('*' * 102)\n",
    "    print('Clasificación de las observaciones según cluster')\n",
    "    inicio = time.time()\n",
    "    n_tipo = 'ATI_KM_M' + str( tipo )\n",
    "    \n",
    "    nm1 = 'cent1_M'+ str( tipo )\n",
    "    nm2 = 'cent2_M'+ str( tipo )\n",
    "    ls = 'LS_M' + str( tipo)\n",
    "            \n",
    "    for ced in data_dic:\n",
    "        aux = None\n",
    "        \n",
    "        if( duplicados =='si'):\n",
    "            aux = np.array( data_dic[ced][ val ] ).reshape(-1, 1)\n",
    "        if( duplicados =='no'):\n",
    "            aux = np.unique( np.array( data_dic[ced][ val ] ) ).reshape(-1, 1)\n",
    "            \n",
    "        Q1 = np.quantile(aux, 0.25)\n",
    "        Q3 = np.quantile(aux, 0.75)\n",
    "        IQR = Q3-Q1\n",
    "        LI = Q1 - 1.5 * IQR\n",
    "        LS = Q3 + 1.5 * IQR\n",
    "\n",
    "        data_dic[ced][ls] = LS    \n",
    "            \n",
    "        if aux.shape[0] >= n:\n",
    "            \n",
    "            kmeans = KMeans( n_clusters = n, init = 'k-means++', n_init = 1, random_state = semilla)\n",
    "            clu = kmeans.fit_predict( aux ) + 1 \n",
    "            ncl = np.unique( clu )\n",
    "            centroide = np.array([[ np.nanmean( aux[clu == i], axis=0)[0], i ] for i in range(1, len(ncl) + 1)] ) \n",
    "            \n",
    "            if len( ncl ) == 1:\n",
    "                data_dic[ced][n_tipo] =  [-2] * len( aux ) #Clasificacion unica de todos los valores\n",
    "                data_dic[ced][nm1] = centroide[:,0][0]\n",
    "                data_dic[ced][nm2] = centroide[:,0][0]\n",
    "                \n",
    "            else:\n",
    "                cl_at = np.where( centroide[:,0] > (LS +  1e-8) )[0]\n",
    "                \n",
    "                mod_aux = np.zeros((len( aux ), 2) )\n",
    "                mod_aux[:, 0] = aux[:, 0]  \n",
    "                mod_aux[np.isin( clu, centroide[cl_at][:, 1]), 1] = 1\n",
    "                \n",
    "                data_dic[ced][n_tipo] = mod_aux[:, 1].tolist()\n",
    "                \n",
    "                if len(cl_at) ==0:\n",
    "                    data_dic[ced][nm1] =  np.nanmean( aux )\n",
    "                    data_dic[ced][nm2] =  np.nanmean( aux )\n",
    "                    \n",
    "                if len(cl_at)!=0: \n",
    "                    data_dic[ced][nm1] =  centroide[:,0][0]\n",
    "                    data_dic[ced][nm2] =  centroide[:,0][1]\n",
    "            \n",
    "        else:\n",
    "            data_dic[ced][n_tipo] =  [-1] * len( aux )\n",
    "            data_dic[ced][nm1] =  np.nan\n",
    "            data_dic[ced][nm2] =  np.nan\n",
    "\n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "    print('*' * 102)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a03d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T20:04:42.826098Z",
     "start_time": "2024-08-12T19:23:17.447206Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 2\n",
    "val = 'SALARIO'\n",
    "tipo = 1\n",
    "duplicados = 'si'\n",
    "\n",
    "clasificacion_kmean( ul_dic_cluster1, n, val, tipo, duplicados )\n",
    "clasificacion_kmean( ml_dic_cluster1, n, val, tipo, duplicados )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster1_ul_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto10 = ul_dic_cluster1\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto10, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster1_ml_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto11 = ml_dic_cluster1\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto11, archivo) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc40da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extensión para el caso de no duplicados\n",
    "def exten_duplicados( data_dic, val, tipo ):\n",
    "    nom = 'ATI_KM_M' + str( 2)\n",
    "    noms = 'ATI_KM_MS' + str( 2 )\n",
    "\n",
    "    for ced in data_dic:\n",
    "        ati = np.array( data_dic[ced][ nom ] )\n",
    "        contador = Counter( data_dic[ced][ val ] )\n",
    "\n",
    "        valores = np.array(list(contador.keys()))\n",
    "        cantidades = np.array(list(contador.values()))\n",
    "\n",
    "        # Crear un array estructurado\n",
    "        array_np = np.column_stack((valores, cantidades, ati ))\n",
    "        array_np\n",
    "        valores_repetidos = []\n",
    "        valores_columna3 = []\n",
    "\n",
    "        for fila in array_np:\n",
    "            valor_columna1 = fila[0]\n",
    "            num_repeticiones = int(fila[1])\n",
    "            valor_columna3 = fila[2]\n",
    "            valores_columna3.extend([valor_columna3] * num_repeticiones)\n",
    "\n",
    "\n",
    "        data_dic[ced][noms] = valores_columna3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa8f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************************\n",
      "Clasificación de las observaciones según cluster\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "val = 'SALARIO'\n",
    "tipo = 2\n",
    "duplicados = 'no'\n",
    "\n",
    "clasificacion_kmean( ul_dic_cluster2, n, val, tipo, duplicados )\n",
    "clasificacion_kmean( ml_dic_cluster2, n, val, tipo, duplicados )\n",
    "\n",
    "exten_duplicados( ul_dic_cluster2, val, tipo )\n",
    "exten_duplicados( ml_dic_cluster2, val, tipo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_dic_cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c842bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster2_ul_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto12 = ul_dic_cluster2\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto12, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster2_ml_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto13 = ml_dic_cluster2\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto13, archivo) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da714d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_dic_cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a10763",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "val = 'SALARIO_NORM'\n",
    "tipo = 3\n",
    "duplicados = 'si'\n",
    "\n",
    "clasificacion_kmean( ul_dic_cluster3, n, val, tipo, duplicados )\n",
    "clasificacion_kmean( ml_dic_cluster3, n, val, tipo, duplicados )\n",
    "\n",
    "for clave in ul_dic_filt_si_nan:\n",
    "    ul_dic_filt_si_nan[clave]['ATI_KM_M3'] = [-2] * len( ul_dic_filt_si_nan[clave]['SALARIO_NORM']) \n",
    "    ul_dic_filt_si_nan[clave]['LS_M3'] = np.nan\n",
    "    ul_dic_filt_si_nan[clave]['cent1_M3'] = np.nan\n",
    "    ul_dic_filt_si_nan[clave]['cent2_M3'] = np.nan \n",
    "    \n",
    "for clave in ml_dic_filt_si_nan:\n",
    "    ml_dic_filt_si_nan[clave]['ATI_KM_M3'] = [-2] * len( ml_dic_filt_si_nan[clave]['SALARIO_NORM']) \n",
    "    ml_dic_filt_si_nan[clave]['LS_M3'] = np.nan\n",
    "    ml_dic_filt_si_nan[clave]['cent1_M3'] = np.nan\n",
    "    ml_dic_filt_si_nan[clave]['cent2_M3'] = np.nan \n",
    "    \n",
    "ul_dic_cluster3_all = ul_dic_cluster3 | ul_dic_filt_si_nan\n",
    "ml_dic_cluster3_all = ml_dic_cluster3 | ml_dic_filt_si_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe446f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_dic_cluster3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster3_ul_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto14 = ul_dic_cluster3_all\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto14, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster3_ml_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto15 = ml_dic_cluster3_all\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto15, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "val = 'SALARIO_NORM'\n",
    "tipo = 4\n",
    "duplicados = 'no'\n",
    "\n",
    "clasificacion_kmean( ul_dic_cluster4, n, val, tipo, duplicados )\n",
    "clasificacion_kmean( ml_dic_cluster4, n, val, tipo, duplicados )\n",
    "\n",
    "exten_duplicados( ul_dic_cluster4, val, tipo )\n",
    "exten_duplicados( ml_dic_cluster4, val, tipo )\n",
    "\n",
    "for clave in ul_dic_filt_si_nan:\n",
    "    ul_dic_filt_si_nan[clave]['ATI_KM_M4'] = [-2] * len( ul_dic_filt_si_nan[clave]['SALARIO_NORM'])  \n",
    "    ul_dic_filt_si_nan[clave]['ATI_KM_MS4'] = [-2] * len( ul_dic_filt_si_nan[clave]['SALARIO_NORM']) \n",
    "    ul_dic_filt_si_nan[clave]['LS_M4'] = np.nan\n",
    "    ul_dic_filt_si_nan[clave]['cent1_M4'] = np.nan\n",
    "    ul_dic_filt_si_nan[clave]['cent2_M4'] = np.nan \n",
    "    \n",
    "for clave in ml_dic_filt_si_nan:\n",
    "    ml_dic_filt_si_nan[clave]['ATI_KM_M4'] = [-2] * len( ml_dic_filt_si_nan[clave]['SALARIO_NORM']) \n",
    "    ml_dic_filt_si_nan[clave]['ATI_KM_MS4'] = [-2] * len( ml_dic_filt_si_nan[clave]['SALARIO_NORM']) \n",
    "    ml_dic_filt_si_nan[clave]['LS_M4'] = np.nan\n",
    "    ml_dic_filt_si_nan[clave]['cent1_M4'] = np.nan\n",
    "    ml_dic_filt_si_nan[clave]['cent2_M4'] = np.nan \n",
    "    \n",
    "    \n",
    "ul_dic_cluster4_all = ul_dic_cluster4 | ul_dic_filt_si_nan\n",
    "ml_dic_cluster4_all = ml_dic_cluster4 | ml_dic_filt_si_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2080948",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_k_mean_cluster4_ul_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto16 = ul_dic_cluster4_all\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto16, archivo) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster4_ml_2.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto17 = ml_dic_cluster4_all\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto17, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f30c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T15:10:37.235655Z",
     "start_time": "2024-08-13T15:09:57.731152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster1_ul_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster1 = pickle.load( archivo ) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster1_ml_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster1 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e866c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T15:17:57.617298Z",
     "start_time": "2024-08-13T15:17:55.985442Z"
    }
   },
   "outputs": [],
   "source": [
    "ml_dic_cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f9744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T20:03:49.219281Z",
     "start_time": "2024-08-13T20:03:49.025085Z"
    }
   },
   "outputs": [],
   "source": [
    "#Para unir los resultados\n",
    "def extend_data( data_val_ati, k ):\n",
    "    inicio = time.time()\n",
    "    print('Extensión a dataframe de los diccionarios')\n",
    "    nom = 'ATI_KM_M' + str( k )\n",
    "    codo = 'num_codo'\n",
    "    silu = 'max_silueta'\n",
    "    ls = 'LS_M' + str( k )\n",
    "    cent1 = 'cent1_M'+ str(k)\n",
    "    cent2 = 'cent2_M'+ str(k)\n",
    "    \n",
    "    data1 = { 'CEDULA_COD': [], 'SALARIO': [], nom : [], 'INDICE':[], codo:[], silu:[], ls:[],cent1:[], cent2:[] }\n",
    "\n",
    "    # Llenar las listas con los datos del diccionario\n",
    "    for cedula, values in data_val_ati.items():\n",
    "        salario = values['SALARIO']\n",
    "        atipico = values[ nom ]\n",
    "        indice = values['INDICE']\n",
    "        numcodo = values[codo]\n",
    "        numsilu = values[silu]\n",
    "        numls = values[ls]\n",
    "        ncl1 = values[cent1]\n",
    "        ncl2 = values[cent2]\n",
    "        num_rows = len(salario)\n",
    "\n",
    "        # Extender las listas en el diccionario de datos\n",
    "        data1['CEDULA_COD'].extend([cedula] * num_rows)\n",
    "        data1['SALARIO'].extend(salario)\n",
    "        data1[ nom ].extend(atipico)\n",
    "        data1[ codo ].extend([numcodo] * num_rows)\n",
    "        data1[ silu ].extend([numsilu] * num_rows)\n",
    "        data1[ ls ].extend([numls] * num_rows)\n",
    "        data1[ cent1 ].extend([ ncl1 ] * num_rows)\n",
    "        data1[ cent2 ].extend([ ncl2 ] * num_rows)\n",
    "        data1['INDICE'].extend(indice)\n",
    "        \n",
    "    data1 = pd.DataFrame( data1 )\n",
    "    data1.rename(columns={ codo: f'NUM_CODO_M{str(k)}', silu: f'NUM_SILU_M{str(k)}',\n",
    "                           ls: f'LS_M{str(k)}', cent1: f'CEN1_M{str(k)}', cent2:f'CEN2_M{str(k)}'}, inplace=True)\n",
    "    \n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23ee18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T19:46:27.441672Z",
     "start_time": "2024-08-13T19:43:09.304632Z"
    }
   },
   "outputs": [],
   "source": [
    "#Union de resultados con el dataframe data_l\n",
    "def union_dic( data, data_no_grupo, data_dic, k):\n",
    "    inicio = time.time()\n",
    "    print('*' * 102)\n",
    "    print('Unión de la extensión con los datos originales para el caso', str(k))\n",
    "    nom = 'ATI_KM_M'   + str(k)\n",
    "    sil = 'NUM_SILU_M' + str(k)\n",
    "    cod = 'NUM_CODO_M' + str(k)\n",
    "    ls = 'LS_M' + str(k)\n",
    "    cen1= 'CEN1_M' +str(k)\n",
    "    cen2= 'CEN2_M' +str(k)\n",
    "\n",
    "    data1 = extend_data( data_dic, k ) \n",
    "    data_kmean = None\n",
    "    data_kmean = pd.concat( [ data_no_grupo[['CEDULA_COD', 'SALARIO', nom, cod, sil, ls, cen1, cen2, 'INDICE']],\n",
    "                              data1[['CEDULA_COD', 'SALARIO', nom, cod, sil, ls, cen1, cen2, 'INDICE']] ], axis=0)\n",
    "\n",
    "\n",
    "    data_kmean = data_kmean.sort_values( by=[\"INDICE\"], ascending=[ True ] )\n",
    "    data_kmean.reset_index(inplace=True)\n",
    "    data_kmean.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "    data_kmean.drop(columns=['nuevo_indice'], inplace=True)\n",
    "\n",
    "    col = [nom, cod, sil, ls, cen1, cen2]\n",
    "    data[ col ] = np.nan\n",
    "\n",
    "    for nom_col in col:\n",
    "        aux = None\n",
    "        aux = data_kmean[ nom_col ].to_numpy()\n",
    "        data.iloc[:, data.columns.get_loc( nom_col )] = aux\n",
    "        \n",
    "    print('Concatenación con el dataframe original')    \n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8861428",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic_union = ul_dic_cluster1 | ml_dic_cluster1\n",
    "union_dic( data_l, data_no_grupo, data_dic_union, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdca120",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c11b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificación de errores\n",
    "nombre_archivo = 'viu_k_mean_data_l_cl.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto18 = data_l\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto18, archivo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_k_mean_cluster2_ul_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ul_dic_cluster2 = pickle.load( archivo ) \n",
    "    \n",
    "nombre_archivo = 'viu_k_mean_cluster2_ml_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    ml_dic_cluster2 = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extensión para el caso de no duplicados\n",
    "def exten_duplicados( data_dic, val, tipo ):\n",
    "    nom = 'ATI_KM_M' + str( 2)\n",
    "    noms = 'ATI_KM_MS' + str( 2 )\n",
    "\n",
    "    for ced in data_dic:\n",
    "        ati = np.array( data_dic[ced][ nom ] )\n",
    "        contador = Counter( data_dic[ced][ val ] )\n",
    "\n",
    "        valores = np.array(list(contador.keys()))\n",
    "        cantidades = np.array(list(contador.values()))\n",
    "\n",
    "        # Crear un array estructurado\n",
    "        array_np = np.column_stack((valores, cantidades, ati ))\n",
    "        array_np\n",
    "        valores_repetidos = []\n",
    "        valores_columna3 = []\n",
    "\n",
    "        for fila in array_np:\n",
    "            valor_columna1 = fila[0]\n",
    "            num_repeticiones = int(fila[1])\n",
    "            valor_columna3 = fila[2]\n",
    "            valores_columna3.extend([valor_columna3] * num_repeticiones)\n",
    "\n",
    "\n",
    "        data_dic[ced][noms] = valores_columna3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 'SALARIO'\n",
    "tipo = 2\n",
    "exten_duplicados( ul_dic_cluster2, val, tipo )\n",
    "exten_duplicados( ml_dic_cluster2, val, tipo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul_dic_cluster2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
