{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fbe0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librearías necesarias\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle  #Para guardar archivos\n",
    "import os\n",
    "\n",
    "from pympler import asizeof #Para liberar memoria\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, to_rgb\n",
    "\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d54d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path general de archivos\n",
    "if socket.gethostname()=='LAPTOP-PUSGG08B': #Ip de la laptop\n",
    "    ruta = \"E:/Cristian Guatemal/Master/Big Data y Ciencia de Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"E:/Cristian Guatemal/Master/Big Data y Ciencia de Datos/VIU_TFM/RData/TFM/\"\n",
    "elif socket.gethostname()=='PCUIOMTDAIE6382': #Ip del working\n",
    "    ruta =   \"D:/Master/Big_Data_Ciencia_Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"D:/Master/Big_Data_Ciencia_Datos/VIU_TFM/RData/TFM/\"\n",
    "# Ruta del archivo de pensionistas de vejez\n",
    "ruta_vj = ruta + 'POB_VEJ_CD656_NEW.dsv'\n",
    "# Ruta del archivo de historia laboral de pensionistas\n",
    "ruta_afi = ruta + 'APORTES_CD656_new.dsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981417f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_clean_afi_sel_g_all_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    data_l = pickle.load( archivo )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5ba7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62130167, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_l.shape #(62130167, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51aedb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución es: 0.0  horas con 1.0 minutos y 4.282320499420166 segundos\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "data_l = data_l.sort_values( by=[\"CEDULA_COD\",\"ANIO\", \"MES\"], ascending=[ True, True, True] )\n",
    "data_l.reset_index(inplace=True)\n",
    "data_l.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "data_l.drop(columns=['nuevo_indice'], inplace=True)\n",
    "data_l['INDICE'] = data_l.index\n",
    "data_l['ATI_CJ'] = np.nan\n",
    "\n",
    "#Casos de no análisis\n",
    "data_no_grupo = data_l[ (data_l['GRUPO_SEL']==0) ].copy()\n",
    "data_no_grupo['ATI_CJ'] = np.nan\n",
    "\n",
    "#Casos de análisis\n",
    "data = data_l[ (data_l['GRUPO_SEL']==1) ].copy()\n",
    "\n",
    "fin = time.time()  \n",
    "\n",
    "tm = fin-inicio\n",
    "print('Tiempo de ejecución es:',tm//3600,' horas con',tm%3600//60,'minutos y',tm%60, 'segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e250d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se calculo los bigotes superiores para toda la historia laboral\n",
    "inicio = time.time() \n",
    "dataa = data_l.copy()\n",
    "dic_aux = dataa.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['SAL_PROM1'] =  np.nanmean(salarios)\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': [], 'SAL_PROM1': [] }\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "    data1['SAL_PROM1'].append( val['SAL_PROM1'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l.loc[:, 'LS1'] = data_l['CEDULA_COD'].map(LS)\n",
    "\n",
    "SPROM = pd.DataFrame( data1 )\n",
    "SPROM = SPROM.groupby('CEDULA_COD')['SAL_PROM1'].first()\n",
    "data_l.loc[:, 'SAL_PROM1'] = data_l['CEDULA_COD'].map(SPROM)\n",
    "\n",
    "del dataa, data1, dic_aux, LS, salarios, SPROM\n",
    "gc.collect()\n",
    "\n",
    "##Se calculo los bigotes superiores para toda la historia laboral, a partir del año 2000 en adelante.\n",
    "dataa = data_l[data_l['ANIO']>=2000].copy()\n",
    "dic_aux = dataa.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['SAL_PROM2'] =  np.nanmean(salarios)\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': [], 'SAL_PROM2': []  }\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "    data1['SAL_PROM2'].append( val['SAL_PROM2'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l.loc[:, 'LS2'] = data_l['CEDULA_COD'].map(LS)\n",
    "\n",
    "SPROM = pd.DataFrame( data1 )\n",
    "SPROM = SPROM.groupby('CEDULA_COD')['SAL_PROM2'].first()\n",
    "data_l.loc[:, 'SAL_PROM2'] = data_l['CEDULA_COD'].map(SPROM)\n",
    "\n",
    "del dataa, data1, dic_aux, LS, salarios, SPROM\n",
    "gc.collect()\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin - inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89160f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l #cedulas unicas 442570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55adf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CEDULA_COD'].nunique() # cedulas unicas 442570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algortimos Cluster jerarquico\n",
    "inicio = time.time() \n",
    "\n",
    "cedula_1 = data.groupby('CEDULA_COD')['NUM_SEC_MES'].apply( lambda x: (x != 1).any() )\n",
    "cedula_dist = cedula_1[ cedula_1 ].index\n",
    "ul = data[ ~data['CEDULA_COD'].isin( cedula_dist )]\n",
    "ml = data[  data['CEDULA_COD'].isin( cedula_dist )]\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin - inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos')\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5116d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de cédulas en ul', ul['CEDULA_COD'].nunique()) #cedulas unicas 373069\n",
    "print('Número de cédulas en ml', ml['CEDULA_COD'].nunique()) #cedulas unicas 69501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade46e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se calculo los bigotes superiores para la historia laboral de los mejores años\n",
    "inicio = time.time() \n",
    "dataa = ul.copy()\n",
    "dic_aux = dataa.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': []}\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l.loc[ ~data_l['CEDULA_COD'].isin( cedula_dist ), 'LS_MS'] = data_l['CEDULA_COD'].map(LS)\n",
    "\n",
    "del dataa, data1, dic_aux, LS\n",
    "gc.collect()\n",
    "\n",
    "dataa = ml.copy()\n",
    "dic_aux = dataa.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': []}\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l.loc[  data_l['CEDULA_COD'].isin( cedula_dist ), 'LS_MS'] = data_l['CEDULA_COD'].map(LS)\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin - inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos')\n",
    "\n",
    "del dataa, data1, dic_aux, LS\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_l[ (~data_l['CEDULA_COD'].isin( cedula_dist )) & (data_l['LS_MS'].isna()) ]\n",
    "data_l[data_l['CEDULA_COD']==216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificación de valores LS calculados\n",
    "a = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                        if isinstance(sal, str) \n",
    "                                        else [float(sal)]\n",
    "                                        for sal in data_l[ (data_l['CEDULA_COD']==216)]['SALARIO_SECTOR']\n",
    "                                    ]\n",
    "# Aplanar la lista de listas de SALARIO_SECTOR\n",
    "salarios = None\n",
    "salarios = [salario for sublist in a for salario in sublist]\n",
    "salarios\n",
    "print('sal promedio', np.nanmean(salarios))\n",
    "q1=  np.percentile(salarios, 25)\n",
    "q3 =  np.percentile(salarios, 75)\n",
    "iqr = q3 -  q1\n",
    "print('Ls', q3+1.5*iqr)\n",
    "\n",
    "b = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                        if isinstance(sal, str) \n",
    "                                        else [float(sal)]\n",
    "                                        for sal in ml[ (ml['CEDULA_COD']==216) ]['SALARIO_SECTOR']\n",
    "                                    ]\n",
    "salarios = None\n",
    "salarios = [salario for sublist in b for salario in sublist]\n",
    "salarios\n",
    "print('sal promedio', np.nanmean(salarios))\n",
    "q1=  np.percentile(salarios, 25)\n",
    "q3 =  np.percentile(salarios, 75)\n",
    "iqr = q3 -  q1\n",
    "print('LS_MS', q3+1.5*iqr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46152792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ejecutar el cluster jerarquico\n",
    "def cluster_jerarquico( data_si_dic ):\n",
    "    print('Algoritmo Cluster Jerárquico')\n",
    "    inicio = time.time()\n",
    "    nom = 'ATI_CJ'\n",
    "    data_val_ati = {}\n",
    "    for cedula in data_si_dic:\n",
    "\n",
    "        if( len( data_si_dic[ cedula ]['SALARIO'] ) > 1 ): #Para formar al menos un cluster\n",
    "\n",
    "            aux = np.array( data_si_dic[ cedula ]['SALARIO'] ).reshape(-1, 1)\n",
    "            Z = linkage( aux , method='single', metric='euclidean')\n",
    "\n",
    "            num_clusters = 2  # Puedes ajustar este valor según tus necesidades\n",
    "            clusters = fcluster(Z, num_clusters, criterion='maxclust')\n",
    "\n",
    "            if( len( np.unique(clusters) ) > 1 ): #Para considerar al menos 2 cluster\n",
    "                # Calcular el centroide de cada clúster\n",
    "                cluster_centers = np.array([[ np.nanmean(aux[clusters == i], axis=0)[0], i ] for i in range(1, num_clusters + 1)] ) \n",
    "\n",
    "                Q1 = np.quantile(aux, 0.25)\n",
    "                Q3 = np.quantile(aux, 0.75)\n",
    "                IQR = Q3-Q1\n",
    "                LI = Q1 - 1.5 * IQR\n",
    "                LS = Q3 + 1.5 * IQR\n",
    "\n",
    "                cl_at = np.where( cluster_centers[:,0] > (LS +  1e-8) )[0]\n",
    "                cluster_centers[cl_at][:, 1]\n",
    "\n",
    "                mod_aux = np.zeros((len(aux), 2))\n",
    "                mod_aux[:, 0] = aux[:, 0]  # Copiar los valores originales de aux en la primera columna\n",
    "                mod_aux[np.isin(clusters, cluster_centers[cl_at][:, 1]), 1] = 1  # Asignar 1 en la segunda columna donde el cluster es 1\n",
    "\n",
    "                data_val_ati[cedula] = {'SALARIO': mod_aux[:, 0].tolist(),\n",
    "                                             nom : mod_aux[:, 1].tolist(),\n",
    "                                        'INDICE' : data_si_dic[ cedula ]['INDICE']}\n",
    "            else:\n",
    "                data_val_ati[cedula] = { 'SALARIO': aux.flatten().tolist(),\n",
    "                                               nom:  [-1] * len(aux),\n",
    "                                         'INDICE' : data_si_dic[ cedula ]['INDICE']} \n",
    "\n",
    "        else:\n",
    "            data_val_ati[cedula] = { 'SALARIO': data_si_dic[ cedula ]['SALARIO'],\n",
    "                                           nom:  [-2] * len( data_si_dic[ cedula ]['SALARIO'] ),\n",
    "                                     'INDICE' : data_si_dic[ cedula ]['INDICE']}\n",
    "    fin = time.time()  \n",
    "    tm = fin-inicio\n",
    "    print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos' )\n",
    "    \n",
    "    return data_val_ati\n",
    " \n",
    "#Para unir los resultados\n",
    "def extend_data( data_val_ati ):\n",
    "    print('Extensión del diccionario')\n",
    "    inicio = time.time()\n",
    "    nom = 'ATI_CJ'\n",
    "    data1 = { 'CEDULA_COD': [], 'SALARIO': [], nom : [], 'INDICE':[]}\n",
    "\n",
    "    # Llenar las listas con los datos del diccionario\n",
    "    for cedula, values in data_val_ati.items():\n",
    "        salario = values['SALARIO']\n",
    "        atipico = values[ nom ]\n",
    "        indice = values['INDICE']\n",
    "        num_rows = len(salario)\n",
    "\n",
    "        # Extender las listas en el diccionario de datos\n",
    "        data1['CEDULA_COD'].extend([cedula] * num_rows)\n",
    "        data1['SALARIO'].extend(salario)\n",
    "        data1[ nom ].extend(atipico)\n",
    "        data1['INDICE'].extend(indice)\n",
    "\n",
    "    fin = time.time()  \n",
    "    tm=fin-inicio\n",
    "    print('\\tTiempo de ejecución es: ',  tm//3600, ' horas con ' ,  tm%3600//60 , ' minutos y',  tm%60, ' segundos' )\n",
    "    return data1\n",
    "\n",
    "#Para graficar el comportamiento de los atipicos\n",
    "def graf_CJ(data_i, ced, val, grupo_sel = 0):\n",
    "    #Adecuación de la base de datos\n",
    "    idx = data_i.columns.get_loc('ATI_CJ')\n",
    "    columnas_requeridas = ['CEDULA_COD', 'ANIO', 'MES', val, 'GRUPO_SEL', 'INDICE', 'BASE_CAL'] + list(data_i.columns[idx:])\n",
    "    data = data_i[data_i['CEDULA_COD'] == ced][columnas_requeridas]\n",
    "    \n",
    "    # Establecer si se quieren todos o solos los 5 mejores años\n",
    "    if(grupo_sel == 1):\n",
    "        data = data[data['GRUPO_SEL']==1]\n",
    "    \n",
    "    #Fecha para eje x\n",
    "    anios = data['ANIO'].tolist()\n",
    "    meses = data['MES'].tolist()\n",
    "    fechas = [datetime(year=anio, month=mes, day=1) for anio, mes in zip(anios, meses)]\n",
    "    data['FECHA']= pd.to_datetime(fechas)\n",
    "    data = data.sort_values(by='FECHA')\n",
    "    \n",
    "    #Paleta de colores\n",
    "    colors = plt.get_cmap('tab20').colors\n",
    "\n",
    "    # Gráfico\n",
    "    plt.figure(figsize=(12, 8))  \n",
    "    marker_dict = {1: 'o', 2: 'x'} \n",
    "    \n",
    "    data_aux = data[data['GRUPO_SEL']==1]\n",
    "    if grupo_sel == 0: \n",
    "        Grupo_b= data[(data['GRUPO_SEL'] == 0)]\n",
    "        plt.scatter(Grupo_b['FECHA'], Grupo_b[val], marker= '^', color='yellow', label='Valores no considerados')\n",
    "        \n",
    "        if 0 in (data_aux['ATI_CJ'].unique()):\n",
    "            Grupo_a = data_aux[data_aux['ATI_CJ'] == 0]\n",
    "            plt.scatter(Grupo_a['FECHA'], Grupo_a[val], marker= marker_dict[1], color='blue', label='Valores No Atípicos : 0')\n",
    "\n",
    "        if 1 in (data_aux['ATI_CJ'].unique()):\n",
    "            Grupo= data_aux[data_aux['ATI_CJ'] == 1]\n",
    "            plt.scatter(Grupo['FECHA'], Grupo[val], marker= marker_dict[1], color= 'red', label='Valores Atípicos : 1')\n",
    "            \n",
    "        if -1 in (data_aux['ATI_CJ'].unique()):\n",
    "            Grupo= data_aux[data_aux['ATI_CJ'] == -1]\n",
    "            plt.scatter(Grupo['FECHA'], Grupo[val], marker= marker_dict[1], color= 'green', label='Clúster único')\n",
    "                \n",
    "    else:\n",
    "        if 0 in (data['ATI_CJ'].unique()):\n",
    "            Grupo_a = data[data['ATI_CJ'] == 0]\n",
    "            plt.scatter(Grupo_a['FECHA'], Grupo_a[val], marker= marker_dict[1], color='blue', label='Valores No Atípicos : 0')\n",
    "\n",
    "        if 1 in (data['ATI_CJ'].unique()):\n",
    "            Grupo= data[data['ATI_CJ'] == 1]\n",
    "            plt.scatter(Grupo['FECHA'], Grupo[val], marker= marker_dict[1], color= 'red', label='Valores Atípicos : 1')\n",
    "            \n",
    "        if -1 in (data['ATI_CJ'].unique()):\n",
    "            Grupo= data[data['ATI_CJ'] == -1]\n",
    "            plt.scatter(Grupo['FECHA'], Grupo[val], marker= marker_dict[1], color= 'green', label='Clúster único')\n",
    "        \n",
    "    \n",
    "    plt.axhline(y= data['SAL_PROM2'].iloc[0], color= '#1297ff', linestyle='-', label='Promedio Salarios')\n",
    "    plt.axhline(y=data['LS2'].iloc[0], alpha=1 , color= '#25ce00', linestyle='--', label='LS2')\n",
    "    plt.axhline(y=data_aux['LS_MS'].iloc[0], alpha=1, color= '#875b20', linestyle='--', label='LS_MS')\n",
    "    plt.axhline(y=data['BASE_CAL'].iloc[0], alpha=1, color= '#E800FF', linestyle=':', label='Base de cálculo')\n",
    "    \n",
    "    # Añadir el número de clusters, EPS, MINPTS\n",
    "    plt.scatter( data_aux['FECHA'].iloc[0], data_aux[val].iloc[0], facecolors='none', label=\"Número de clústers: {}\".format(int(max(data_aux['ATI_CJ'].unique()) + 1)))\n",
    "    \n",
    "    # Añadir títulos y etiquetas\n",
    "    plt.title(f\"Aportaciones de la cédula: {ced}\")\n",
    "    plt.xlabel('FECHA')\n",
    "    plt.ylabel(f\"{val}\")\n",
    "    \n",
    "    # Crear la leyenda\n",
    "    leyenda = plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tamaño de la data utilizada con un único sector dentro de los mejores años de sueldo', ul.shape) #(26006294, 16)\n",
    "print('Tamaño de la data utilizada con múltiples sectores dentro de los mejores años de sueldo', ml.shape) #(26006294, 16)\n",
    "print('Convertir el dataframe a diccionario')\n",
    "inicio = time.time()\n",
    "\n",
    "ul_dic = ul.groupby('CEDULA_COD').agg({'SALARIO': list, 'INDICE': list}).to_dict(orient='index')\n",
    "ml_dic = ml.groupby('CEDULA_COD').agg({'SALARIO': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin-inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos' )\n",
    "\n",
    "data_val_ati1 = cluster_jerarquico( ul_dic)\n",
    "data_val_ati2 = cluster_jerarquico( ml_dic)\n",
    "\n",
    "data1 = extend_data( data_val_ati1 )\n",
    "data2 = extend_data( data_val_ati2 )\n",
    "\n",
    "\n",
    "print('Concatenación de dataframe')\n",
    "inicio = time.time()\n",
    "nom = 'ATI_CJ'\n",
    "data_jerar = None\n",
    "data_jerar = pd.concat( [ data_no_grupo[['CEDULA_COD', 'SALARIO',  nom , 'INDICE']],\n",
    "                          pd.DataFrame( data1 ), pd.DataFrame( data2 ) ], axis=0)\n",
    "\n",
    "data_jerar = data_jerar.sort_values( by=[\"INDICE\"], ascending=[ True ] )\n",
    "data_jerar.reset_index(inplace=True)\n",
    "data_jerar.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "data_jerar.drop(columns=['nuevo_indice'], inplace=True)\n",
    "\n",
    "col = ['ATI_CJ']\n",
    "\n",
    "for nom_col in col:\n",
    "    aux = None\n",
    "    aux = data_jerar[ nom_col ].to_numpy()\n",
    "    data_l.iloc[:, data_l.columns.get_loc( nom_col )] = aux\n",
    "\n",
    "del data1, data2, data_val_ati1, data_val_ati2, ul_dic, ml_dic, data_jerar, aux\n",
    "gc.collect()\n",
    "    \n",
    "fin = time.time()  \n",
    "tm = fin-inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60 ,'minutos y',tm%60,'segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac0e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo = 'viu_cj_data_l_cl.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto18 = data_l\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto18, archivo) \n",
    "    \n",
    "del objeto18\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#El valor de -1 implica que se formó un solo cluster\n",
    "#El valor de -2 implica que en la selección de datos, la cedula solo tenía un único valor para formar los cluster\n",
    "# pues era el resultado de filtrar el data_si\n",
    "\n",
    "#Se analiza el caso de los valores de atipicos del método 1\n",
    "data_l[ ( data_l['GRUPO_SEL']==1 )]['ATI_CJ'].unique() #array([ 0.,  1., -1.])\n",
    "data_l['ATI_CJ'].unique() #array([nan,  0.,  1., -1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea40740",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l[ (data_l['CEDULA_COD'].isin( cedula_dist )) & (data_l['GRUPO_SEL']==1)]['ATI_CJ'].unique()  #array([ 0.,  1., -1.])\n",
    "data_l[ (~data_l['CEDULA_COD'].isin( cedula_dist )) & (data_l['GRUPO_SEL']==1)]['ATI_CJ'].unique() #array([ 0.,  1., -1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cedulas que tiene datos atípicos----------------------------------------------------------------------------------------------\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico:', data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ']==1)]['CEDULA_COD'].nunique()) #123850\n",
    "print('\\tCedulas con valor -1:',            data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ']==-1)]['CEDULA_COD'].nunique()) #52121\n",
    "print('\\tCedulas con valor 0:',             data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ']==0)]['CEDULA_COD'].nunique()) #383682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd1e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ']==1)]['CEDULA_COD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fec512",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_CJ(data_l , 37165, 'SALARIO',  grupo_sel = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08038ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = np.array(data_l[ ( data_l['CEDULA_COD']==37165) & (data_l['GRUPO_SEL']==1)]['SALARIO'] ).reshape(-1, 1)\n",
    "Z = linkage( aux , method='single', metric='euclidean')\n",
    "\n",
    "num_clusters = 2  # Puedes ajustar este valor según tus necesidades\n",
    "clusters = fcluster(Z, num_clusters, criterion='maxclust')\n",
    "print(clusters)\n",
    "# if( len( np.unique(clusters) ) > 1 ): #Para considerar al menos 2 cluster\n",
    "#     # Calcular el centroide de cada clúster\n",
    "cluster_centers = np.array([[ np.nanmean(aux[clusters == i], axis=0)[0], i ] for i in range(1, num_clusters + 1)] ) \n",
    "print(cluster_centers)\n",
    "Q1 = np.quantile(aux, 0.25)\n",
    "Q3 = np.quantile(aux, 0.75)\n",
    "IQR = Q3-Q1\n",
    "LI = Q1 - 1.5 * IQR\n",
    "LS = Q3 + 1.5 * IQR\n",
    "print(LS)\n",
    "cl_at = np.where( cluster_centers[:,0] > (LS +  1e-8) )[0]\n",
    "print(cl_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4134aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisis para atípicos\n",
    "del ul, ml\n",
    "gc.collect()\n",
    "\n",
    "inicio = time.time()\n",
    "data = data_l[ data_l['GRUPO_SEL'] == 1 ]\n",
    "nodata = data_l[ data_l['GRUPO_SEL'] == 0 ]\n",
    "cedula_1 = data.groupby('CEDULA_COD')['NUM_SEC_MES'].apply( lambda x: (x != 1).any() )\n",
    "cedula_dist = cedula_1[ cedula_1 ].index\n",
    "ul = data[ ~data['CEDULA_COD'].isin( cedula_dist )]\n",
    "ml = data[  data['CEDULA_COD'].isin( cedula_dist )]\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin-inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60 ,'minutos y',tm%60,'segundos' )\n",
    "\n",
    "del data_l\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefd4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Clasificacion para cedulas con único sector', ul['CEDULA_COD'].nunique()) #373069\n",
    "print('Clasificacion para cedulas con múltiples sectores', ml['CEDULA_COD'].nunique()) #69501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a31518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Clasificacion para cedulas con único sector', ul['ATI_CJ'].unique()) #[ 0.  1. -1.]\n",
    "print('Clasificacion para cedulas con múltiples sectores', ml['ATI_CJ'].unique()) # [ 0.  1. -1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf5373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso a modificarse para cedulas con un unico sector\n",
    "print('Cedulas con único sector, que fueron clasificados como -1',ul[ (ul['ATI_CJ'] == - 1 )]['CEDULA_COD'].nunique() ) #51259\n",
    "print('Cedulas con único sector, que fueron clasificados como  1',ul[ (ul['ATI_CJ'] == 1 )]['CEDULA_COD'].nunique() ) #94148\n",
    "print('Cedulas con único sector, que fueron clasificados como  0',ul[ (ul['ATI_CJ'] == 0 )]['CEDULA_COD'].nunique() ) #316286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30ca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso a modificarse\n",
    "print('Para las çedulas con único sector, que fueron clasificados como -1 y se clasificaran como atipico',\n",
    "      ul[ (ul['ATI_CJ'] == - 1 ) & (ul['SALARIO'] > ul[['LS2', 'LS_MS']].min(axis=1) )]['CEDULA_COD'].nunique() ) #3943\n",
    "print('Para las çedulas con único sector, que fueron clasificados como -1 y se clasificaran como no atipico',\n",
    "      ul[ (ul['ATI_CJ'] == - 1 ) & (ul['SALARIO'] <= ul[['LS2', 'LS_MS']].min(axis=1) )]['CEDULA_COD'].nunique() ) # 51247\n",
    "print('Para las çedulas con único sector, que fueron clasificados como -1 y se clasificaran como no atipico',\n",
    "      ul[ (ul['ATI_CJ'] == - 1 ) & (ul['SALARIO'] <= ul['SBU'] )]['CEDULA_COD'].nunique() ) # 8007\n",
    "\n",
    "print('Para las çedulas con único sector, que fueron clasificados como  1 y se clasificaran como no atipico',\n",
    "      ul[ (ul['ATI_CJ'] == 1 ) & (ul['SALARIO'] <= ul[['LS2', 'LS_MS']].min(axis=1) )]['CEDULA_COD'].nunique() ) # 10325\n",
    "print('Para las çedulas con único sector, que fueron clasificados como  1 y se clasificaran como no atipico',\n",
    "      ul[ (ul['ATI_CJ'] == 1 ) & (ul['SALARIO'] <= ul['SBU'] )]['CEDULA_COD'].nunique() ) # 8406\n",
    "print('Para las çedulas con único sector, que fueron clasificados como  0 y se clasificaran como atipico',\n",
    "      ul[ (ul['ATI_CJ'] == 0 ) & (ul['SALARIO'] > ul[['LS2', 'LS_MS']].min(axis=1) )]['CEDULA_COD'].nunique() ) #39877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_CJ(ul , 37165, 'SALARIO',  grupo_sel = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877faeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul[ul['CEDULA_COD']==37165]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcciones----------------------------------------------------------------------------------------------------------------\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es mayor a LS1 es atípico( -1 -> 1 )\n",
    "ul.loc[ (ul['ATI_CJ'] == - 1 ) & (ul['SALARIO'] > ul[['LS2', 'LS_MS']].min(axis=1) ) , 'ATI_CJ'] = 1 \n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a LS1 no es atípico( -1 -> 0 )\n",
    "ul.loc[ (ul['ATI_CJ'] == - 1 ) & (ul['SALARIO'] <= ul[['LS2', 'LS_MS']].min(axis=1) ), 'ATI_CJ'] = 0 \n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a un SBU no es atípico( -1 -> 0 )\n",
    "ul.loc[ (ul['ATI_CJ'] == - 1 ) & (ul['SALARIO'] <= ul['SBU'] ), 'ATI_CJ'] = 0 \n",
    "\n",
    "#Se hacen las correcciones para los valores 1, en donde si el Salario es menor o igual al min(ls2, ls_ms) no es atípico( 1 -> 0 )\n",
    "ul.loc[ (ul['ATI_CJ'] == 1 ) & (ul['SALARIO'] <= ul[['LS2', 'LS_MS']].min(axis=1) ), 'ATI_CJ'] = 0\n",
    "#Se hacen las correcciones para los valores de 1, en donde si el salario es menor al SBU no es atipico (1->0)\n",
    "ul.loc[ (ul['ATI_CJ'] == 1 ) & (ul['SALARIO'] <= ul['SBU'] ), 'ATI_CJ'] = 0\n",
    "\n",
    "#Se hacen las correcciones para los valores de 0, en donde si el salario es mayor al LS2  es atipico (0->1)\n",
    "ul.loc[ (ul['ATI_CJ'] == 0 ) & (ul['SALARIO'] > ul[['LS2', 'LS_MS']].min(axis=1) ), 'ATI_CJ'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc85d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso a modificarse\n",
    "print('Cedulas con único sector, que fueron clasificados como -1',ul[ (ul['ATI_CJ'] == - 1 )]['CEDULA_COD'].nunique() )#51259\n",
    "print('Cedulas con único sector, que fueron clasificados como  1',ul[ (ul['ATI_CJ'] == 1 )]['CEDULA_COD'].nunique() ) #137215\n",
    "print('Cedulas con único sector, que fueron clasificados como  0',ul[ (ul['ATI_CJ'] == 0 )]['CEDULA_COD'].nunique() ) #373040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_CJ(ul , 37165, 'SALARIO',  grupo_sel = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a93f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso a modificarse\n",
    "print('Cedulas con múltiples sectores, que fueron clasificados como -1',\n",
    "        ml[ (ml['ATI_CJ'] == - 1 )]['CEDULA_COD'].nunique() ) #862\n",
    "print('Cedulas con múltiples sectores, que fueron clasificados como  1',\n",
    "        ml[ (ml['ATI_CJ'] == 1 )]['CEDULA_COD'].nunique() ) #29702\n",
    "print('Cedulas con  múltiples sectores, que fueron clasificados como 0',\n",
    "        ml[ (ml['ATI_CJ'] == 0 )]['CEDULA_COD'].nunique() ) #67396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9612b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml[(ml['ATI_CJ'] == - 1 ) & (ml['SALARIO'] > ml[['LS2', 'LS_MS']].min(axis=1) )]['CEDULA_COD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ee20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_CJ(ml ,  12738, 'SALARIO',  grupo_sel = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml[ml['CEDULA_COD']==12738]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_sim = ml.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'LS2':list,'LS_MS':list,'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_sim:\n",
    "    dic_sim[cedula]['SALARIO_SECTOR'] = [[float(val) for val in sal.split(';')] if isinstance(sal, str) else [sal] \n",
    "                                          for sal in dic_sim[cedula]['SALARIO_SECTOR']]\n",
    "\n",
    "    min_ls = [min(ls2, ls_as) for ls2, ls_as in zip(dic_sim[cedula]['LS2'], dic_sim[cedula]['LS_MS'])]\n",
    "\n",
    "    dic_sim[cedula]['ATI_CJ_AS'] = [ 1 if any(sal > ls for sal in salarios) else 0 \n",
    "                                    for salarios, ls in zip( dic_sim[cedula]['SALARIO_SECTOR'], min_ls )]\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'SALARIO_SECTOR': [], \n",
    "          'LS_MS' : [], 'ATI_CJ_AS':[],  'INDICE':[]}\n",
    "\n",
    "# Llenar las listas con los datos del diccionario\n",
    "for cedula, values in dic_sim.items():\n",
    "    salario = values['SALARIO_SECTOR']\n",
    "    ls = values[ 'LS_MS' ]\n",
    "    atipico = values[ 'ATI_CJ_AS' ]\n",
    "    indice = values['INDICE']\n",
    "    num_rows = len(salario)\n",
    "\n",
    "    # Extender las listas en el diccionario de datos\n",
    "    data1['CEDULA_COD'].extend([cedula] * num_rows)\n",
    "    data1['SALARIO_SECTOR'].extend(salario)\n",
    "    data1['LS_MS' ].extend(ls)\n",
    "    data1['ATI_CJ_AS' ].extend(atipico)\n",
    "    data1['INDICE'].extend(indice)\n",
    "\n",
    "data1 = pd.DataFrame( data1 )\n",
    "data1.set_index('INDICE', inplace=True )\n",
    "cedul = list(dic_sim.keys())  #total de 111903\n",
    "filtro = data1[ data1['CEDULA_COD'].isin(cedul )] # 111903 cedulas\n",
    "indi = filtro.index\n",
    "ml.loc[ indi, 'ATI_CJ_AS'] = filtro['ATI_CJ_AS']\n",
    "\n",
    "del data1,  dic_sim, cedul, filtro, indi, salario, ls, atipico, indice, num_rows\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso a modificarse para cedulas que tiene múltiples sectores\n",
    "print('Para las çedulas con único sector, que fueron clasificados como -1 y se clasificaran como atipico',\n",
    "      ml[ (ml['ATI_CJ'] == - 1 ) & (ml['SALARIO'] > ml[['LS2', 'LS_MS']].min(axis=1) )]['CEDULA_COD'].nunique() ) # 468\n",
    "print('Para las çedulas con único sector, que fueron clasificados como -1 y se clasificaran como no atipico',\n",
    "      ml[ (ml['ATI_CJ'] == - 1 ) & (ml['SALARIO'] <= ml[['LS2', 'LS_MS']].min(axis=1) )]['CEDULA_COD'].nunique() ) # 758\n",
    "print('Para las çedulas con único sector, que fueron clasificados como -1 y se clasificaran como no atipico',\n",
    "      ml[ (ml['ATI_CJ'] == - 1 ) & (ml['SALARIO'] <= ml['SBU'] )]['CEDULA_COD'].nunique() ) # 191\n",
    "\n",
    "print('Para las çedulas con único sector, que fueron clasificados como  1 y se clasificaran como no atipico',\n",
    "      ml[ (ml['ATI_CJ'] == 1 ) & (ml['ATI_CJ_AS'] == 0)]['CEDULA_COD'].nunique() ) #16724\n",
    "print('Para las çedulas con único sector, que fueron clasificados como  1 y se clasificaran como atipico',\n",
    "      ml[ (ml['ATI_CJ'] == 0 ) & (ml['ATI_CJ_AS'] == 1)]['CEDULA_COD'].nunique() ) # 24790\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d62b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es mayor a LS1 es atípico( -1 -> 1 )\n",
    "ml.loc[ (ml['ATI_CJ'] == - 1 ) & (ml['SALARIO'] > ml[['LS2', 'LS_MS']].min(axis=1) ), 'ATI_CJ'] = 1 \n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a LS1 no es atípico( -1 -> 0 )\n",
    "ml.loc[ (ml['ATI_CJ'] == - 1 ) & (ml['SALARIO'] <= ml[['LS2', 'LS_MS']].min(axis=1) ), 'ATI_CJ'] = 0 \n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a un SBU no es atípico( -1 -> 0 )\n",
    "ml.loc[ (ml['ATI_CJ'] == - 1 ) & (ml['SALARIO'] <= ml['SBU'] ), 'ATI_CJ'] = 0 \n",
    "\n",
    "#Se hacen las correcciones para los valores 1, en donde si el Salario es menor o igual al min(ls2, ls_ms) no es atípico( 1 -> 0 )\n",
    "ml.loc[  (ml['ATI_CJ'] == 1 ) & (ml['ATI_CJ_AS'] == 0), 'ATI_CJ'] = ml['ATI_CJ_AS']\n",
    "#Se hacen las correcciones para los valores de 1, en donde si el salario es menor al SBU no es atipico (1->0)\n",
    "ml.loc[ (ml['ATI_CJ'] == 0 ) & (ml['ATI_CJ_AS'] == 1), 'ATI_CJ'] = ml['ATI_CJ_AS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_CJ(ml ,  12738, 'SALARIO',  grupo_sel = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml[ml['CEDULA_COD']==12738]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso a modificarse\n",
    "print('Cedulas con múltiples sectores, que fueron clasificados como -1',\n",
    "        ml[ (ml['ATI_CJ'] == - 1 )]['CEDULA_COD'].nunique() ) #862\n",
    "print('Cedulas con múltiples sectores, que fueron clasificados como  1',\n",
    "        ml[ (ml['ATI_CJ'] == 1 )]['CEDULA_COD'].nunique() ) #33943\n",
    "print('Cedulas con  múltiples sectores, que fueron clasificados como 0',\n",
    "        ml[ (ml['ATI_CJ'] == 0 )]['CEDULA_COD'].nunique() ) #69324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12189e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cede17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299eb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Concatenación de dataframe')\n",
    "inicio = time.time()\n",
    "val = ['CEDULA_COD', 'ANIO', 'MES', 'SALARIO', 'SALARIO_SECTOR', 'SECTOR_A',\n",
    "       'NUM_SEC_MES', '%_NUM_SECTOR', 'GRUPO', 'SAL_PROM_GRUPO', 'GRUPO_SEL',\n",
    "       'INI_CAL', 'FIN_CAL', 'BASE_CAL', 'SBU', 'ID_SBU', 'INDICE', 'ATI_CJ',\n",
    "       'LS1', 'SAL_PROM1', 'LS2', 'SAL_PROM2', 'LS_MS']\n",
    "\n",
    "data_jerar = None\n",
    "data_jerar = pd.concat( [ nodata[val] ,\n",
    "                          ul[val], ml[val] ], axis=0)\n",
    "\n",
    "data_jerar = data_jerar.sort_values( by=[\"INDICE\"], ascending=[ True ] )\n",
    "data_jerar.reset_index(inplace=True)\n",
    "data_jerar.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "data_jerar.drop(columns=['nuevo_indice'], inplace=True)\n",
    "\n",
    "fin = time.time()  \n",
    "tm = fin-inicio\n",
    "print('\\tTiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y',tm%60,'segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc836f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guadar archivo------------------------------------------------------------------------------------------------------------\n",
    "nombre_archivo = 'viu_cj_data_ati.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto8 = data_jerar\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto8, archivo)      \n",
    "\n",
    "del objeto8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a589fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jerar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data_jerar['CEDULA_COD'].drop_duplicates().sample(n=30000, random_state=1)\n",
    "muestra = data_jerar[data_jerar['CEDULA_COD'].isin(grouped)]\n",
    "muestra.to_csv('muestra_cj.txt', sep='\\t', index=False)# Agrupar por CEDULA_COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31eb09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_cj_data_ati.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    data_l = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8ff6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_CJ(data_jerar ,  12738, 'SALARIO',  grupo_sel = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificación de valores LS calculados\n",
    "a = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                        if isinstance(sal, str) \n",
    "                                        else [float(sal)]\n",
    "                                        for sal in data_jerar[ (data_jerar['CEDULA_COD']==12738) & (data_jerar['ANIO']>=2000)]['SALARIO_SECTOR']\n",
    "                                    ]\n",
    "# Aplanar la lista de listas de SALARIO_SECTOR\n",
    "salarios = None\n",
    "salarios = [salario for sublist in a for salario in sublist]\n",
    "salarios\n",
    "print('sal promedio', np.nanmean(salarios))\n",
    "q1=  np.percentile(salarios, 25)\n",
    "q3 =  np.percentile(salarios, 75)\n",
    "iqr = q3 -  q1\n",
    "print('Ls', q3+1.5*iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e1f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jerar[ (data_jerar['CEDULA_COD']==12738)]['SALARIO_SECTOR']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
