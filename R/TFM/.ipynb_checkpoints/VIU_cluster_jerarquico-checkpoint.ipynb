{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librearías necesarias\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle  #Para guardar archivos\n",
    "import os\n",
    "\n",
    "from pympler import asizeof #Para liberar memoria\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, to_rgb\n",
    "\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2737f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librearías necesarias\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle  #Para guardar archivos\n",
    "import os\n",
    "\n",
    "from pympler import asizeof #Para liberar memoria\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, to_rgb\n",
    "\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981417f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_clean_afi_sel_g_all_2.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    data_l = pickle.load( archivo )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ba7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l.shape #(62130167, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aedb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()\n",
    "data_l = data_l.sort_values( by=[\"CEDULA_COD\",\"ANIO\", \"MES\"], ascending=[ True, True, True] )\n",
    "data_l.reset_index(inplace=True)\n",
    "data_l.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "data_l.drop(columns=['nuevo_indice'], inplace=True)\n",
    "data_l['INDICE'] = data_l.index\n",
    "\n",
    "#Casos de no análisis\n",
    "data_no_grupo = data_l[ (data_l['GRUPO_SEL']==0) ].copy()\n",
    "data_no_grupo['ATI_CJ_M1'] = np.nan\n",
    "data_no_grupo['ATI_CJ_M2'] = np.nan\n",
    "data_no_grupo['ATI_CJ_M3'] = np.nan\n",
    "\n",
    "#Casos de análisis\n",
    "data = data_l[ (data_l['GRUPO_SEL']==1) ].copy()\n",
    "\n",
    "fin = time.time()  \n",
    "print('Tiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46152792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ejecutar el cluster jerarquico\n",
    "def cluster_jerarquico( data_si_dic, k):\n",
    "    inicio = time.time()\n",
    "    nom = 'ATI_CJ_M' + str( k+1 )\n",
    "    data_val_ati = {}\n",
    "    for cedula in data_si_dic:\n",
    "\n",
    "        if( len( data_si_dic[ cedula ]['SALARIO'] ) > 1 ): #Para formar al menos un cluster\n",
    "\n",
    "            aux = np.array( data_si_dic[ cedula ]['SALARIO'] ).reshape(-1, 1)\n",
    "            Z = linkage( aux , method='single', metric='euclidean')\n",
    "\n",
    "            num_clusters = 2  # Puedes ajustar este valor según tus necesidades\n",
    "            clusters = fcluster(Z, num_clusters, criterion='maxclust')\n",
    "\n",
    "            if( len( np.unique(clusters) ) > 1 ): #Para considerar al menos 2 cluster\n",
    "                # Calcular el centroide de cada clúster\n",
    "                cluster_centers = np.array([[ np.nanmean(aux[clusters == i], axis=0)[0], i ] for i in range(1, num_clusters + 1)] ) \n",
    "\n",
    "                Q1 = np.quantile(aux, 0.25)\n",
    "                Q3 = np.quantile(aux, 0.75)\n",
    "                IQR = Q3-Q1\n",
    "                LI = Q1 - 1.5 * IQR\n",
    "                LS = Q3 + 1.5 * IQR\n",
    "\n",
    "                cl_at = np.where( cluster_centers[:,0] > (LS +  1e-8) )[0]\n",
    "                cluster_centers[cl_at][:, 1]\n",
    "\n",
    "                mod_aux = np.zeros((len(aux), 2))\n",
    "                mod_aux[:, 0] = aux[:, 0]  # Copiar los valores originales de aux en la primera columna\n",
    "                mod_aux[np.isin(clusters, cluster_centers[cl_at][:, 1]), 1] = 1  # Asignar 1 en la segunda columna donde el cluster es 1\n",
    "\n",
    "                data_val_ati[cedula] = {'SALARIO': mod_aux[:, 0].tolist(),\n",
    "                                             nom : mod_aux[:, 1].tolist(),\n",
    "                                        'INDICE' : data_si_dic[ cedula ]['INDICE']}\n",
    "            else:\n",
    "                data_val_ati[cedula] = { 'SALARIO': aux.flatten().tolist(),\n",
    "                                               nom:  [-1] * len(aux),\n",
    "                                         'INDICE' : data_si_dic[ cedula ]['INDICE']} \n",
    "\n",
    "        else:\n",
    "            data_val_ati[cedula] = { 'SALARIO': data_si_dic[ cedula ]['SALARIO'],\n",
    "                                           nom:  [-2] * len( data_si_dic[ cedula ]['SALARIO'] ),\n",
    "                                     'INDICE' : data_si_dic[ cedula ]['INDICE']}\n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "    \n",
    "    return data_val_ati\n",
    " \n",
    "#Para unir los resultados\n",
    "def extend_data( data_val_ati, k ):\n",
    "    inicio = time.time()\n",
    "    nom = 'ATI_CJ_M' + str( k + 1 )\n",
    "    data1 = { 'CEDULA_COD': [], 'SALARIO': [], nom : [], 'INDICE':[]}\n",
    "\n",
    "    # Llenar las listas con los datos del diccionario\n",
    "    for cedula, values in data_val_ati.items():\n",
    "        salario = values['SALARIO']\n",
    "        atipico = values[ nom ]\n",
    "        indice = values['INDICE']\n",
    "        num_rows = len(salario)\n",
    "\n",
    "        # Extender las listas en el diccionario de datos\n",
    "        data1['CEDULA_COD'].extend([cedula] * num_rows)\n",
    "        data1['SALARIO'].extend(salario)\n",
    "        data1[ nom ].extend(atipico)\n",
    "        data1['INDICE'].extend(indice)\n",
    "\n",
    "    fin = time.time()  \n",
    "    print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "    return data1\n",
    "\n",
    "#Para graficar el comportamiento de los atipicos\n",
    "def graf_ati(ced, k):\n",
    "    nom = 'ATI_CJ_M'+ str(k)\n",
    "    dt = data_l[(data_l['GRUPO_SEL']==1) & (data_l['CEDULA_COD']==ced)]\n",
    "    unique_ati = dt[ nom ].nunique(dropna=False)\n",
    "    categories = dt[ nom ].unique()\n",
    "\n",
    "    # Generar una lista de colores discretos\n",
    "    colors = plt.cm.coolwarm(np.linspace(0, 1, unique_ati))\n",
    "\n",
    "    # Crear un mapa de colores discreto\n",
    "    cmap = ListedColormap(colors)\n",
    "\n",
    "    # Graficar\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    scatter = plt.scatter(dt.index, dt['SALARIO'], c=dt[ nom ], cmap=cmap)\n",
    "\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Salario')\n",
    "    plt.title('Gráfico de Salario')\n",
    "\n",
    "    # Crear una leyenda discreta personalizada\n",
    "    # Definir las etiquetas para cada categoría\n",
    "    labels = { 0: 'No es atípico', 1: 'Es atípico', -1: 'Es un solo clúter', -2:'No forma parte del proceso',\n",
    "               np.nan: 'Valor NA'}\n",
    "\n",
    "    # Crear los handles para la leyenda\n",
    "    handles = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                          markersize=10, markerfacecolor=cmap(i), \n",
    "                          label=labels[i]) for i in categories]\n",
    "\n",
    "    plt.legend(handles=handles, title='Tipo de Salario')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ff3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ ~(( data['SALARIO'] >= data['SBU'] ) & ( data['ANIO'] >= 2000 )) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c70213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea un bucle para cada caso\n",
    "for k in range(0,3):\n",
    "    nom = 'ATI_CJ_M' + str( k+1 )\n",
    "    if (k==0):\n",
    "        ##Primer Caso--Considerando solo los salarios mayores al SBU y desde el año 2000\n",
    "        print('*' * 50, 'Caso ', str( k+1 ), '*' * 50)\n",
    "        data_si = data[   (( data['SALARIO'] >= data['SBU'] ) & ( data['ANIO'] >= 2000 )) ].copy() \n",
    "        data_no = data[ ~(( data['SALARIO'] >= data['SBU'] ) & ( data['ANIO'] >= 2000 )) ].copy() \n",
    "        data_no[ nom ] = np.nan\n",
    "        print('Tamaño de la data utilizada dentro de los años seleccionados', data_si.shape) #(26006294, 16)\n",
    "        print('Tamaño de la data no utilizada dentro de los años seleccionados',data_no.shape)  #(465822, 16)\n",
    "        \n",
    "        data_si_dic = data_si.groupby('CEDULA_COD').agg({'SALARIO': list, 'INDICE': list}).to_dict(orient='index')\n",
    "        data_no_dic = data_no.groupby('CEDULA_COD').agg({'SALARIO': list, 'INDICE': list}).to_dict(orient='index')\n",
    "        \n",
    "        print('Algoritmo Cluster Jerárquico')\n",
    "        data_val_ati = cluster_jerarquico( data_si_dic, k )\n",
    "        print('Extensión del diccionario')\n",
    "        data1 = extend_data( data_val_ati, k )\n",
    "        \n",
    "        print('Concatenación de dataframe')\n",
    "        inicio = time.time()\n",
    "        data_jerar = None\n",
    "        data_jerar = pd.concat( [ data_no_grupo[['CEDULA_COD', 'SALARIO',  nom , 'INDICE']],\n",
    "                                  pd.DataFrame( data1 ), \n",
    "                                  data_no[['CEDULA_COD', 'SALARIO',  nom , 'INDICE']] ], axis=0)\n",
    "    \n",
    "        data_jerar = data_jerar.sort_values( by=[\"INDICE\"], ascending=[ True ] )\n",
    "        data_jerar.reset_index(inplace=True)\n",
    "        data_jerar.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "        data_jerar.drop(columns=['nuevo_indice'], inplace=True)\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        \n",
    "        print('Creación de la columna')\n",
    "        inicio = time.time()\n",
    "        data_l[ nom ] = np.nan\n",
    "        aux = data_jerar[ nom ].to_numpy()\n",
    "        data_l.iloc[:, data_l.columns.get_loc( nom )] = aux\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        \n",
    "        print('Verificación de posibles errores')\n",
    "        inicio = time.time()\n",
    "        dif1 = data_l[data_l['SALARIO']!= data_jerar['SALARIO']].index\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        print('*' * 108, '\\n')  \n",
    "        \n",
    "    if (k==1):\n",
    "        ##Segundo Caso--Considerando todo el registro de los mejores años\n",
    "        print('*' * 50, 'Caso ', str( k+1 ), '*' * 50)\n",
    "        data_si = data.copy()\n",
    "        print('Tamaño de la data utilizada dentro de los años seleccionados', data_si.shape) \n",
    "        \n",
    "        data_si_dic = data_si.groupby('CEDULA_COD').agg({'SALARIO': list, 'INDICE': list}).to_dict(orient='index')\n",
    "        \n",
    "        print('Algoritmo Cluster Jerárquico')\n",
    "        data_val_ati = cluster_jerarquico( data_si_dic, k )\n",
    "        print('Extensión del diccionario')\n",
    "        data1 = extend_data( data_val_ati, k )\n",
    "        \n",
    "        print('Concatenación de dataframe')\n",
    "        inicio = time.time()\n",
    "        data_jerar = None\n",
    "        data_jerar = pd.concat( [ data_no_grupo[['CEDULA_COD', 'SALARIO', nom, 'INDICE']],\n",
    "                                  pd.DataFrame( data1 ) ], axis=0)\n",
    "    \n",
    "        data_jerar = data_jerar.sort_values( by=[\"INDICE\"], ascending=[ True ] )\n",
    "        data_jerar.reset_index(inplace=True)\n",
    "        data_jerar.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "        data_jerar.drop(columns=['nuevo_indice'], inplace=True)\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        \n",
    "        print('Creación de la columna')\n",
    "        inicio = time.time()\n",
    "        data_l[ nom ] = np.nan\n",
    "        aux = data_jerar[ nom ].to_numpy()\n",
    "        data_l.iloc[:, data_l.columns.get_loc( nom ) ] = aux\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        \n",
    "        print('Verificación de posibles errores')\n",
    "        inicio = time.time()\n",
    "        dif2 = data_l[data_l['SALARIO']!= data_jerar['SALARIO']].index\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        print('*' * 108, '\\n')\n",
    "        \n",
    "    if (k==2):\n",
    "        ##Tercer Caso--Considerando todo el registro de los mejores años, pero a partir del año 2000\n",
    "        print('*' * 50, 'Caso ', str( k+1 ), '*' * 50)\n",
    "        data_si = data[  ( ( data['ANIO'] >= 2000 )) ].copy()\n",
    "        data_no = data[ ~( ( data['ANIO'] >= 2000 )) ].copy()   \n",
    "        data_no[ nom ] = np.nan\n",
    "        print('Tamaño de la data utilizada dentro de los años seleccionados', data_si.shape) \n",
    "        print('Tamaño de la data no utilizada dentro de los años seleccionados',data_no.shape) \n",
    "        \n",
    "        data_si_dic = data_si.groupby('CEDULA_COD').agg({'SALARIO': list, 'INDICE': list}).to_dict(orient='index')\n",
    "        data_no_dic = data_no.groupby('CEDULA_COD').agg({'SALARIO': list, 'INDICE': list}).to_dict(orient='index')\n",
    "        \n",
    "        print('Algoritmo Cluster Jerárquico')\n",
    "        data_val_ati = cluster_jerarquico( data_si_dic, k )\n",
    "        print('Extensión del diccionario')\n",
    "        data1 = extend_data( data_val_ati, k )\n",
    "        \n",
    "        print('Concatenación de dataframe')\n",
    "        inicio = time.time()\n",
    "        data_jerar = None\n",
    "        data_jerar = pd.concat( [ data_no_grupo[['CEDULA_COD', 'SALARIO', nom, 'INDICE']],\n",
    "                                  pd.DataFrame( data1 ), \n",
    "                                  data_no[['CEDULA_COD', 'SALARIO', nom, 'INDICE']] ], axis=0)\n",
    "    \n",
    "        data_jerar = data_jerar.sort_values( by=[\"INDICE\"], ascending=[ True ] )\n",
    "        data_jerar.reset_index(inplace=True)\n",
    "        data_jerar.rename(columns={'index': 'nuevo_indice'}, inplace=True)\n",
    "        data_jerar.drop(columns=['nuevo_indice'], inplace=True)\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        \n",
    "        print('Creación de la columna')\n",
    "        inicio = time.time()\n",
    "        data_l[ nom ] = np.nan\n",
    "        aux = data_jerar[ nom ].to_numpy()\n",
    "        data_l.iloc[:, data_l.columns.get_loc( nom )] = aux\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        \n",
    "        print('Verificación de posibles errores')\n",
    "        inicio = time.time()\n",
    "        dif3 = data_l[data_l['SALARIO']!= data_jerar['SALARIO']].index\n",
    "        fin = time.time()  \n",
    "        print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos' )\n",
    "        print('*' * 108, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3feebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, data_jerar, data1, aux, data_si, data_no, data_no_grupo, data_val_ati\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6b4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se calculan los limítes máximos de aportación en función de la HL\n",
    "#Caso 1: Para toda la historia laboral\n",
    "inicio = time.time()   \n",
    "grupo1 = data_l.copy()\n",
    "Q1 = grupo1.groupby('CEDULA_COD')['SALARIO'].quantile(0.25)\n",
    "Q3 = grupo1.groupby('CEDULA_COD')['SALARIO'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "LI = Q1 - 1.5 * IQR\n",
    "LS = Q3 + 1.5 * IQR\n",
    "data_l['LS1'] = data_l['CEDULA_COD'].map( LS )\n",
    "\n",
    "#Caso 2: Para la historia laboral a partir del año 2020\n",
    "grupo2 = data_l[ data_l['ANIO']>=2000 ].copy()\n",
    "Q1 = grupo2.groupby('CEDULA_COD')['SALARIO'].quantile(0.25)\n",
    "Q3 = grupo2.groupby('CEDULA_COD')['SALARIO'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "LI = Q1 - 1.5 * IQR\n",
    "LS = Q3 + 1.5 * IQR\n",
    "data_l['LS2'] = data_l['CEDULA_COD'].map( LS )\n",
    "\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos')\n",
    "\n",
    "del grupo1, grupo2, Q1, Q3, IQR, LI, LS\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#El valor de NA implica que esos datos no son parte de data_si, por lo que no se analizaron\n",
    "#El valor de -1 implica que se formó un solo cluster\n",
    "#El valor de -2 implica que en la selección de datos (data_si), la cedula solo tenía un único valor para formar los cluster\n",
    "# pues era el resultado de filtrar el data_si\n",
    "\n",
    "##Se analiza el caso de los valores de atipicos del método 1\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 )]['ATI_CJ_M1'].unique() #array([ 0., nan,  1., -1., -2.])\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 ) & (data_l['ATI_CJ_M1']==-2)] #86 rows × 21 columns\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 ) & (data_l['ATI_CJ_M1'].isna())]  #465822 rows × 21 columns\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 ) & (data_l['ATI_CJ_M1']==-1)]  # 3292785 rows × 21 columns\n",
    "\n",
    "##Se analiza el caso de los valores de atipicos del método 2\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 )]['ATI_CJ_M2'].unique() #rray([ 0.,  1., -1.])\n",
    "# ata_l[ ( data_l['GRUPO_SEL']==1 ) & (data_l['ATI_CJ_M2']==-1)]  #3125765 rows × 21 columns\n",
    "\n",
    "##Se analiza el caso de los valores de atipicos del método 3\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 )]['ATI_CJ_M3'].unique() #array([ 0.,  1., -1., nan, -2.])\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 ) & (data_l['ATI_CJ_M3']==-2)] #2 rows × 21 columns\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 ) & (data_l['ATI_CJ_M3'].isna())]  # 7454 rows × 21 columns\n",
    "# data_l[ ( data_l['GRUPO_SEL']==1 ) & (data_l['ATI_CJ_M3']==-1)] #3125140 rows × 21 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cedulas que tiene datos atípicos----------------------------------------------------------------------------------------------\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico:', data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==1)]['CEDULA_COD'].nunique()) #134017\n",
    "print('\\tCedulas con valor -2:',            data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==-2)]['CEDULA_COD'].nunique()) #86\n",
    "print('\\tCedulas con valor nan:',           data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1'].isna())]['CEDULA_COD'].nunique()) #85804\n",
    "print('\\tCedulas con valor -1:',            data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==-1)]['CEDULA_COD'].nunique()) #55669\n",
    "print('\\tCedulas con valor 0:',             data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==0)]['CEDULA_COD'].nunique()) #379216\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico:', data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==1)]['CEDULA_COD'].nunique()) #123850\n",
    "print('\\tCedulas con valor -2:',            data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==-2)]['CEDULA_COD'].nunique()) #0\n",
    "print('\\tCedulas con valor nan:',           data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2'].isna())]['CEDULA_COD'].nunique()) #0\n",
    "print('\\tCedulas con valor -1:',            data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==-1)]['CEDULA_COD'].nunique()) #52121\n",
    "print('\\tCedulas con valor 0:',             data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==0)]['CEDULA_COD'].nunique()) #383682\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico:', data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==1)]['CEDULA_COD'].nunique()) #123826\n",
    "print('\\tCedulas con valor -2:',            data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==-2)]['CEDULA_COD'].nunique()) #2\n",
    "print('\\tCedulas con valor nan:',           data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3'].isna())]['CEDULA_COD'].nunique()) #499\n",
    "print('\\tCedulas con valor -1:',            data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==-1)]['CEDULA_COD'].nunique()) # 52124\n",
    "print('\\tCedulas con valor 0:',             data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==0)]['CEDULA_COD'].nunique()) #383653\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fec512",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ati(23075971, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88a895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso 1- Correcciones---------------------------------------------------------------------------------------------------\n",
    "#Se corrige en función deL Límite máximo de la HL a apartir del año 2000, pues es la fecha en la que entra en dolar a ecuador ( -2 -> 1 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==-2) & (data_l['SALARIO'] > data_l['LS2']) ), 'ATI_CJ_M1'] = 1 #quedan 45 casos\n",
    "#Se corrige en función del valores menoRes al limite máximo la HL a apartir del año 2000, pues es la fecha en la que entra en dolar a ecuador ( -2 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==-2) & (data_l['SALARIO'] <= data_l['LS2']) ), 'ATI_CJ_M1'] = 0 \n",
    "# Se hacen las correcciones para los valores -2, en donde si el Salario es menor o igual a un SBU no es atípico( -2 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==-2) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M1'] = 0 \n",
    "\n",
    "#Se corrige en función deL Límite máximo de toda la HL, pues si no hay datos del SBU para atrás ( NA -> 1 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1'].isna()) & (data_l['SALARIO'] > data_l['LS1']) ), 'ATI_CJ_M1'] = 1  #quedan 463235 casos\n",
    "#Se corrige en función del valores menoRes al limite máximo la HL, pues si no hay datos del SBU para atrás ( NA -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1'].isna()) & (data_l['SALARIO'] <= data_l['LS1']) ), 'ATI_CJ_M1'] = 0  #\n",
    "#Se hacen las correcciones para los valores NA, en donde si el Salario es menor o igual a un SBU no es atípico( NA -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1'].isna()) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M1'] = 0  \n",
    "\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es mayor a LS1 es atípico( -1 -> 1 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==-1) & (data_l['SALARIO'] > data_l['LS1']) ), 'ATI_CJ_M1'] = 1 #quedan 3267088\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a LS1 no es atípico( -1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==-1) & (data_l['SALARIO'] <= data_l['LS1']) ), 'ATI_CJ_M1'] = 0 #q \n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a un SBU no es atípico( -1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==-1) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M1'] = 0 #\n",
    "\n",
    "#Se hacen las correcciones para los valores 1, en donde si el Salario es menor o igual al SBU no es atípico( 1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==1) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaeff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso 2 - Correcciones---------------------------------------------------------------------------------------------------\n",
    "#No existen valores igual a NA e igual a -2\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es mayor a LS1 es atípico( -1 -> 1 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==-1) & (data_l['SALARIO'] > data_l['LS1']) ), 'ATI_CJ_M2'] = 1 # quedan 3104185\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a LS1 no es atípico( -1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==-1) & (data_l['SALARIO'] <= data_l['LS1']) ), 'ATI_CJ_M2'] = 0\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a un SBU no es atípico( -1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==-1) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M2'] = 0 \n",
    "#Se hacen las correcciones para los valores 1, en donde si el Salario es menor o igual al SBU no es atípico( 1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==1) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9777bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caso 3 - Correcciones-------------------------------------------------------------------------------------------------\n",
    "#Se corrige en función deL Límite máximo de la HL a apartir del año 2000, pues es la fecha en la que entra en dolar a ecuador ( -2 -> 1 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==-2) & (data_l['SALARIO'] > data_l['LS2']) ), 'ATI_CJ_M3'] = 1 # quedan 2 casos\n",
    "#Se corrige en función del valores menores al limite máximo la HL a apartir del año 2000, pues es la fecha en la que entra en dolar a ecuador ( -2 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==-2) & (data_l['SALARIO'] <= data_l['LS2']) ), 'ATI_CJ_M3'] = 0\n",
    "#Se hacen las correcciones para los valores -2, en donde si el Salario es menor o igual a un SBU no es atípico( -2 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==-2) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M3'] = 0 #\n",
    "\n",
    "#Se corrige en función deL Límite máximo de toda la HL, pues si no hay datos del SBU para atrás ( NA -> 1 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3'].isna()) & (data_l['SALARIO'] > data_l['LS1']) ), 'ATI_CJ_M3'] = 1 #quedan 7394 casos\n",
    "#Se corrige en función del valores menoRes al limite máximo la HL, pues sno hay datos del SBU para atrás ( NA -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3'].isna()) & (data_l['SALARIO'] <= data_l['LS1']) ), 'ATI_CJ_M3'] = 0  \n",
    "#Se hacen las correcciones para los valores NA, en donde si el Salario es menor o igual a un SBU no es atípico( NA -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3'].isna()) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M3'] = 0 \n",
    "\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es mayor a LS1 es atípico( -1 -> 1 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==-1) & (data_l['SALARIO'] > data_l['LS1']) ), 'ATI_CJ_M3'] = 1 #quedan 3103457  casos\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a LS1 no es atípico( -1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==-1) & (data_l['SALARIO'] <= data_l['LS1']) ), 'ATI_CJ_M3'] = 0\n",
    "#Se hacen las correcciones para los valores -1, en donde si el Salario es menor o igual a un SBU no es atípico( -1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==-1) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M3'] = 0 \n",
    "#Se hacen las correcciones para los valores 1, en donde si el Salario es menor o igual al SBU no es atípico( 1 -> 0 )\n",
    "data_l.loc[ ( (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==1) & (data_l['SALARIO'] <= data_l['SBU']) ), 'ATI_CJ_M3'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2b16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ati(23075971, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730dd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cedulas que tiene datos atípicos----------------------------------------------------------------------------------------------\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico:', data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==1)]['CEDULA_COD'].nunique()) #125237\n",
    "print('\\tCedulas con sin atípicos:',        data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==0)]['CEDULA_COD'].nunique()) #436149\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico:', data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==1)]['CEDULA_COD'].nunique()) #116931\n",
    "print('\\tCedulas con sin atípicos:',        data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==0)]['CEDULA_COD'].nunique()) #436148\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico:', data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==1)]['CEDULA_COD'].nunique()) #116938\n",
    "print('\\tCedulas con sin atípicos:',        data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==0)]['CEDULA_COD'].nunique()) #436149\n",
    "print('*' * 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc836f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guadar archivo------------------------------------------------------------------------------------------------------------\n",
    "nombre_archivo = 'viu_clean_data_l.pkl'\n",
    "# Ruta completa del archivo\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "# Objetos a guardar\n",
    "objeto8 = data_l\n",
    "\n",
    "# Guardar los objetos en el archivo\n",
    "with open(ruta_archivo, 'wb') as archivo:\n",
    "    pickle.dump(objeto8, archivo)      \n",
    "\n",
    "del objeto8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a589fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31eb09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_clean_data_l.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "with open( ruta_archivo, 'rb') as archivo:\n",
    "    data_l = pickle.load( archivo ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisis para atípicos vs aportes simultáneos\n",
    "cedula_1 = data_l.groupby('CEDULA_COD')['NUM_SEC_MES'].apply( lambda x: (x != 1).any() )\n",
    "cedula_dist = cedula_1[ cedula_1 ].index\n",
    "ul = data_l[ ~data_l['CEDULA_COD'].isin( cedula_dist )]\n",
    "ml = data_l[  data_l['CEDULA_COD'].isin( cedula_dist )]\n",
    "\n",
    "#Cedulas que tiene datos atípicos----------------------------------------------------------------------------------------------\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      ul[ (ul['GRUPO_SEL']==1) & (ul['ATI_CJ_M1']==1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M1']==1)]['CEDULA_COD'].nunique())\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      ul[ (ul['GRUPO_SEL']==1) & (ul['ATI_CJ_M2']==1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M2']==1)]['CEDULA_COD'].nunique())\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      ul[ (ul['GRUPO_SEL']==1) & (ul['ATI_CJ_M3']==1)]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M3']==1)]['CEDULA_COD'].nunique())\n",
    "print('*' * 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9187ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creando limites de atipicos\n",
    "inicio = time.time()   \n",
    "#Caso 3: Para toda la historia laboral sin considerar aportes simultáneos\n",
    "# cedula_1 = data_l.groupby('CEDULA_COD')['NUM_SEC_MES'].apply( lambda x: (x != 1).any() )\n",
    "# cedula_dist = cedula_1[ cedula_1 ].index\n",
    "# grupo3 = data_l[ ~data_l['CEDULA_COD'].isin( cedula_dist )]\n",
    "grupo3 = ul\n",
    "\n",
    "Q1 = grupo3.groupby('CEDULA_COD')['SALARIO'].quantile(0.25)\n",
    "Q3 = grupo3.groupby('CEDULA_COD')['SALARIO'].quantile(0.75)\n",
    "IQR = Q3-Q1\n",
    "LI = Q1 - 1.5 * IQR\n",
    "LS = Q3 + 1.5 * IQR\n",
    "data_l['LS3'] = data_l['CEDULA_COD'].map( LS )\n",
    "\n",
    "#Caso 4: Para toda la historia laboral considerando aportes simultáneos\n",
    "#grupo4 = data_l[ data_l['CEDULA_COD'].isin( cedula_dist )]\n",
    "grupo4 = ml\n",
    "dic_aux = grupo4.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_aux:\n",
    "    dic_aux[cedula]['SALARIO_SECTOR'] = [ [float(val) for val in sal.replace(':', ';').split(';')] \n",
    "                                            if isinstance(sal, str) \n",
    "                                            else [float(sal)]\n",
    "                                            for sal in dic_aux[cedula]['SALARIO_SECTOR']\n",
    "                                        ]\n",
    "    # Aplanar la lista de listas de SALARIO_SECTOR\n",
    "    salarios = None\n",
    "    salarios = [salario for sublist in dic_aux[cedula]['SALARIO_SECTOR'] for salario in sublist]\n",
    "    dic_aux[cedula]['Q1'] =  np.percentile(salarios, 25)\n",
    "    dic_aux[cedula]['Q3'] =  np.percentile(salarios, 75)\n",
    "    dic_aux[cedula]['IQR'] = dic_aux[cedula]['Q3'] -  dic_aux[cedula]['Q1']\n",
    "    dic_aux[cedula]['LI'] =  dic_aux[cedula]['Q1'] -  1.5  * dic_aux[cedula]['IQR']\n",
    "    dic_aux[cedula]['LS'] =  dic_aux[cedula]['Q3'] +  1.5  * dic_aux[cedula]['IQR']\n",
    "\n",
    "data1 = { 'CEDULA_COD': [], 'LS': [] }\n",
    "\n",
    "for cedula, val in dic_aux.items():\n",
    "    data1['CEDULA_COD'].append(cedula)\n",
    "    data1['LS'].append( val['LS'] )\n",
    "\n",
    "LS = pd.DataFrame( data1 )\n",
    "LS = LS.groupby('CEDULA_COD')['LS'].first()\n",
    "data_l['LS4'] = data_l['CEDULA_COD'].map( LS )  \n",
    "\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos')\n",
    "\n",
    "del grupo3, grupo4, dic_aux, data1, Q1, Q3, IQR, LI, LS\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9063e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M1']==1) ]['CEDULA_COD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l[ (data_l['GRUPO_SEL']==1) & (data_l['CEDULA_COD']==397)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ddd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ul, ml\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7735b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ati(397, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l['ATI_CJ_AS'] = 0\n",
    "grupo1 = None\n",
    "grupo1 = data_l[  data_l['CEDULA_COD'].isin( cedula_dist )].copy() #Es igual a ml pero se actualizan los valores\n",
    "\n",
    "inicio = time.time()   \n",
    "dic_sim = grupo1.groupby('CEDULA_COD').agg({'SALARIO_SECTOR': list, 'LS4': list,'INDICE': list}).to_dict(orient='index')\n",
    "\n",
    "for cedula in dic_sim:\n",
    "    dic_sim[cedula]['SALARIO_SECTOR'] = [[float(val) for val in sal.split(';')] if isinstance(sal, str) else [sal] \n",
    "                                          for sal in dic_sim[cedula]['SALARIO_SECTOR']]\n",
    "    dic_sim[cedula]['ATI_CJ_AS'] = [ 1 if any(sal > ls for sal in salarios) else 0 \n",
    "                                    for salarios, ls in zip( dic_sim[cedula]['SALARIO_SECTOR'], dic_sim[cedula]['LS4'])]\n",
    "\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos')\n",
    "\n",
    "del grupo1   \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed7fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = { 'CEDULA_COD': [], 'SALARIO_SECTOR': [], \n",
    "         'LS4' : [], 'ATI_CJ_AS':[],  'INDICE':[]}\n",
    "\n",
    "# Llenar las listas con los datos del diccionario\n",
    "for cedula, values in dic_sim.items():\n",
    "    salario = values['SALARIO_SECTOR']\n",
    "    ls = values[ 'LS4' ]\n",
    "    atipico = values[ 'ATI_CJ_AS' ]\n",
    "    indice = values['INDICE']\n",
    "    num_rows = len(salario)\n",
    "\n",
    "    # Extender las listas en el diccionario de datos\n",
    "    data1['CEDULA_COD'].extend([cedula] * num_rows)\n",
    "    data1['SALARIO_SECTOR'].extend(salario)\n",
    "    data1['LS4' ].extend(ls)\n",
    "    data1['ATI_CJ_AS' ].extend(atipico)\n",
    "    data1['INDICE'].extend(indice)\n",
    "    \n",
    "data1 = pd.DataFrame( data1 )\n",
    "data1.set_index('INDICE', inplace=True )\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4642ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()   \n",
    "cedulas = list(dic_sim.keys())  #total de 111903\n",
    "filtro = data1[ data1['CEDULA_COD'].isin(cedulas )] # 111903 cedulas\n",
    "indi = filtro.index\n",
    "data_l.loc[ indi, 'ATI_CJ_AS'] = filtro['ATI_CJ_AS']\n",
    "\n",
    "fin = time.time()  \n",
    "print('\\tTiempo de ejecución es: ',  (fin-inicio)//3600, ' horas con ' ,  (fin-inicio)%3600//60 , ' minutos y', (fin-inicio)%60, ' segundos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd56db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal=[[float(val) for val in sal.split(';')] if isinstance(sal, str) else [sal] for sal in data_l[data_l['CEDULA_COD']==216]['SALARIO_SECTOR']]\n",
    "sala=[salario for sublist in sal for salario in sublist]\n",
    "LS = np.percentile(sala, 75) + 1.5 * (np.percentile(sala, 75)-np.percentile(sala, 25))\n",
    "LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cfb6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l[data_l['CEDULA_COD']==216].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d271c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[data1['CEDULA_COD']==216].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ba28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = data_l[  data_l['CEDULA_COD'].isin( cedula_dist )].copy()\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas que tienen más de un sector y que fue clasificado como atípico, que se modificaran a no atipico:',\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M1']==1) & ( ml['ATI_CJ_AS']==0)]['CEDULA_COD'].nunique()) #29408\n",
    "print('\\tCedulas que tienen más de un sector y que fue clasificado como  no atípico, que se modificaran a atipico',\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M1']==0) & ( ml['ATI_CJ_AS']==1)]['CEDULA_COD'].nunique()) #24171\n",
    "\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas que tienen más de un sector y que fue clasificado como atípico, que se modificarann a no atipico:',\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M2']==1) & ( ml['ATI_CJ_AS']==0)]['CEDULA_COD'].nunique()) #26929\n",
    "print('\\tCedulas que tienen más de un sector y que fue clasificado como  no atípico, que se modificaran a atipico',\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M2']==0) & ( ml['ATI_CJ_AS']==1)]['CEDULA_COD'].nunique()) #24893\n",
    "\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas que tienen más de un sector y que fue clasificado como atípico, que se modificarann a no atipico:',\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M3']==1) & ( ml['ATI_CJ_AS']==0)]['CEDULA_COD'].nunique()) #26933\n",
    "print('\\tCedulas que tienen más de un sector y que fue clasificado como  no atípico, que se modificaran a atipico',\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M3']==0) & ( ml['ATI_CJ_AS']==1)]['CEDULA_COD'].nunique()) #24893\n",
    "print('*' * 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cedulas que tiene varios sectores que se modificaran ( 1 -> 0 )\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M1']==1) & ( ml['ATI_CJ_AS']==0)]['CEDULA_COD'].unique() #29408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6843935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cedulas que tiene varios sectores que se modificaran ( 0 -> 1 )\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M1']==0) & ( ml['ATI_CJ_AS']==1)]['CEDULA_COD'].unique() #24171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a698d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml[ (ml['GRUPO_SEL']==1) & (ml['CEDULA_COD']==1908)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráficas para cuando de 1->0 en aportes simultáneos\n",
    "graf_ati(1908, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa243bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráficas para cuando de 0->1 en aportes simultáneos\n",
    "ml[ (ml['GRUPO_SEL']==1) & (ml['CEDULA_COD']==472)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3387d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráficas para cuando de 0 -> 1 en aportes simultáneos\n",
    "graf_ati(472, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cedula_dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84881a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se hacen las correcciones\n",
    "#Caso 1\n",
    "data_l.loc[(data_l['CEDULA_COD'].isin(cedula_dist)) & \n",
    "           (data_l['GRUPO_SEL'] == 1) & (data_l['ATI_CJ_M1'] == 1) & (data_l['ATI_CJ_AS'] == 0), 'ATI_CJ_M1'] = data_l['ATI_CJ_AS']\n",
    "data_l.loc[(data_l['CEDULA_COD'].isin(cedula_dist)) & \n",
    "           (data_l['GRUPO_SEL'] == 1) & (data_l['ATI_CJ_M1'] == 0) & (data_l['ATI_CJ_AS'] == 1), 'ATI_CJ_M1'] = data_l['ATI_CJ_AS']\n",
    "\n",
    "#Caso 2\n",
    "data_l.loc[(data_l['CEDULA_COD'].isin(cedula_dist)) & \n",
    "           (data_l['GRUPO_SEL'] == 1) & (data_l['ATI_CJ_M2'] == 1) & (data_l['ATI_CJ_AS'] == 0), 'ATI_CJ_M1'] = data_l['ATI_CJ_AS']\n",
    "data_l.loc[(data_l['CEDULA_COD'].isin(cedula_dist)) & \n",
    "           (data_l['GRUPO_SEL'] == 1) & (data_l['ATI_CJ_M2'] == 0) & (data_l['ATI_CJ_AS'] == 1), 'ATI_CJ_M1'] = data_l['ATI_CJ_AS']\n",
    "\n",
    "#Caso 3\n",
    "data_l.loc[(data_l['CEDULA_COD'].isin(cedula_dist)) & \n",
    "           (data_l['GRUPO_SEL'] == 1) & (data_l['ATI_CJ_M3'] == 1) & (data_l['ATI_CJ_AS'] == 0), 'ATI_CJ_M1'] = data_l['ATI_CJ_AS']\n",
    "data_l.loc[(data_l['CEDULA_COD'].isin(cedula_dist)) & \n",
    "           (data_l['GRUPO_SEL'] == 1) & (data_l['ATI_CJ_M3'] == 0) & (data_l['ATI_CJ_AS'] == 1), 'ATI_CJ_M1'] = data_l['ATI_CJ_AS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72fca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data1, dic_sim, filtro, indi, cedulas, ml\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca053b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cedulas que tiene datos atípicos luego de la corrección---------------------------------------------------------------------\n",
    "print('*' * 50, 'Caso ', str( 1 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==1) &(~data_l['CEDULA_COD'].isin(cedula_dist))]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M1']==1) & (data_l['CEDULA_COD'].isin(cedula_dist))]['CEDULA_COD'].nunique())\n",
    "print('*' * 50, 'Caso ', str( 2 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==1) &(~data_l['CEDULA_COD'].isin(cedula_dist))]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M2']==1) &(data_l['CEDULA_COD'].isin(cedula_dist))]['CEDULA_COD'].nunique())\n",
    "print('*' * 50, 'Caso ', str( 3 ), '*' * 50)\n",
    "print('\\tCedulas con al menos un atípico con un único sector:',\n",
    "      data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==1) &(~data_l['CEDULA_COD'].isin(cedula_dist))]['CEDULA_COD'].nunique()) \n",
    "print('\\tCedulas con al menos un atípico con más de un único sector:',\n",
    "      data_l[ (data_l['GRUPO_SEL']==1) & (data_l['ATI_CJ_M3']==1) &(data_l['CEDULA_COD'].isin(cedula_dist))]['CEDULA_COD'].nunique())\n",
    "print('*' * 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = data_l[  data_l['CEDULA_COD'].isin( cedula_dist )]\n",
    "ul = data_l[ ~ data_l['CEDULA_COD'].isin( cedula_dist )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ul[ (ul['GRUPO_SEL']==1) & (ul['ATI_CJ_M1']==1)]['CEDULA_COD'].nunique())\n",
    "print(ml[ (ml['GRUPO_SEL']==1) & (ml['ATI_CJ_M1']==1)]['CEDULA_COD'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f90fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ati(1908, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adebe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "graf_ati(472, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9bb49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
