{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a19f179",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12496\\1379843079.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#Importación de librearías necesarias\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle  #Para guardar archivos\n",
    "import os\n",
    "\n",
    "from pympler import asizeof #Para liberar memoria\n",
    "import gc\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import joblib\n",
    "\n",
    "semilla = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path general de archivos\n",
    "if socket.gethostname()=='LAPTOP-PUSGG08B': #Ip de la laptop\n",
    "    ruta = \"E:/Cristian Guatemal/Master/Big Data y Ciencia de Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"E:/Cristian Guatemal/Master/Big Data y Ciencia de Datos/VIU_TFM/RData/TFM/\"\n",
    "elif socket.gethostname()=='PCUIOMTDAIE6382': #Ip del working pc\n",
    "    ruta =   \"D:/Master/Big_Data_Ciencia_Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"D:/Master/Big_Data_Ciencia_Datos/VIU_TFM/RData/TFM/\"\n",
    "elif socket.gethostname()=='LPUIODAIE208Y3X': #Ip del working laptop\n",
    "    ruta =   \"C:/Cristian_Guatemal/Personal/Master/Big_Data_Ciencia_Datos/VIU_TFM/Data/TFM/\"\n",
    "    r_ruta = \"C:/Cristian_Guatemal/Personal/Master/Big_Data_Ciencia_Datos/VIU_TFM/RData/TFM/\"\n",
    "# Ruta del archivo de pensionistas de vejez\n",
    "ruta_vj = ruta + 'POB_VEJ_CD656_NEW.dsv'\n",
    "# Ruta del archivo de historia laboral de pensionistas\n",
    "ruta_afi = ruta + 'APORTES_CD656_new.dsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo------------------------------------------------------------------------------------------------------------\n",
    "directorio = r_ruta\n",
    "nombre_archivo = 'viu_ml_preparacion_data.pkl'\n",
    "ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "data= pd.read_pickle(ruta_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5616f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e169cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selección de variables para entrenar los modelos\n",
    "val_otr = ['BASE_CAL', 'LS2', 'SAL_PROM2', 'LS_MS', 'SUELDO',\n",
    "           'SEXO', 'PRES', 'N_PRI_P', 'N_PUB_P', 'N_IND_P', 'N_VOL_EC_P',\n",
    "           'N_VOL_EX_P', 'M_PRI_P', 'M_PUB_P', 'M_IND_P', 'M_VOL_EC_P','M_VOL_EX_P',\n",
    "           'NUMERO_IMPOSICIONES', 'TIEM_T',\n",
    "           'TARGET']\n",
    "data_otr = data[ val_otr ]\n",
    "data_otr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645637ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split( data_arb, test_size = 0.2, random_state = semilla )\n",
    "train.reset_index(drop=True, inplace= True)\n",
    "test.reset_index(drop=True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbd6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and pljots the confusion matrix.\n",
    "    Normalization can be applied by setting normalize=True.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f449811",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = SVC( C=1E10, random_state = semilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be661473",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_r_svc = { \"C\":[1,5,10,15],\n",
    "                     \"kernel\":['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n",
    "                     \"gamma\":['scale', 'auto'], \n",
    "                     \"class_weight\":['balanced', 'None']\n",
    "                    \n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f937f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()\n",
    "random_svc = RandomizedSearchCV( estimator = model_svc, \n",
    "                                 param_distributions = param_dist_r_svc,\n",
    "                                 n_iter = 100, cv = 5, scoring = 'accuracy', random_state = semilla, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_svc.fit(X = train.drop(['TARGET'], axis=1), y = train['TARGET'])\n",
    "\n",
    "fin = time.time()  \n",
    "tm= fin-inicio\n",
    "print('Tiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y', tm%60,'segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afa1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_svc = random_svc.best_estimator_\n",
    "best_random_svc.fit( X = train.drop(['TARGET'], axis=1), y = train['TARGET'])\n",
    "y_pred_r_svc= best_random_svc.predict(X = test.drop(['TARGET'], axis = 1,))\n",
    "acc = accuracy_score(test['TARGET'], y_pred_r_svc )\n",
    "print ('Acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['TARGET'], y_pred_r_svc) )\n",
    "plot_confusion_matrix(test['TARGET'], y_pred_r_svc, normalize=True, classes=best_random_sv.classes_, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE RELEVANCIES\n",
    "pd.DataFrame({'Attributes': train.drop('TARGET', axis=1).columns.tolist(),\n",
    "              'Importancia': best_random_svc.feature_importances_}).sort_values( by='Importancia', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gua9rdando el modelo\n",
    "joblib.dump( best_random_svc, r_ruta + 'SVC_random_search.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dc2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch\n",
    "param_dist_g_svc = { \"C\":[1,5,10,15],\n",
    "                     \"kernel\":['linear'],\n",
    "                     \"gamma\":['scale'], \n",
    "                     \"class_weight\":['balanced']\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()\n",
    "grid_svc = GridSearchCV( estimator = model_svc,\n",
    "                         param_grid = param_dist_g_svc, \n",
    "                         cv=5,  scoring = 'accuracy', n_jobs = -1 )\n",
    "grid_svc.fit( X = train.drop(['TARGET'], axis=1), y = train['TARGET'] )\n",
    "fin = time.time()  \n",
    "tm= fin-inicio\n",
    "print('Tiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y', tm%60,'segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_svc = grid_svc.best_estimator_\n",
    "# fit and predict\n",
    "best_grid_svc.fit( X = train.drop(['TARGET'], axis=1), y = train['TARGET'])\n",
    "y_pred_g_svc = best_grid_svc.predict(X = test.drop(['TARGET'], axis = 1,))\n",
    "acc = accuracy_score(test['TARGET'], y_pred_g_svc )\n",
    "print ('Acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8be466",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['TARGET'], y_pred_g_svc ) )\n",
    "plot_confusion_matrix(test['TARGET'], y_pred_g_svc, normalize=True, classes=best_grid_svc.classes_, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE RELEVANCIES\n",
    "pd.DataFrame({'Attributes': train.drop('TARGET', axis=1).columns.tolist(),\n",
    "              'Importancia': best_grid_svc.feature_importances_}).sort_values( by='Importancia', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardando el modelo\n",
    "joblib.dump( best_grid_svc, r_ruta + 'SVC_grid_search.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3865a3",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = XGBClassifier( random_state = semilla, use_label_encoder=False, eval_metric='mlogloss' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2795de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dis_r_xgb = { 'n_estimators': np.arange(50, 500, 50),  \n",
    "                    'learning_rate': [0.01, 0.1, 0.2, 0.3],  \n",
    "                    'max_depth': np.arange(3, 15, 1),  \n",
    "                    'min_child_weight': np.arange(1, 10, 1),  \n",
    "                    'subsample': [0.6, 0.8, 1.0],  \n",
    "                    'colsample_bytree': [0.6, 0.8, 1.0],  \n",
    "                    'gamma': [0, 0.1, 0.2, 0.3],  \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()\n",
    "random_xgb = RandomizedSearchCV( estimator = model_xgb, \n",
    "                                 param_distributions = param_dis_r_xgb,\n",
    "                                 n_iter = 100, cv = 5, scoring = 'accuracy', random_state = semilla, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_xgb.fit(X = train.drop(['TARGET'], axis=1), y = train['TARGET'])\n",
    "\n",
    "fin = time.time()  \n",
    "tm= fin-inicio\n",
    "print('Tiempo de ejecución es:',tm//3600,'horas con',tm%3600//60,'minutos y', tm%60,'segundos' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114eab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_xgb = random_xgb.best_estimator_\n",
    "best_random_xgb.fit( X = train.drop(['TARGET'], axis=1), y = train['TARGET'])\n",
    "y_pred_r_xgb = best_random_xgb.predict(X = test.drop(['TARGET'], axis = 1,))\n",
    "acc = accuracy_score(test['TARGET'], y_pred_r_xgb )\n",
    "print ('Acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b866bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test['TARGET'], y_pred_r_xgb) )\n",
    "plot_confusion_matrix(test['TARGET'], y_pred_r_xgb, normalize=True, classes=best_random_xgb.classes_, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE RELEVANCIES\n",
    "pd.DataFrame({'Attributes': train.drop('TARGET', axis=1).columns.tolist(),\n",
    "              'Importancia': best_random_xgb.feature_importances_}).sort_values( by='Importancia', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa920e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gua9rdando el modelo\n",
    "joblib.dump( best_random_xgb, r_ruta + 'XGBClassifier_random_search.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337147ef",
   "metadata": {},
   "source": [
    "## Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd5e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Definimos una capa convolucional\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# Definimos una segunda capa convolucional\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Definimos una tercera capa convolucional\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Añadimos nuestro clasificador\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilamos el modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit( train.drop('TARGET', axis=!), train['TARGET'],\n",
    "           batch_size=128,\n",
    "           shuffle=True,\n",
    "           epochs=10,\n",
    "           validation_data=(test.drop('TARGET', axis=1), test['TARGET']))\n",
    "\n",
    "# Evaluamos el modelo\n",
    "scores = model.evaluate( test.drop('TARGET', axis=1), test['TARGET'])\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normaliza\n",
    "val_no_acp = ['SEXO','PRES',\n",
    "             'N_PRI_P','N_PUB_P', 'N_IND_P', 'N_VOL_EC_P', 'N_VOL_EX_P', \n",
    "             'M_PRI_P','M_PUB_P', 'M_IND_P', 'M_VOL_EC_P', 'M_VOL_EX_P',\n",
    "             'TARGET']\n",
    "col_na = train.drop( val_no_acp, axis=1).columns.tolist()\n",
    "\n",
    "escal_nor = StandardScaler()\n",
    "\n",
    "Xs = escal_nor.fit_transform( train.drop( val_no_acp, axis=1)) #Se normaliza el train\n",
    "Xs = pd.concat([ pd.DataFrame(Xs).reset_index().drop(['index'], axis=1), \n",
    "                 pd.DataFrame(train[val_no_acp]).reset_index().drop(['index'], axis=1)], axis=1)\n",
    "Xs.columns = col_na + val_no_acp\n",
    "\n",
    "test_norm = escal_nor.transform( test.drop( val_no_acp, axis=1))\n",
    "Ys = pd.concat([ pd.DataFrame(test_norm).reset_index().drop(['index'], axis=1), \n",
    "                   pd.DataFrame(test[val_no_acp]).reset_index().drop(['index'], axis=1)], axis=1)\n",
    "Ys.columns = Xs.columnsndo los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializamos el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Definimos una capa convolucional\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# Definimos una segunda capa convolucional\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Definimos una tercera capa convolucional\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Añadimos nuestro clasificador\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compilamos el modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "model.fit(Xs.drop('TARGET', axis = 1), Xs['TARGET]',\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          epochs=10,\n",
    "          validation_data=(Ys.drop('TARGET', axis=1), Ys['TARGET'])) # aquí deberíamos usar un conjunto distinto al de test!!!\n",
    "\n",
    "# Evaluamos el modelo\n",
    "scores = model.evaluate( Ys.drop('TARGET', axis=1), Ys['TARGET'] )\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
